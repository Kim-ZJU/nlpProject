{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4887e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pickle as pkl\n",
    "import re\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28856827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sentence(sentence):\n",
    "    periodStrip  = re.compile(\"(?!<=\\d)(\\.)(?!\\d)\")\n",
    "    commaStrip   = re.compile(\"(\\d)(\\,)(\\d)\")\n",
    "    punct        = [';', r\"/\", '[', ']', '\"', '{', '}',\n",
    "                    '(', ')', '=', '+', '\\\\', '_', '-',\n",
    "                    '>', '<', '@', '`', ',', '?', '!']\n",
    "    contractions = {\"aint\": \"ain't\", \"arent\": \"aren't\", \"cant\": \"can't\", \"couldve\": \"could've\", \"couldnt\": \"couldn't\", \\\n",
    "                    \"couldn'tve\": \"couldn't've\", \"couldnt've\": \"couldn't've\", \"didnt\": \"didn't\", \"doesnt\": \"doesn't\", \"dont\": \"don't\", \"hadnt\": \"hadn't\", \\\n",
    "                    \"hadnt've\": \"hadn't've\", \"hadn'tve\": \"hadn't've\", \"hasnt\": \"hasn't\", \"havent\": \"haven't\", \"hed\": \"he'd\", \"hed've\": \"he'd've\", \\\n",
    "                    \"he'dve\": \"he'd've\", \"hes\": \"he's\", \"howd\": \"how'd\", \"howll\": \"how'll\", \"hows\": \"how's\", \"Id've\": \"I'd've\", \"I'dve\": \"I'd've\", \\\n",
    "                    \"Im\": \"I'm\", \"Ive\": \"I've\", \"isnt\": \"isn't\", \"itd\": \"it'd\", \"itd've\": \"it'd've\", \"it'dve\": \"it'd've\", \"itll\": \"it'll\", \"let's\": \"let's\", \\\n",
    "                    \"maam\": \"ma'am\", \"mightnt\": \"mightn't\", \"mightnt've\": \"mightn't've\", \"mightn'tve\": \"mightn't've\", \"mightve\": \"might've\", \\\n",
    "                    \"mustnt\": \"mustn't\", \"mustve\": \"must've\", \"neednt\": \"needn't\", \"notve\": \"not've\", \"oclock\": \"o'clock\", \"oughtnt\": \"oughtn't\", \\\n",
    "                    \"ow's'at\": \"'ow's'at\", \"'ows'at\": \"'ow's'at\", \"'ow'sat\": \"'ow's'at\", \"shant\": \"shan't\", \"shed've\": \"she'd've\", \"she'dve\": \"she'd've\", \\\n",
    "                    \"she's\": \"she's\", \"shouldve\": \"should've\", \"shouldnt\": \"shouldn't\", \"shouldnt've\": \"shouldn't've\", \"shouldn'tve\": \"shouldn't've\", \\\n",
    "                    \"somebody'd\": \"somebodyd\", \"somebodyd've\": \"somebody'd've\", \"somebody'dve\": \"somebody'd've\", \"somebodyll\": \"somebody'll\", \\\n",
    "                    \"somebodys\": \"somebody's\", \"someoned\": \"someone'd\", \"someoned've\": \"someone'd've\", \"someone'dve\": \"someone'd've\", \\\n",
    "                    \"someonell\": \"someone'll\", \"someones\": \"someone's\", \"somethingd\": \"something'd\", \"somethingd've\": \"something'd've\", \\\n",
    "                    \"something'dve\": \"something'd've\", \"somethingll\": \"something'll\", \"thats\": \"that's\", \"thered\": \"there'd\", \"thered've\": \"there'd've\", \\\n",
    "                    \"there'dve\": \"there'd've\", \"therere\": \"there're\", \"theres\": \"there's\", \"theyd\": \"they'd\", \"theyd've\": \"they'd've\", \\\n",
    "                    \"they'dve\": \"they'd've\", \"theyll\": \"they'll\", \"theyre\": \"they're\", \"theyve\": \"they've\", \"twas\": \"'twas\", \"wasnt\": \"wasn't\", \\\n",
    "                    \"wed've\": \"we'd've\", \"we'dve\": \"we'd've\", \"weve\": \"we've\", \"werent\": \"weren't\", \"whatll\": \"what'll\", \"whatre\": \"what're\", \\\n",
    "                    \"whats\": \"what's\", \"whatve\": \"what've\", \"whens\": \"when's\", \"whered\": \"where'd\", \"wheres\": \"where's\", \"whereve\": \"where've\", \\\n",
    "                    \"whod\": \"who'd\", \"whod've\": \"who'd've\", \"who'dve\": \"who'd've\", \"wholl\": \"who'll\", \"whos\": \"who's\", \"whove\": \"who've\", \"whyll\": \"why'll\", \\\n",
    "                    \"whyre\": \"why're\", \"whys\": \"why's\", \"wont\": \"won't\", \"wouldve\": \"would've\", \"wouldnt\": \"wouldn't\", \"wouldnt've\": \"wouldn't've\", \\\n",
    "                    \"wouldn'tve\": \"wouldn't've\", \"yall\": \"y'all\", \"yall'll\": \"y'all'll\", \"y'allll\": \"y'all'll\", \"yall'd've\": \"y'all'd've\", \\\n",
    "                    \"y'alld've\": \"y'all'd've\", \"y'all'dve\": \"y'all'd've\", \"youd\": \"you'd\", \"youd've\": \"you'd've\", \"you'dve\": \"you'd've\", \\\n",
    "                    \"youll\": \"you'll\", \"youre\": \"you're\", \"youve\": \"you've\"}\n",
    "\n",
    "    inText = sentence.replace('\\n', ' ')\n",
    "    inText = inText.replace('\\t', ' ')\n",
    "    inText = inText.strip()\n",
    "    outText = inText\n",
    "    for p in punct:\n",
    "        if (p + ' ' in inText or ' ' + p in inText) or \\\n",
    "           (re.search(commaStrip, inText) != None):\n",
    "            outText = outText.replace(p, '')\n",
    "        else:\n",
    "            outText = outText.replace(p, ' ')\n",
    "    outText = periodStrip.sub(\"\", outText, re.UNICODE)\n",
    "    outText = outText.lower().split()\n",
    "    for wordId, word in enumerate(outText):\n",
    "        if word in contractions:\n",
    "            outText[wordId] = contractions[word]\n",
    "    outText = ' '.join(outText)\n",
    "    return outText\n",
    "\n",
    "def process_answer(answer):\n",
    "    articles = ['a', 'an', 'the']\n",
    "    manualMap = { 'none': '0', 'zero': '0', 'one': '1', 'two': '2', 'three':\n",
    "                  '3', 'four': '4', 'five': '5', 'six': '6', 'seven': '7',\n",
    "                  'eight': '8', 'nine': '9', 'ten': '10' }\n",
    "    new_answer = process_sentence(answer)\n",
    "    outText = []\n",
    "    for word in new_answer.split():\n",
    "        if word not in articles:\n",
    "            word = manualMap.setdefault(word, word)\n",
    "            outText.append(word)\n",
    "    return ' '.join(outText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46dd59e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing 0 in train\n",
      "finished processing 10000 in train\n",
      "finished processing 20000 in train\n",
      "finished processing 30000 in train\n",
      "finished processing 40000 in train\n"
     ]
    }
   ],
   "source": [
    "f = open(\"./questions/train.json\", \"r\")\n",
    "f1 = open(\"/Users/kim/GitHub/data/annotations/train.json\", \"r\")\n",
    "file = json.load(f)\n",
    "file1 = json.load(f1)\n",
    "annotations = file1['annotations']\n",
    "train_question_ids = []\n",
    "train_image_ids = []\n",
    "train_questions = []\n",
    "train_answers = []\n",
    "question_dict_count = dict()\n",
    "answer_dict_count = dict()\n",
    "\n",
    "# 形成qa：一个字典，整理出对应question_id的annotation\n",
    "qa = {ann['question_id']: [] for ann in annotations}\n",
    "for ann in annotations:\n",
    "    qa[ann['question_id']] = ann\n",
    "\n",
    "#获取image_id question_id\n",
    "for idx, item in enumerate(file['questions']):\n",
    "    train_question_ids.append(item['question_id'])\n",
    "    train_image_ids.append(item['image_id'])\n",
    "    \n",
    "    #process question\n",
    "    question = item['question']\n",
    "    question = process_sentence(question)\n",
    "    question = question.split()\n",
    "    for word in question:\n",
    "        question_dict_count[word] = question_dict_count.get(word, 0) + 1\n",
    "    train_questions.append(question)\n",
    "    answer = qa[item['question_id']]['answers']\n",
    "    answer_new = [process_answer(ans['answer']) for ans in answer]\n",
    "    ans_array = []\n",
    "    for ans in answer:\n",
    "        ans_array.append(ans['answer'])\n",
    "    for word in answer_new:\n",
    "        answer_dict_count[word] = answer_dict_count.get(word, 0) + 1\n",
    "    train_answers.append(ans_array)\n",
    "    if idx % 10000 == 0:\n",
    "        print ('finished processing %d in train' %(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bbdc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort question dict\n",
    "question_count = question_dict_count.values()\n",
    "sorted_index = [count[0] for count in\n",
    "                sorted(enumerate(question_count),\n",
    "                       key = lambda x : x[1],\n",
    "                       reverse=True)]\n",
    "sorted_count = sorted(question_count, reverse=True)\n",
    "question_key = list(question_dict_count.keys())\n",
    "# 对question_key重新排序\n",
    "question_key = [question_key[idx] for idx in sorted_index]\n",
    "# add '<unk>' to the begining\n",
    "question_key.insert(0, '<unk>')\n",
    "# '<unk>' begins at 1, 0 is reserved for empty words\n",
    "question_key = dict((key, idx + 1) for idx, key in enumerate(question_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ed6d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1000\n",
    "# sort answer dict and get top k answers\n",
    "del answer_dict_count['']\n",
    "answer_count = answer_dict_count.values()\n",
    "sorted_index = [count[0] for count in\n",
    "                sorted(enumerate(answer_count),\n",
    "                       key = lambda x : x[1],\n",
    "                       reverse=True)]\n",
    "sorted_count = sorted(answer_count, reverse=True)\n",
    "answer_key = list(answer_dict_count.keys())\n",
    "answer_key = [answer_key[idx] for idx in sorted_index]\n",
    "answer_top_k = answer_key[:k]\n",
    "answer_top_k = dict((key, idx) for idx, key in enumerate(answer_top_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6baad7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2105 out of 44375, 0.047437 of the question in train are removed\n"
     ]
    }
   ],
   "source": [
    "# convert words to idx and remove some\n",
    "train_question_idx = []\n",
    "train_answer_idx = []\n",
    "train_answer_counter = []\n",
    "idx_to_remove = []\n",
    "for idx, answer in enumerate(train_answers):\n",
    "    question_idx = [question_key[word] for word in train_questions[idx]]\n",
    "    train_question_idx.append(question_idx)\n",
    "    answer_idx = [answer_top_k[ans] for ans in answer\n",
    "                 if ans in answer_top_k]\n",
    "    answer_counter = Counter(answer_idx)\n",
    "    train_answer_counter.append(answer_counter)\n",
    "    train_answer_idx.append(answer_idx)\n",
    "    if not answer_idx:\n",
    "        idx_to_remove.append(idx)\n",
    "print ('%d out of %d, %f of the question in train are removed'\\\n",
    "    %(len(idx_to_remove), len(train_question_ids),\n",
    "      len(idx_to_remove) / float(len(train_question_ids))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "536109cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-e394453ae179>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_question_idx = np.array(train_question_idx)\n",
      "<ipython-input-7-e394453ae179>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_answer_idx = np.array(train_answer_idx)\n"
     ]
    }
   ],
   "source": [
    "# transform to array and delete all the empty answer\n",
    "train_question_ids = np.array(train_question_ids)\n",
    "train_image_ids = np.array(train_image_ids)\n",
    "train_question_idx = np.array(train_question_idx)\n",
    "train_answer_idx = np.array(train_answer_idx)\n",
    "train_answer_counter = np.array(train_answer_counter)\n",
    "\n",
    "train_question_ids = np.delete(train_question_ids, idx_to_remove)\n",
    "train_image_ids = np.delete(train_image_ids, idx_to_remove)\n",
    "train_question_idx = np.delete(train_question_idx, idx_to_remove)\n",
    "train_answer_idx = np.delete(train_answer_idx, idx_to_remove)\n",
    "train_answer_counter = np.delete(train_answer_counter, idx_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d6f4d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Counter({16: 10}) Counter({0: 10}) Counter({12: 7, 51: 2, 940: 1}) ...\n",
      " Counter({2: 10}) Counter({1: 1, 613: 1}) Counter({7: 10})]\n",
      "finished processing train\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# reshuffle the train data\n",
    "idx_shuffle = list(range(train_question_ids.shape[0]))\n",
    "random.shuffle(idx_shuffle)\n",
    "train_question_ids = train_question_ids[idx_shuffle]\n",
    "train_image_ids = train_image_ids[idx_shuffle]\n",
    "train_question_idx = train_question_idx[idx_shuffle]\n",
    "train_answer_idx = train_answer_idx[idx_shuffle]\n",
    "train_answer_counter = train_answer_counter[idx_shuffle]\n",
    "\n",
    "# the most frequent as label\n",
    "train_answer_label = [counter.most_common(1)[0][0]\n",
    "                      for counter in train_answer_counter]\n",
    "train_answer_label = np.array(train_answer_label)\n",
    "\n",
    "# transform from counter to dict\n",
    "train_answer_counter = [dict(counter) for counter in train_answer_counter]\n",
    "train_answer_counter = np.array(train_answer_counter)\n",
    "\n",
    "print ('finished processing train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bd9ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
