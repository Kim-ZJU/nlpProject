{"metadata": {"language_info": {"name": "python", "version": "3.7.6", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "mindspore-python3.7-aarch64", "display_name": "MindSpore-python3.7-aarch64", "language": "python"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "## 1.\u5bfc\u5165\u6a21\u5757", "metadata": {}}, {"cell_type": "code", "source": "import moxing as mox\n\ndata_url = \"s3://nlp.final/san/data/\"\ncode_url = \"s3://nlp.final/san/code/image_model/src\"\n# mox.file.copy_parallel(src_url=\"obs://nlp-kim/project/data/\", dst_url='./data/') \n# mox.file.copy_parallel(src_url=\"s3://dl4nlp-my/project/data/\", dst_url='./data/') \nmox.file.copy_parallel(src_url = code_url,dst_url='./src/')", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 1, "outputs": [{"name": "stderr", "text": "INFO:root:Using MoXing-v1.17.3-d858ff4a\nINFO:root:Using OBS-Python-SDK-3.20.9.1\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=data_url, dst_url='./data/') ", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 2, "outputs": [{"name": "stderr", "text": "INFO:root:Listing OBS: 1000\nINFO:root:Listing OBS: 2000\nINFO:root:Listing OBS: 3000\nINFO:root:Listing OBS: 4000\nINFO:root:Listing OBS: 5000\nINFO:root:Listing OBS: 6000\nINFO:root:Listing OBS: 7000\nINFO:root:Listing OBS: 8000\nINFO:root:Listing OBS: 9000\nINFO:root:Listing OBS: 10000\nINFO:root:Listing OBS: 11000\nINFO:root:Listing OBS: 12000\nINFO:root:Listing OBS: 13000\nINFO:root:Listing OBS: 14000\nINFO:root:Listing OBS: 15000\nINFO:root:Listing OBS: 16000\nINFO:root:Listing OBS: 17000\nINFO:root:Listing OBS: 18000\nINFO:root:Listing OBS: 19000\nINFO:root:Listing OBS: 20000\nINFO:root:Listing OBS: 21000\nINFO:root:Listing OBS: 22000\nINFO:root:Listing OBS: 23000\nINFO:root:Listing OBS: 24000\nINFO:root:Listing OBS: 25000\nINFO:root:Listing OBS: 26000\nINFO:root:Listing OBS: 27000\nINFO:root:Listing OBS: 28000\nINFO:root:Listing OBS: 29000\nINFO:root:Listing OBS: 30000\nINFO:root:Listing OBS: 31000\nINFO:root:Listing OBS: 32000\nINFO:root:Listing OBS: 33000\nINFO:root:Listing OBS: 34000\nINFO:root:Listing OBS: 35000\nINFO:root:Listing OBS: 36000\nINFO:root:Listing OBS: 37000\nINFO:root:Listing OBS: 38000\nINFO:root:Listing OBS: 39000\nINFO:root:Listing OBS: 40000\nINFO:root:Listing OBS: 41000\nINFO:root:Listing OBS: 42000\nINFO:root:Listing OBS: 43000\nINFO:root:Listing OBS: 44000\nINFO:root:Listing OBS: 45000\nINFO:root:Listing OBS: 46000\nINFO:root:Listing OBS: 47000\nINFO:root:Listing OBS: 48000\nINFO:root:Listing OBS: 49000\nINFO:root:Listing OBS: 50000\nINFO:root:Listing OBS: 51000\nINFO:root:Listing OBS: 52000\nINFO:root:Listing OBS: 53000\nINFO:root:Listing OBS: 54000\nINFO:root:Listing OBS: 55000\nINFO:root:Listing OBS: 56000\nINFO:root:Listing OBS: 57000\nINFO:root:Listing OBS: 58000\nINFO:root:Listing OBS: 59000\nINFO:root:Listing OBS: 60000\nINFO:root:Listing OBS: 61000\nINFO:root:Listing OBS: 62000\nINFO:root:Listing OBS: 63000\nINFO:root:Listing OBS: 64000\nINFO:root:Listing OBS: 65000\nINFO:root:Listing OBS: 66000\nINFO:root:Listing OBS: 67000\nINFO:root:Listing OBS: 68000\nINFO:root:Listing OBS: 69000\nINFO:root:Listing OBS: 70000\nINFO:root:Listing OBS: 71000\nINFO:root:pid: None.\t1000/71899\nINFO:root:pid: None.\t2000/71899\nINFO:root:pid: None.\t3000/71899\nINFO:root:pid: None.\t4000/71899\nINFO:root:pid: None.\t5000/71899\nINFO:root:pid: None.\t6000/71899\nINFO:root:pid: None.\t7000/71899\nINFO:root:pid: None.\t8000/71899\nINFO:root:pid: None.\t9000/71899\nINFO:root:pid: None.\t10000/71899\nINFO:root:pid: None.\t11000/71899\nINFO:root:pid: None.\t12000/71899\nINFO:root:pid: None.\t13000/71899\nINFO:root:pid: None.\t14000/71899\nINFO:root:pid: None.\t15000/71899\nINFO:root:pid: None.\t16000/71899\nINFO:root:pid: None.\t17000/71899\nINFO:root:pid: None.\t18000/71899\nINFO:root:pid: None.\t19000/71899\nINFO:root:pid: None.\t20000/71899\nINFO:root:pid: None.\t21000/71899\nINFO:root:pid: None.\t22000/71899\nINFO:root:pid: None.\t23000/71899\nINFO:root:pid: None.\t24000/71899\nINFO:root:pid: None.\t25000/71899\nINFO:root:pid: None.\t26000/71899\nINFO:root:pid: None.\t27000/71899\nINFO:root:pid: None.\t28000/71899\nINFO:root:pid: None.\t29000/71899\nINFO:root:pid: None.\t30000/71899\nINFO:root:pid: None.\t31000/71899\nINFO:root:pid: None.\t32000/71899\nINFO:root:pid: None.\t33000/71899\nINFO:root:pid: None.\t34000/71899\nINFO:root:pid: None.\t35000/71899\nINFO:root:pid: None.\t36000/71899\nINFO:root:pid: None.\t37000/71899\nINFO:root:pid: None.\t38000/71899\nINFO:root:pid: None.\t39000/71899\nINFO:root:pid: None.\t40000/71899\nINFO:root:pid: None.\t41000/71899\nINFO:root:pid: None.\t42000/71899\nINFO:root:pid: None.\t43000/71899\nINFO:root:pid: None.\t44000/71899\nINFO:root:pid: None.\t45000/71899\nINFO:root:pid: None.\t46000/71899\nINFO:root:pid: None.\t47000/71899\nINFO:root:pid: None.\t48000/71899\nINFO:root:pid: None.\t49000/71899\nINFO:root:pid: None.\t50000/71899\nINFO:root:pid: None.\t51000/71899\nINFO:root:pid: None.\t52000/71899\nINFO:root:pid: None.\t53000/71899\nINFO:root:pid: None.\t54000/71899\nINFO:root:pid: None.\t55000/71899\nINFO:root:pid: None.\t56000/71899\nINFO:root:pid: None.\t57000/71899\nINFO:root:pid: None.\t58000/71899\nINFO:root:pid: None.\t59000/71899\nINFO:root:pid: None.\t60000/71899\nINFO:root:pid: None.\t61000/71899\nINFO:root:pid: None.\t62000/71899\nINFO:root:pid: None.\t63000/71899\nINFO:root:pid: None.\t64000/71899\nINFO:root:pid: None.\t65000/71899\nINFO:root:pid: None.\t66000/71899\nINFO:root:pid: None.\t67000/71899\nINFO:root:pid: None.\t68000/71899\nINFO:root:pid: None.\t69000/71899\nINFO:root:pid: None.\t70000/71899\nINFO:root:pid: None.\t71000/71899\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "import sys\nimport os\nimport json\nimport pickle as pkl\nimport re\nfrom collections import Counter\nimport numpy as np\nimport random\n\nfrom collections import OrderedDict\nimport math\n\nimport mindspore\nimport mindspore.nn as nn\nfrom mindspore import Tensor,Model\nfrom mindspore import context\nfrom mindspore.train.model import Model\nfrom mindspore.nn.metrics import Accuracy\nfrom mindspore.train.serialization import load_checkpoint, load_param_into_net\nfrom mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n#from mindspore.ops import operations as ops\nfrom mindspore import ops\nfrom mindspore import dtype as mstype", "metadata": {"trusted": true}, "execution_count": 3, "outputs": []}, {"cell_type": "markdown", "source": "## 2.\u6570\u636e\u9884\u5904\u7406", "metadata": {}}, {"cell_type": "markdown", "source": "### 2.1 \u5904\u7406\u51fd\u6570\u53ca\u521d\u59cb\u5316\u51fd\u6570", "metadata": {}}, {"cell_type": "code", "source": "# mox.file.copy_parallel(src_url=\"obs://nlp-kim/project/code/data_vqa/process_func.py\", dst_url='./process_func.py')\n# mox.file.copy_parallel(src_url=\"obs://nlp-kim/project/code/data_vqa/initialization.py\", dst_url='./initialization.py')\nmox.file.copy_parallel(src_url = \"s3://nlp.final/san/code/data_vqa\",dst_url=\"./data_vqa\")\nfrom data_vqa.process_func import *\n#from data_vqa.initialization import *\nfrom data_vqa.vqa_dataset_by_api import create_dataset\nfrom data_vqa.vqa_config import train,test,val", "metadata": {"trusted": true}, "execution_count": 4, "outputs": []}, {"cell_type": "markdown", "source": "### 2.2 \u53d8\u91cf\u8bf4\u660e", "metadata": {}}, {"cell_type": "code", "source": "#qa\uff1aquestion\u548c\u5bf9\u5e94\u7684annotions\n#train_question_ids\uff1aquestion\u7684id\u7684\u6570\u7ec4\n\n#question_dict_count\uff1a question\u4e2d\u7684\u5355\u8bcd\u51fa\u73b0\u6b21\u6570\u7edf\u8ba1\n#train_questions\uff1a question\u8bed\u53e5split\u4e3aword\u7684\u6570\u7ec4\u7684\u6570\u7ec4\n#answer_dict_count\uff1a answer\u4e2d\u7684\u5355\u8bcd\u51fa\u73b0\u6b21\u6570\u7edf\u8ba1\n#train_answers\uff1a answer\u88absplit\u4e3aword\u7684\u6570\u7ec4\u7684\u6570\u7ec4\n\n#question_key\uff1a\u6309\u7167question\u4e2d\u51fa\u73b0\u6b21\u6570\u8fdb\u884c\u6392\u5e8f\n#answer_top_k: \u6309\u7167answer\u4e2d\u51fa\u73b0\u7684\u6b21\u6570\u8fdb\u884c\u6392\u5e8f\n", "metadata": {"trusted": true}, "execution_count": 5, "outputs": []}, {"cell_type": "markdown", "source": "### 2.3 \u9884\u5904\u7406\u7ec6\u8282", "metadata": {}}, {"cell_type": "code", "source": "f = open(\"./data/questions/train.json\", \"r\")\nf1 = open(\"./data/annotations/train.json\", \"r\")\nfile = json.load(f)\nfile1 = json.load(f1)\nannotations = file1['annotations']\ntrain_question_ids = []\ntrain_image_ids = []\ntrain_questions = []\ntrain_answers = []\nquestion_dict_count = dict()\nanswer_dict_count = dict()\n\n# \u5f62\u6210qa\uff1a\u4e00\u4e2a\u5b57\u5178\uff0c\u6574\u7406\u51fa\u5bf9\u5e94question_id\u7684annotation\nqa = {ann['question_id']: [] for ann in annotations}\nfor ann in annotations:\n    qa[ann['question_id']] = ann\n\n#\u83b7\u53d6image_id question_id\n# \u9700\u8981\u8fdb\u884c\u5c01\u88c5\u4ee5\u9002\u7528\u4e8e\u8bad\u7ec3\u3001\u6d4b\u8bd5\u3001\u8bc4\u4f30\nimg_not_exist_count = 0\nfor idx, item in enumerate(file['questions']):\n    img_path = os.path.join(\"./data/images/train\",\"COCO_{0}2014_{1}.jpg\".format(\"train\",str(item['image_id']).zfill(12)))\n    if not os.path.exists(img_path):\n        img_not_exist_count += 1\n        continue\n\n    train_question_ids.append(item['question_id'])\n    train_image_ids.append(item['image_id'])\n    \n    #process question\n    question = item['question']\n    question = process_sentence(question)\n    question = question.split()\n    for word in question:\n        question_dict_count[word] = question_dict_count.get(word, 0) + 1\n    train_questions.append(question)\n    answer = qa[item['question_id']]['answers']\n    answer_new = [process_answer(ans['answer']) for ans in answer]\n    ans_array = []\n    for ans in answer:\n        ans_array.append(ans['answer'])\n    for word in answer_new:\n        answer_dict_count[word] = answer_dict_count.get(word, 0) + 1\n    train_answers.append(ans_array)\n    if idx % 10000 == 0:\n        print ('finished processing %d in train' %(idx))\n\n# sort question dict\nquestion_count = question_dict_count.values()\nsorted_index = [count[0] for count in\n                sorted(enumerate(question_count),\n                       key = lambda x : x[1],\n                       reverse=True)]\nsorted_count = sorted(question_count, reverse=True)\nquestion_key = list(question_dict_count.keys())\n# \u5bf9question_key\u91cd\u65b0\u6392\u5e8f\nquestion_key = [question_key[idx] for idx in sorted_index]\n# add '<unk>' to the begining\nquestion_key.insert(0, '<unk>')\n# '<unk>' begins at 1, 0 is reserved for empty words\nquestion_key = dict((key, idx + 1) for idx, key in enumerate(question_key))\n\nk = 1000\n# sort answer dict and get top k answers\n\n#\u56e0\u62a5\u9519\u6682\u5220\n# del answer_dict_count['']\nanswer_count = answer_dict_count.values()\nsorted_index = [count[0] for count in\n                sorted(enumerate(answer_count),\n                       key = lambda x : x[1],\n                       reverse=True)]\nsorted_count = sorted(answer_count, reverse=True)\nanswer_key = list(answer_dict_count.keys())\nanswer_key = [answer_key[idx] for idx in sorted_index]\nanswer_top_k = answer_key[:k]\nanswer_top_k = dict((key, idx) for idx, key in enumerate(answer_top_k))\n\n# convert words to idx and remove some\ntrain_question_idx = []\ntrain_answer_idx = []\ntrain_answer_counter = []\nidx_to_remove = []\nfor idx, answer in enumerate(train_answers):\n    question_idx = [question_key[word] for word in train_questions[idx]]\n    #print(question_idx)\n    #print('\\n')\n    #print(train_questions[idx])\n    train_question_idx.append(question_idx)\n    answer_idx = [answer_top_k[ans] for ans in answer\n                 if ans in answer_top_k]\n    answer_counter = Counter(answer_idx)\n    train_answer_counter.append(answer_counter)\n    train_answer_idx.append(answer_idx)\n    if not answer_idx:\n        idx_to_remove.append(idx)\nprint ('%d out of %d, %f of the question in train are removed'\\\n    %(len(idx_to_remove), len(train_question_ids),\n      len(idx_to_remove) / float(len(train_question_ids))))\n\n# transform to array and delete all the empty answer\ntrain_question_ids = np.array(train_question_ids)\ntrain_image_ids = np.array(train_image_ids)\ntrain_question_idx = np.array(train_question_idx)\ntrain_answer_idx = np.array(train_answer_idx)\ntrain_answer_counter = np.array(train_answer_counter)\n\ntrain_question_ids = np.delete(train_question_ids, idx_to_remove)\ntrain_image_ids = np.delete(train_image_ids, idx_to_remove)\ntrain_question_idx = np.delete(train_question_idx, idx_to_remove)\ntrain_answer_idx = np.delete(train_answer_idx, idx_to_remove)\ntrain_answer_counter = np.delete(train_answer_counter, idx_to_remove)\n\n# reshuffle the train data\nidx_shuffle = list(range(train_question_ids.shape[0]))\nrandom.shuffle(idx_shuffle)\ntrain_question_ids = train_question_ids[idx_shuffle]\ntrain_image_ids = train_image_ids[idx_shuffle]\ntrain_question_idx = train_question_idx[idx_shuffle]\ntrain_answer_idx = train_answer_idx[idx_shuffle]\ntrain_answer_counter = train_answer_counter[idx_shuffle]\n\n# the most frequent as label\ntrain_answer_label = [counter.most_common(1)[0][0]\n                      for counter in train_answer_counter]\ntrain_answer_label = np.array(train_answer_label)\n\n# transform from counter to dict\ntrain_answer_counter = [dict(counter) for counter in train_answer_counter]\ntrain_answer_counter = np.array(train_answer_counter)\n\nprint ('finished processing train')\n\nprint('{0} images not exist'.format(img_not_exist_count))", "metadata": {"trusted": true}, "execution_count": 6, "outputs": [{"name": "stdout", "text": "finished processing 10000 in train\nfinished processing 20000 in train\n950 out of 23071, 0.041177 of the question in train are removed\nfinished processing train\n21304 images not exist\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "print(answer_top_k)", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 7, "outputs": [{"name": "stdout", "text": "{'no': 0, 'yes': 1, '1': 2, '2': 3, 'white': 4, '0': 5, '3': 6, 'black': 7, 'red': 8, 'blue': 9, '4': 10, 'brown': 11, 'green': 12, 'yellow': 13, '5': 14, 'gray': 15, 'nothing': 16, '6': 17, 'baseball': 18, 'frisbee': 19, 'pizza': 20, 'right': 21, 'kitchen': 22, 'tennis': 23, 'left': 24, 'wood': 25, 'bathroom': 26, 'orange': 27, '7': 28, 'pink': 29, '8': 30, 'living room': 31, 'dog': 32, 'man': 33, 'cat': 34, 'phone': 35, 'silver': 36, 'skateboarding': 37, '10': 38, 'grass': 39, 'kite': 40, 'water': 41, 'cake': 42, 'table': 43, 'surfing': 44, 'skateboard': 45, 'tan': 46, 'skiing': 47, 'black and white': 48, 'snow': 49, 'wii': 50, 'standing': 51, 'surfboard': 52, '9': 53, 'cow': 54, 'laptop': 55, 'bus': 56, 'giraffe': 57, 'snowboarding': 58, 'woman': 59, 'purple': 60, 'elephant': 61, 'horse': 62, 'motorcycle': 63, 'soccer': 64, 'stop': 65, 'apple': 66, 'food': 67, 'banana': 68, 'sunny': 69, 'male': 70, 'beach': 71, '20': 72, 'eating': 73, 'clear': 74, 'unknown': 75, 'maybe': 76, 'bear': 77, 'plane': 78, '12': 79, 'bed': 80, 'umbrella': 81, 'wine': 82, 'hat': 83, 'train': 84, 'down': 85, 'walking': 86, 'winter': 87, 'summer': 88, 'tile': 89, 'sand': 90, 'cell phone': 91, 'many': 92, 'broccoli': 93, 'female': 94, 'outside': 95, 'bedroom': 96, '15': 97, 'night': 98, 'plate': 99, 'beige': 100, 'camera': 101, 'flowers': 102, 'knife': 103, 'brick': 104, 'hot dog': 105, 'chair': 106, 'cloudy': 107, 'fork': 108, 'ball': 109, 'tv': 110, 'car': 111, 'plastic': 112, 'up': 113, 'zoo': 114, 'blonde': 115, 'girl': 116, 'lettuce': 117, 'zebra': 118, 'sandwich': 119, 'boat': 120, 'people': 121, 'overcast': 122, 'coffee': 123, 'blue and white': 124, 'bike': 125, 'airplane': 126, '11': 127, 'truck': 128, 'red and white': 129, 'skis': 130, 'sitting': 131, 'bench': 132, 'tie': 133, 'wall': 134, 'trees': 135, 'day': 136, 'street': 137, '13': 138, 'cows': 139, 'glass': 140, 'bat': 141, 'english': 142, 'metal': 143, 'couch': 144, 'birthday': 145, 'square': 146, 'floor': 147, 'bananas': 148, 'sheep': 149, 'snowboard': 150, 'bird': 151, 'not sure': 152, 'ground': 153, 'ocean': 154, 'desk': 155, 'kites': 156, 'carpet': 157, 'round': 158, 'flying kite': 159, 'park': 160, 'horses': 161, 'usa': 162, 'dirt': 163, 'afternoon': 164, 'paper': 165, 'helmet': 166, 'glasses': 167, 'remote': 168, 'sky': 169, 'beer': 170, 'stripes': 171, 'lot': 172, 'field': 173, 'collar': 174, 'closed': 175, 'chicken': 176, '25': 177, 'concrete': 178, 'neither': 179, '30': 180, 'city': 181, 'tree': 182, \"can't tell\": 183, 'fence': 184, '50': 185, 'bicycle': 186, 'playing': 187, 'evening': 188, 'computer': 189, '14': 190, 'mountain': 191, 'not possible': 192, 'boy': 193, 'vegetables': 194, 'apples': 195, \"don't know\": 196, 'morning': 197, 'carrots': 198, 'africa': 199, 'fall': 200, 'dell': 201, 'real': 202, 'forward': 203, 'donut': 204, 'office': 205, 'suitcase': 206, 'person': 207, 'pepperoni': 208, '16': 209, 'small': 210, 'fruit': 211, 'nike': 212, 'china': 213, 'window': 214, 'spring': 215, 'teddy bear': 216, 'salad': 217, 'inside': 218, 'elephants': 219, 'road': 220, 'bowl': 221, 'mountains': 222, 'counter': 223, 'clock': 224, 'giraffes': 225, 'windows': 226, 'no 1': 227, 'soup': 228, 'light': 229, 'cheese': 230, 'hair': 231, 'sun': 232, 'solid': 233, 'rose': 234, 'dinner': 235, 'wii remote': 236, 'oranges': 237, 'flying': 238, 'nowhere': 239, 'toilet': 240, 'wii controller': 241, 'shorts': 242, 'leaves': 243, 'white and black': 244, 'breakfast': 245, 'rectangle': 246, 'tea': 247, 'tennis racket': 248, 'birds': 249, 'ski poles': 250, 'picture': 251, 'microwave': 252, 'old': 253, 'playing wii': 254, 'toothbrush': 255, 'refrigerator': 256, 'off': 257, 'sidewalk': 258, 'brown and white': 259, 'jacket': 260, 'donuts': 261, 'cooking': 262, 'oak': 263, 'chinese': 264, 'home': 265, 'floral': 266, 'mirror': 267, 'rain': 268, '17': 269, 'on table': 270, 'towel': 271, 'shoes': 272, 'wetsuit': 273, 'spoon': 274, 'house': 275, 'warm': 276, 'dining room': 277, 'sign': 278, 'shirt': 279, 'striped': 280, 'blanket': 281, 'bag': 282, 'sink': 283, 'christmas': 284, '100': 285, 'both': 286, 'cold': 287, 'book': 288, 'ski': 289, 'controller': 290, 'tomato': 291, 'daytime': 292, '21': 293, '18': 294, '': 295, 'playing tennis': 296, 'oven': 297, 'circle': 298, 'several': 299, 'short': 300, 'sleeping': 301, 'w': 302, 'unsure': 303, 'door': 304, 'young': 305, 'straight': 306, 'flying kites': 307, 'sneakers': 308, 'restaurant': 309, 'seagull': 310, 'lunch': 311, 'building': 312, 'american': 313, 'gold': 314, 'rug': 315, 'tennis ball': 316, 'river': 317, 'kite flying': 318, 'america': 319, 'stone': 320, 'noon': 321, 'hand': 322, 'ketchup': 323, 'cream': 324, 'living': 325, 'on': 326, 'happy': 327, 'clouds': 328, 'front': 329, 'fish': 330, 'green and white': 331, 'long': 332, 'adult': 333, 'cement': 334, 'color': 335, 'lab': 336, 'television': 337, 'bread': 338, 'milk': 339, 'plaid': 340, 'strawberries': 341, 'flower': 342, 'very': 343, 'water skiing': 344, 'palm': 345, \"i don't know\": 346, 'carrot': 347, 'sunglasses': 348, 'roses': 349, 'open': 350, 'plain': 351, '28': 352, 'black white': 353, 'white and red': 354, 'airport': 355, 'plant': 356, 'rope': 357, 'wedding': 358, 'rocks': 359, 'back': 360, 'graffiti': 361, 'clothes': 362, 'ring': 363, 'resting': 364, 'middle': 365, 'ford': 366, 'passenger': 367, 'cars': 368, 'soda': 369, 'scissors': 370, 'playing frisbee': 371, 'lake': 372, 'drinking': 373, 'vase': 374, 'ponytail': 375, 'united states': 376, 'lamp': 377, 'air': 378, 'polo': 379, '40': 380, 'rock': 381, 'hot dogs': 382, 'mustard': 383, 'backpack': 384, 'white and blue': 385, 'chairs': 386, 'talking': 387, 'gas': 388, 'mouse': 389, 'away': 390, 'england': 391, 'united': 392, 'posing': 393, 'spinach': 394, 'pole': 395, 'ramp': 396, 'taking off': 397, 'sunset': 398, 'sandals': 399, 'good': 400, 'police': 401, 'dirty': 402, 'toy': 403, 'fake': 404, 'hay': 405, 'canada': 406, 'luggage': 407, 'fridge': 408, 'fries': 409, 'child': 410, 'rural': 411, '26': 412, 'texting': 413, 'pictures': 414, 'guitar': 415, 'asphalt': 416, 'no idea': 417, 'skating': 418, 'watch': 419, 'batting': 420, 'rainy': 421, 'books': 422, 'racket': 423, 'to right': 424, 'urban': 425, 'sausage': 426, 'smiling': 427, 'peppers': 428, 'catcher': 429, 'running': 430, 'steam': 431, 'beef': 432, 'in air': 433, 'nobody': 434, 'calm': 435, 'coca cola': 436, 'driving': 437, 'baseball bat': 438, 'grazing': 439, 'north': 440, 'marble': 441, 'pitcher': 442, '7097': 443, 'zebras': 444, '23': 445, 'out': 446, 'chocolate': 447, 'samsung': 448, 'parking': 449, 'wilson': 450, 'modern': 451, 'tulips': 452, 'dusk': 453, 'clean': 454, 'umpire': 455, 'head': 456, 'catching': 457, 'riding': 458, 'skate park': 459, 'on ground': 460, 'cats': 461, 'stove': 462, 'smoke': 463, 'planes': 464, 'red and black': 465, 'human': 466, 'looking': 467, 'playing baseball': 468, 'party': 469, 'chips': 470, 'center': 471, 'cup': 472, 'bikes': 473, 'ski pole': 474, 'suit': 475, 'nighttime': 476, 'stop sign': 477, 'poles': 478, 'poodle': 479, 'bears': 480, 'fork and knife': 481, 'tomatoes': 482, 'electric': 483, 'pine': 484, 'london': 485, 'brown and black': 486, 'vanilla': 487, 'landing': 488, 'orange and white': 489, 'bricks': 490, 'pillow': 491, 'lights': 492, 'safety': 493, 'east': 494, 'women': 495, 'keyboard': 496, 'cloth': 497, 'ice cream': 498, 'on bed': 499, 'background': 500, 'leather': 501, 'indoors': 502, 'spanish': 503, 'glove': 504, 'drywall': 505, 'bacon': 506, 'parking lot': 507, 'brushing teeth': 508, 'multi': 509, 'french fries': 510, 'carriage': 511, 'wiimote': 512, 'mercedes': 513, 'basketball': 514, 'new york': 515, 'forest': 516, 'yellow and blue': 517, '24': 518, 'cargo': 519, 'sandwiches': 520, 'swimming': 521, 'skateboarder': 522, '2013': 523, '34': 524, 'red and blue': 525, '1 way': 526, 'outdoors': 527, 'p': 528, 'new': 529, 'lemon': 530, 'pointing': 531, 'goggles': 532, 'sweater': 533, '22': 534, 'public': 535, 'surf': 536, 'watching': 537, 'church': 538, 'dessert': 539, 'wild': 540, 'stairs': 541, 'obama': 542, 'free': 543, 'wright': 544, 'hot': 545, 'bottle': 546, 'maple': 547, 'asian': 548, 'papers': 549, 'video game': 550, 'shelf': 551, 'lady': 552, 'on desk': 553, 'meat': 554, 'ham': 555, 'bottom': 556, 'audi': 557, 'tennis shoes': 558, 'tracks': 559, 'air canada': 560, 'surfboards': 561, 'fly kite': 562, 'red white': 563, 'japan': 564, 'stripe': 565, '2 feet': 566, 'on right': 567, 'slow': 568, 'bridge': 569, 'cannot tell': 570, 'arm': 571, 'racing': 572, 'paint': 573, 'sauce': 574, 'train station': 575, '27': 576, 'sofa': 577, 'pigeon': 578, 'wire': 579, 'desert': 580, 'curtains': 581, 'daisy': 582, 'beard': 583, 'face': 584, '6:00': 585, '36': 586, 'box': 587, 'news': 588, 'microphone': 589, 'tennis court': 590, 'greyhound': 591, 'potato': 592, 'turkey': 593, 'big': 594, 'handle': 595, 'painting': 596, 'in water': 597, 'on road': 598, 'wine glass': 599, '55': 600, 'scarf': 601, 'playing game': 602, 'fabric': 603, 'towels': 604, 'kiting': 605, 'plates': 606, 'toilet paper': 607, 'onions': 608, 'white and brown': 609, 'blue and yellow': 610, 'tiles': 611, 'baby': 612, 'fire hydrant': 613, 'regular': 614, 'light blue': 615, 'tower': 616, '19': 617, 'double decker': 618, 'trash': 619, 'egg': 620, 'coat': 621, 'rice': 622, 'on wall': 623, '2010': 624, 'granite': 625, 'work': 626, 'african': 627, 'watermelon': 628, 'gray and white': 629, 'toward': 630, 'pepsi': 631, 'pillows': 632, 'star': 633, 'onion': 634, 'knife and fork': 635, 'teal': 636, 'over': 637, 'dark': 638, 'doughnut': 639, 'fast': 640, 'cap': 641, 'soccer ball': 642, 'jumping': 643, 'south': 644, 'size': 645, 'taking picture': 646, 'basil': 647, 'asia': 648, 'curtain': 649, 'family': 650, 'tusks': 651, '33': 652, '31': 653, 'rainbow': 654, 'thai': 655, 'game': 656, 'apartment': 657, 'hill': 658, 'dresser': 659, 'on left': 660, 'cabinet': 661, 'collie': 662, 'garbage': 663, 'california': 664, 'no parking': 665, 'plants': 666, 'crosswalk': 667, 'main': 668, 'jeans': 669, 'behind': 670, 'juice': 671, 'boots': 672, 'cigarette': 673, 'desktop': 674, 'motorbike': 675, 'traffic': 676, 'dining': 677, 'photographer': 678, 'adidas': 679, 'west': 680, 'squares': 681, '29': 682, 'germany': 683, 'harley davidson': 684, 'terrier': 685, 'hydrant': 686, 'cleaning': 687, 'motorcycles': 688, 'shadow': 689, 'helicopter': 690, 'c': 691, 'night time': 692, 'strawberry': 693, 'main course': 694, 'polar bear': 695, 'game controller': 696, 'candles': 697, 'ceramic': 698, 'skateboards': 699, 'plaster': 700, 'purse': 701, 'straw': 702, 'shower': 703, 'cotton': 704, 'batter': 705, 'board': 706, 'grill': 707, 'air france': 708, 'lots': 709, 'checkered': 710, 'drink': 711, 'waiting': 712, 'on building': 713, 'n': 714, 'stainless steel': 715, 'pavement': 716, 'halloween': 717, 'branch': 718, 'fun': 719, 'coffee maker': 720, 'blender': 721, 'black and red': 722, 'talking on phone': 723, 'kid': 724, 'wind': 725, 'freight': 726, 'staring': 727, 'bracelet': 728, 'string': 729, 'necklace': 730, 'yellow and black': 731, 'steel': 732, 'berries': 733, 'to left': 734, 'white and green': 735, 'blue and red': 736, 'library': 737, 'tabby': 738, 'thrown': 739, 'german shepherd': 740, 'chase': 741, 'oval': 742, 'cupcakes': 743, 'lufthansa': 744, \"can't see\": 745, 'boys': 746, 'houses': 747, 'in field': 748, 'diamonds': 749, 'san francisco': 750, 'moving': 751, 'furniture': 752, 'blue white': 753, 'brush': 754, 'smoothie': 755, 'gravel': 756, 'roof': 757, 'foreground': 758, 'woods': 759, 'natural': 760, 'pink and white': 761, 'steak': 762, 'cutting board': 763, 'decoration': 764, 'suv': 765, 'hit ball': 766, 'right side': 767, 'hands': 768, 'eiffel tower': 769, 'midday': 770, 'singing': 771, 'construction': 772, 'newspaper': 773, 'in sky': 774, 'bicycles': 775, '60': 776, 'on plate': 777, 'country': 778, 'words': 779, 'dishwasher': 780, 'lily': 781, 'cutting': 782, 'fireplace': 783, 'saddle': 784, 'headband': 785, 'polar': 786, 'prisoners': 787, 'parasail': 788, 'fire': 789, 'electricity': 790, 'klm': 791, 'protection': 792, 'left side': 793, 'room': 794, 'half': 795, 'mac': 796, 'softball': 797, 'on street': 798, 'boating': 799, 'white black': 800, 'travel': 801, 'go': 802, 'snowy': 803, 'bar': 804, 'downhill': 805, 'santa': 806, 'uniform': 807, 'friends': 808, 'working': 809, 'parade': 810, 'wii controllers': 811, 'top': 812, 'rail': 813, 'red white and blue': 814, '32': 815, 'swinging': 816, 'paddle boarding': 817, 'horizontal': 818, 'heart': 819, 'radio': 820, 'dogs': 821, '365': 822, 'flag': 823, 'pants': 824, 'off white': 825, 'pan': 826, 'triangle': 827, '3 feet': 828, 'cross': 829, 'german': 830, 'men': 831, 'cord': 832, 'honda': 833, 'harley': 834, 'olives': 835, 'court': 836, 'cactus': 837, 'on grass': 838, 'business': 839, 'cups': 840, 'surfer': 841, 'pork': 842, 'no number': 843, 'first': 844, 'raining': 845, 'farm': 846, 'doubles': 847, 'kite string': 848, 'italian': 849, 'serving': 850, 'dress': 851, 'linoleum': 852, 'bush': 853, 'thumb': 854, 'yellow and white': 855, 'frosting': 856, 'lace': 857, 'towards': 858, 'art': 859, 'leopard': 860, 'basket': 861, 'relaxing': 862, 'tennis racquet': 863, 'boats': 864, 'goat': 865, 'traveling': 866, 'stopped': 867, '6:40': 868, '53': 869, 'broadway': 870, 'fedex': 871, 'walk': 872, '1.10': 873, '1:05': 874, 'white and gray': 875, 'parked': 876, 'possibly': 877, 'den': 878, 'not': 879, 'black & white': 880, 'trailer': 881, 'bikini': 882, 'reflection': 883, 'motorola': 884, 'fog': 885, 'photo': 886, 'japanese': 887, 'on floor': 888, 'pajamas': 889, 'kids': 890, 'bow tie': 891, 'partly cloudy': 892, 'mushrooms': 893, 'private': 894, 'mug': 895, 'hit': 896, 'sedan': 897, 'nintendo': 898, 'fair': 899, 'homemade': 900, 'on sidewalk': 901, 'green and yellow': 902, 'soap': 903, 'residence': 904, 'side': 905, 'buildings': 906, 'shut': 907, 'blinds': 908, 'cutting cake': 909, 'jet': 910, 'flat': 911, 'sunrise': 912, 'printed': 913, 'dry': 914, 'pepper': 915, 'older': 916, 'hilly': 917, 'camel': 918, 'pig': 919, '100 year party ct': 920, 'fan': 921, 'signs': 922, 'coke': 923, 'volleyball': 924, 'on beach': 925, 'labrador': 926, 'pickle': 927, '35': 928, 'nice': 929, 'apron': 930, 'stand': 931, 't': 932, 'reins': 933, 'light brown': 934, 'wooden': 935, 'palm trees': 936, 'above': 937, 'numbers': 938, 'hats': 939, 'south park': 940, 'roman numerals': 941, 'playing video game': 942, '45': 943, 'elm': 944, 'red and green': 945, 'france': 946, 'pen': 947, 'bus stop': 948, 'wool': 949, 'cheesecake': 950, 'dairy queen': 951, 'clock tower': 952, 'lancashire united': 953, 'siamese': 954, 'swim trunks': 955, 'love': 956, 'uphill': 957, 'airplanes': 958, 'do not enter': 959, 'pineapple': 960, 'cushion': 961, 'wireless': 962, 'logo': 963, 'pie': 964, 'sparrow': 965, 'hotel': 966, 'sunlight': 967, 'on counter': 968, 'dark brown': 969, 'sprint': 970, 'balance': 971, 'dozens': 972, 'lexus': 973, 'high': 974, 'cowboy': 975, 'salt': 976, '44': 977, 'air force': 978, 'van': 979, '10 feet': 980, 'hello kitty': 981, 'remote control': 982, 'flags': 983, 'multi colored': 984, 'reading': 985, 'children': 986, 'india': 987, 'wii remotes': 988, 'owner': 989, 'helmets': 990, 'florida': 991, 'riding motorcycle': 992, 'green and red': 993, 'bib': 994, 'ducks': 995, 'butter': 996, 'on shelf': 997, 'fell': 998, 'x': 999}\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "import math\nimport os\nimport json\nimport numpy as np\n\n\nimport mindspore.dataset.vision.py_transforms as vision\nimport mindspore.dataset as de\nfrom PIL import Image\nfrom easydict import EasyDict as edict\n\ndef img2tensor(img):\n    # mean = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n    # std = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    transform = edict({\n        \"ToPIL\": vision.ToPIL(),\n        \"Decode\": vision.Decode(),\n        \"Resize\": vision.Resize((512, 512)),\n        \"CenterCrop\": vision.CenterCrop(448),\n        \"ToTensor\":vision.ToTensor(),\n        # \"Rescale\":vision.Rescale(1.0/255.0,0.0),\n        \"Normalize\": vision.Normalize(mean=mean, std=std),\n        \"HWC2CHW\": vision.HWC2CHW(),\n    })\n    # print(\"input image:\",img.shape)\n    img = transform.HWC2CHW(img) / 255\n    # print(\"before normaize\",img)\n    # img = (img - mean[:, None, None]) / std[:, None, None]\n    img = transform.Normalize(img)\n    # print('img after normalize:',img)\n    # print(\"totensor:\",img)\n    # img = [img]\n    # tensor = Tensor(img,mstype.float32)\n    # return tensor\n    return img\n    \ndef create_dataset(batch_size,mode = 'train',drop_remainder=True,q_dict = None,a_dict=None):\n    dataset = VQADataset(mode,q_dict = q_dict,a_dict = a_dict)\n    sampler = DistributedSampler(dataset)\n\n    de_dataset = de.GeneratorDataset(dataset, [\"image\", \"question\",\"label\"],shuffle=False,sampler=sampler)\n    de_dataset = de_dataset.map(operations=img2tensor, input_columns=\"image\", num_parallel_workers=8)\n    # de_dataset = de_dataset.map(operations=None, input_columns=\"question\", num_parallel_workers=8)\n    # de_dataset = de_dataset.map(operations=None, input_columns=\"label\", num_parallel_workers=8)\n    de_dataset = de_dataset.project(columns=['image','question','label'])\n    de_dataset = de_dataset.batch(batch_size, drop_remainder=drop_remainder)\n    \n    return de_dataset\n    \nclass DistributedSampler():\n    \"\"\"\n    sampling the dataset.\n    Args:\n    Returns:\n        num_samples, number of samples.\n    \"\"\"\n    def __init__(self, dataset, rank=0, group_size=1, shuffle=True, seed=0):\n        self.dataset = dataset\n        self.rank = rank\n        self.group_size = group_size\n        self.dataset_length = len(self.dataset)\n        self.num_samples = int(math.ceil(self.dataset_length * 1.0 / self.group_size))\n        self.total_size = self.num_samples * self.group_size\n        self.shuffle = shuffle\n        self.seed = seed\n\n    def __iter__(self):\n        if self.shuffle:\n            self.seed = (self.seed + 1) & 0xffffffff\n            np.random.seed(self.seed)\n            indices = np.random.permutation(self.dataset_length).tolist()\n        else:\n            indices = list(range(len(self.dataset_length)))\n\n        indices += indices[:(self.total_size - len(indices))]\n        indices = indices[self.rank::self.group_size]\n        return iter(indices)\n\n    def __len__(self):\n        return self.num_samples\n\nclass VQADataset:\n    \"\"\"\n    Args:\n    mode: train/val/test\n    cfg: \n    Returns:\n        de_dataset.\n    \"\"\"\n    def __init__(self, mode = \"train\",q_dict =None,a_dict = None):\n        super(VQADataset, self).__init__()\n        self.Resize =  vision.Resize((512, 512))\n        self.CenterCrop =  vision.CenterCrop(448)\n        self.images = []   # image paths\n        self.questions = []   #  questions \u5e94\u8be5\u662f\u5df2\u7ecf\u8f6c\u6362\u6210one-hot\u7684\u7f16\u7801\n        self.answers = []   # answers   \u5bf9\u5e94\u7684\u6b63\u786e\u7b54\u6848\n        self.q_dict = q_dict\n        self.a_dict = a_dict\n        ann = {}\n        ques = {}\n        image_path = ''\n        if mode == \"train\":\n            ann = json.load(open(train.annotation,'r'))\n            ques = json.load(open(train.question,'r'))\n            image_path = train.image\n        elif mode == 'test':\n            ann = json.load(open(test.annotation,'r'))\n            ques = json.load(open(test.question,'r'))\n            image_path = test.image\n        else:\n            ann = json.load(open(val.annotation,'r'))\n            ques = json.load(open(val.question,'r'))\n            image_path = val.image\n        \n        self.question_dict = {item['question_id']:item['question'] for item in ques['questions']}\n        annotations = ann['annotations']\n        img_not_exist_count = 0\n        for index,item in enumerate(annotations):\n            img_path = os.path.join(image_path,\"COCO_{0}2014_{1}.jpg\".format(mode,str(item['image_id']).zfill(12)))\n            if not os.path.exists(img_path):  # filter non-existing image\n                img_not_exist_count += 1\n                continue\n            \n            answers = item['answers']     # filter blank answer\n            if len(answers) == 0:\n                continue\n            \n            election = dict() \n            for index,ans in enumerate(answers):\n                if ans['answer_confidence'] == 'yes':\n                    election[ans['answer']] = election.get(ans['answer'],0)+1\n            if not election:\n                continue\n                \n            elected = max(election, key=election.get)\n            if not elected in self.a_dict:\n                continue\n            \n            if mode == 'val':\n                sentence = self.question_dict[item['question_id']]\n                sentence = process_sentence(sentence)\n                sentence = sentence.split()\n                x = 0\n                for word in sentence:\n                    if not word in self.q_dict:\n                        x = 1\n                        break;\n                if x == 1:\n                    continue\n\n            self.answers.append(elected)\n            self.images.append(img_path)\n            self.questions.append(item['question_id'])\n            \n\n    def __getitem__(self, index):\n        image = Image.open(self.images[index]).convert('RGB')\n        image = self.Resize(image)\n        image = self.CenterCrop(image)\n        # image = self.images[index]\n\n        question_str = self.question_dict[self.questions[index]]\n        question = process_sentence(question_str)\n        question = question.split()\n        question = convert_sentence_to_vec(question,self.q_dict)\n\n#         answer = self.a_dict[self.answers[index]]\n        answer = np.zeros(1000,dtype=np.float32)\n        answer[self.a_dict[self.answers[index]]] = 1\n        return image, question,answer\n\n    def __len__(self):\n        return len(self.questions)\n", "metadata": {"trusted": true}, "execution_count": 58, "outputs": []}, {"cell_type": "markdown", "source": "### 2.4 \u6784\u5efa\u8bcd\u5411\u91cf", "metadata": {}}, {"cell_type": "code", "source": "# #\u4e0d\u7528\u8dd1\u8fd9\u6bb5\n# #construct one hot vector\n# all_question_vector=[]\n# for idx,question in enumerate(train_questions):\n#     count = 0\n#     question_vector = []\n#     for word in question:\n#         count = count + 1\n#         if count > 10:\n#             break\n#         else:\n#             q_emb = np.zeros((len(question_key) + 1), dtype='int32')\n#             q_emb[question_key[word]] = 1\n#             question_vector.append(q_emb)\n#     while count < 10:\n#         padding = np.zeros((len(question_key) + 1), dtype='int32')\n#         question_vector.append(padding)\n#         count = count + 1\n#     all_question_vector.append(question_vector)", "metadata": {}, "execution_count": 9, "outputs": []}, {"cell_type": "code", "source": "#convert word to idx\nall_question_idx = []\nfor question in train_questions:\n    all_question_idx.append(convert_sentence_to_vec(question, question_key))\nall_question_idx", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 9, "outputs": [{"execution_count": 9, "output_type": "execute_result", "data": {"text/plain": "[[5, 2, 242, 1035, 7, 10, 2857, 13, 0, 0],\n [4, 3, 2, 16, 31, 0, 0, 0, 0, 0],\n [4, 3, 2, 28, 20, 0, 0, 0, 0, 0],\n [148, 162, 2134, 46, 447, 7, 2, 196, 0, 0],\n [22, 3, 2, 166, 0, 0, 0, 0, 0, 0],\n [3, 2, 61, 288, 259, 0, 0, 0, 0, 0],\n [4, 13, 136, 3, 1490, 19, 2, 212, 0, 0],\n [5, 34, 65, 2858, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 37, 0, 0, 0, 0, 0],\n [4, 5, 2, 739, 53, 8, 0, 0, 0, 0],\n [4, 26, 9, 47, 3, 69, 0, 0, 0, 0],\n [4, 3, 2, 740, 8, 2, 255, 42, 0, 0],\n [4, 740, 3, 8, 2, 255, 42, 0, 0, 0],\n [3, 6, 708, 0, 0, 0, 0, 0, 0, 0],\n [11, 12, 2859, 5, 14, 0, 0, 0, 0, 0],\n [87, 162, 1109, 94, 0, 0, 0, 0, 0, 0],\n [3, 14, 10, 1734, 7, 101, 9, 2, 114, 0],\n [3, 2, 272, 649, 0, 0, 0, 0, 0, 0],\n [3, 2, 115, 470, 121, 2135, 0, 0, 0, 0],\n [4, 13, 3, 2, 58, 134, 0, 0, 0, 0],\n [3, 2, 44, 779, 7, 6, 18, 897, 0, 0],\n [4, 13, 5, 2, 2860, 7, 2, 1036, 0, 0],\n [3, 6, 10, 117, 250, 92, 0, 0, 0, 0],\n [11, 12, 1735, 15, 6, 44, 25, 0, 0, 0],\n [4, 13, 3, 2, 63, 0, 0, 0, 0, 0],\n [4, 3, 2, 1212, 16, 2861, 19, 2, 1212, 35],\n [104, 30, 413, 10, 1736, 369, 30, 2862, 6, 48],\n [4, 3, 2, 16, 80, 8, 0, 0, 0, 0],\n [4, 3, 163, 7, 2, 191, 0, 0, 0, 0],\n [11, 12, 681, 5, 8, 2, 78, 0, 0, 0],\n [3, 6, 448, 2863, 0, 0, 0, 0, 0, 0],\n [4, 121, 449, 5, 182, 19, 2, 63, 0, 0],\n [11, 265, 15, 6, 169, 79, 0, 0, 0, 0],\n [54, 88, 3, 2, 28, 38, 2, 197, 7, 0],\n [22, 3, 2, 57, 53, 0, 0, 0, 0, 0],\n [4, 3, 2, 2136, 16, 7, 2, 1213, 260, 0],\n [11, 12, 299, 5, 7, 2, 18, 0, 0, 0],\n [54, 121, 5, 1491, 65, 0, 0, 0, 0, 0],\n [11, 12, 17, 1492, 25, 10, 273, 0, 0, 0],\n [11, 12, 373, 29, 30, 55, 0, 0, 0, 0],\n [4, 3, 1342, 2, 709, 0, 0, 0, 0, 0],\n [4, 13, 134, 3, 6, 16, 20, 0, 0, 0],\n [3, 10, 28, 20, 10, 2137, 1493, 0, 0, 0],\n [11, 12, 187, 243, 5, 14, 0, 0, 0, 0],\n [4, 13, 3, 2, 101, 164, 0, 0, 0, 0],\n [22, 15, 6, 18, 513, 251, 0, 0, 0, 0],\n [15, 2, 188, 79, 125, 0, 0, 0, 0, 0],\n [3, 6, 40, 2, 334, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 289, 0, 0, 0, 0, 0],\n [279, 7, 2, 116, 1494, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 57, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 321, 244, 0, 0, 0, 0],\n [189, 192, 36, 620, 0, 0, 0, 0, 0, 0],\n [4, 111, 3, 83, 300, 0, 0, 0, 0, 0],\n [5, 30, 1110, 9, 198, 0, 0, 0, 0, 0],\n [3, 2, 209, 7, 1737, 0, 0, 0, 0, 0],\n [68, 5, 594, 9, 2, 395, 471, 0, 0, 0],\n [4, 3, 2, 125, 8, 2, 64, 0, 0, 0],\n [4, 33, 9, 129, 3, 6, 0, 0, 0, 0],\n [4, 13, 3, 2, 2864, 0, 0, 0, 0, 0],\n [4, 327, 3, 65, 0, 0, 0, 0, 0, 0],\n [3, 14, 188, 0, 0, 0, 0, 0, 0, 0],\n [3, 2, 1343, 384, 572, 19, 1738, 236, 2, 274],\n [4, 13, 126, 5, 2, 226, 145, 2865, 0, 0],\n [4, 3, 2, 1495, 9, 2, 385, 0, 0, 0],\n [3, 6, 10, 741, 292, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 1111, 0, 0, 0, 0, 0],\n [5, 14, 1739, 1214, 8, 2, 63, 0, 0, 0],\n [15, 49, 25, 227, 130, 8, 46, 1496, 8, 46],\n [4, 3, 2, 111, 23, 17, 5, 65, 0, 0],\n [3, 1344, 2866, 498, 573, 0, 0, 0, 0, 0],\n [3, 6, 16, 20, 151, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 38, 0, 0, 0, 0, 0],\n [4, 13, 52, 3, 6, 16, 20, 0, 0, 0],\n [4, 3, 2, 406, 8, 2, 396, 0, 0, 0],\n [4, 2867, 61, 3, 7, 2, 175, 0, 0, 0],\n [4, 3, 2, 42, 31, 0, 0, 0, 0, 0],\n [3, 6, 621, 0, 0, 0, 0, 0, 0, 0],\n [3, 2, 71, 710, 2138, 0, 0, 0, 0, 0],\n [3, 6, 10, 450, 0, 0, 0, 0, 0, 0],\n [11, 12, 145, 5, 40, 2, 84, 101, 9, 2],\n [4, 3, 2, 13, 9, 2, 44, 0, 0, 0],\n [4, 3, 2, 48, 1037, 0, 0, 0, 0, 0],\n [11, 12, 711, 5, 8, 2, 48, 0, 0, 0],\n [3, 6, 10, 92, 48, 0, 0, 0, 0, 0],\n [3, 2, 304, 1215, 0, 0, 0, 0, 0, 0],\n [4, 15, 2, 483, 96, 85, 1345, 109, 8, 2],\n [11, 256, 5, 14, 0, 0, 0, 0, 0, 0],\n [3, 2, 16, 288, 10, 18, 9, 1497, 0, 0],\n [68, 5, 23, 17, 8, 158, 574, 970, 0, 0],\n [15, 2, 154, 25, 1740, 314, 0, 0, 0, 0],\n [3, 2, 98, 53, 1741, 8, 2, 154, 0, 0],\n [4, 3, 2, 472, 62, 9, 0, 0, 0, 0],\n [4, 111, 3, 83, 300, 0, 0, 0, 0, 0],\n [4, 266, 3, 2, 60, 0, 0, 0, 0, 0],\n [5, 34, 1498, 0, 0, 0, 0, 0, 0, 0],\n [4, 155, 5, 2, 548, 19, 2, 74, 20, 0],\n [4, 13, 3, 2, 196, 0, 0, 0, 0, 0],\n [3, 49, 65, 10, 70, 0, 0, 0, 0, 0],\n [4, 514, 5, 142, 0, 0, 0, 0, 0, 0],\n [4, 3, 8, 2, 58, 52, 0, 0, 0, 0],\n [3, 14, 10, 1112, 8, 82, 681, 0, 0, 0],\n [4, 423, 3, 142, 0, 0, 0, 0, 0, 0],\n [4, 3, 2139, 230, 13, 8, 2, 78, 0, 0],\n [3, 14, 10, 2868, 9, 243, 7, 6, 18, 0],\n [11, 12, 971, 5, 14, 0, 0, 0, 0, 0],\n [4, 116, 3, 8, 6, 549, 0, 0, 0, 0],\n [4, 5, 2, 120, 473, 8, 2, 71, 0, 0],\n [4, 3, 2, 2869, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 42, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 98, 7, 2, 2870, 305, 0],\n [4, 13, 3, 2, 210, 185, 0, 0, 0, 0],\n [3, 14, 10, 2140, 7, 2, 66, 0, 0, 0],\n [4, 13, 3, 2, 1742, 8, 2, 289, 0, 0],\n [5, 2, 397, 244, 2, 133, 13, 0, 0, 0],\n [3, 2, 2871, 1743, 2872, 8, 0, 0, 0, 0],\n [11, 12, 2873, 2874, 5, 7, 6, 18, 0, 0],\n [3, 2, 56, 328, 0, 0, 0, 0, 0, 0],\n [5, 23, 299, 24, 329, 65, 1216, 0, 0, 0],\n [4, 111, 5, 34, 65, 0, 0, 0, 0, 0],\n [4, 3, 2, 13, 9, 2, 188, 0, 0, 0],\n [4, 13, 3, 2, 122, 0, 0, 0, 0, 0],\n [4, 33, 9, 322, 3, 7, 2, 550, 0, 0],\n [3, 2, 193, 7, 2, 530, 472, 0, 0, 0],\n [4, 650, 1744, 3, 10, 1217, 9, 6, 385, 0],\n [3, 14, 10, 127, 0, 0, 0, 0, 0, 0],\n [11, 12, 1346, 5, 14, 0, 0, 0, 0, 0],\n [11, 12, 315, 41, 36, 131, 0, 0, 0, 0],\n [4, 13, 5, 2, 256, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 515, 0, 0, 0, 0, 0],\n [4, 5, 2, 414, 8, 2, 101, 9, 2, 45],\n [3, 2, 45, 857, 499, 0, 0, 0, 0, 0],\n [4, 1745, 6, 742, 0, 0, 0, 0, 0, 0],\n [4, 370, 9, 280, 5, 237, 2, 315, 0, 0],\n [4, 3, 2, 118, 9, 6, 1113, 45, 0, 0],\n [4, 13, 3, 2, 45, 742, 0, 0, 0, 0],\n [3, 2, 13, 9, 2, 146, 2141, 0, 0, 0],\n [68, 3, 2, 154, 1746, 19, 2, 575, 0, 0],\n [4, 202, 3, 8, 2, 306, 817, 99, 3, 8],\n [4, 15, 2, 1747, 48, 595, 0, 0, 0, 0],\n [4, 5, 972, 898, 398, 123, 2, 386, 0, 0],\n [3, 14, 10, 484, 0, 0, 0, 0, 0, 0],\n [4, 531, 3, 2, 61, 163, 50, 0, 0, 0],\n [11, 149, 3, 2, 98, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 45, 0, 0, 0, 0, 0],\n [4, 3, 49, 8, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 210, 185, 0, 0, 0, 0, 0],\n [3, 6, 10, 407, 103, 0, 0, 0, 0, 0],\n [4, 3, 2, 132, 62, 108, 9, 0, 0, 0],\n [3, 6, 32, 1114, 1499, 0, 0, 0, 0, 0],\n [5, 34, 107, 1115, 0, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 27, 0, 0, 0],\n [11, 12, 17, 5, 14, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 1038, 9, 6, 292, 0, 0],\n [11, 12, 191, 1347, 5, 14, 0, 0, 0, 0],\n [4, 252, 3, 1748, 0, 0, 0, 0, 0, 0],\n [11, 12, 972, 145, 5, 8, 2, 451, 0, 0],\n [4, 3, 2, 227, 2875, 2142, 9, 2, 1218, 138],\n [3, 14, 10, 175, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 532, 61, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 61, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 184, 234, 0, 0, 0, 0],\n [3, 2, 76, 353, 0, 0, 0, 0, 0, 0],\n [7, 4, 33, 9, 1500, 5, 2, 1749, 682, 0],\n [99, 5, 119, 2, 44, 0, 0, 0, 0, 0],\n [3, 14, 43, 2876, 8, 2, 60, 0, 0, 0],\n [3, 2, 424, 10, 2877, 424, 0, 0, 0, 0],\n [11, 12, 2143, 5, 434, 0, 0, 0, 0, 0],\n [3, 14, 173, 7, 2, 76, 0, 0, 0, 0],\n [11, 307, 3, 6, 61, 0, 0, 0, 0, 0],\n [3, 6, 27, 2878, 0, 0, 0, 0, 0, 0],\n [22, 89, 18, 75, 9, 2, 238, 0, 0, 0],\n [4, 293, 3, 2, 899, 0, 0, 0, 0, 0],\n [3, 14, 374, 7, 2, 66, 0, 0, 0, 0],\n [11, 12, 160, 5, 14, 0, 0, 0, 0, 0],\n [3, 2, 16, 20, 305, 0, 0, 0, 0, 0],\n [68, 29, 34, 500, 170, 1750, 0, 0, 0, 0],\n [3, 2, 56, 294, 0, 0, 0, 0, 0, 0],\n [3, 2, 415, 8, 2, 64, 10, 416, 24, 10],\n [3, 2, 712, 7, 101, 9, 2, 220, 0, 0],\n [4, 169, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 3, 7, 2, 221, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 306, 2144, 0, 0, 0, 0],\n [4, 26, 9, 301, 5, 2, 346, 8, 0, 0],\n [99, 3, 163, 6, 222, 0, 0, 0, 0, 0],\n [68, 3, 2, 295, 651, 2879, 0, 0, 0, 0],\n [4, 26, 9, 42, 3, 6, 0, 0, 0, 0],\n [4, 155, 3, 2, 42, 0, 0, 0, 0, 0],\n [4, 3, 2, 42, 53, 8, 0, 0, 0, 0],\n [4, 13, 3, 2, 306, 1219, 0, 0, 0, 0],\n [3, 2, 2880, 8, 2, 900, 7, 1116, 0, 0],\n [5, 2, 17, 2881, 0, 0, 0, 0, 0, 0],\n [22, 3, 2, 126, 375, 86, 0, 0, 0, 0],\n [4, 1501, 514, 5, 7, 2, 27, 0, 0, 0],\n [3, 2, 57, 276, 683, 0, 0, 0, 0, 0],\n [3, 2, 1751, 2145, 2, 136, 0, 0, 0, 0],\n [4, 26, 9, 818, 3, 49, 290, 0, 0, 0],\n [3, 2, 16, 203, 0, 0, 0, 0, 0, 0],\n [4, 302, 3, 51, 0, 0, 0, 0, 0, 0],\n [15, 2, 576, 41, 361, 19, 36, 2146, 0, 0],\n [22, 3, 2, 272, 7, 2, 76, 0, 0, 0],\n [3, 6, 10, 295, 1502, 0, 0, 0, 0, 0],\n [29, 30, 10, 1752, 7, 2, 76, 0, 0, 0],\n [11, 12, 684, 135, 5, 14, 0, 0, 0, 0],\n [4, 1039, 281, 105, 6, 223, 0, 0, 0, 0],\n [4, 3, 2, 98, 20, 0, 0, 0, 0, 0],\n [4, 26, 9, 354, 3, 2, 35, 1220, 0, 0],\n [11, 12, 238, 0, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 8, 2, 78, 119, 0, 0],\n [3, 2, 596, 622, 105, 24, 140, 0, 0, 0],\n [22, 3, 2, 61, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 27, 51, 104, 36, 7, 59, 2882],\n [68, 1348, 2, 16, 858, 7, 6, 26, 9, 261],\n [4, 3, 2, 16, 38, 0, 0, 0, 0, 0],\n [3, 2, 16, 290, 10, 152, 0, 0, 0, 0],\n [15, 6, 16, 79, 1117, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 181, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 362, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 743, 0, 0, 0, 0, 0],\n [4, 551, 3, 2, 28, 119, 2, 347, 0, 0],\n [3, 6, 199, 0, 0, 0, 0, 0, 0, 0],\n [3, 95, 20, 10, 2883, 623, 0, 0, 0, 0],\n [4, 3, 2, 28, 31, 0, 0, 0, 0, 0],\n [3, 2, 35, 20, 10, 2884, 0, 0, 0, 0],\n [4, 5, 34, 65, 0, 0, 0, 0, 0, 0],\n [5, 23, 859, 0, 0, 0, 0, 0, 0, 0],\n [5, 2, 262, 199, 0, 0, 0, 0, 0, 0],\n [15, 6, 146, 79, 407, 0, 0, 0, 0, 0],\n [4, 3, 2, 132, 62, 9, 0, 0, 0, 0],\n [4, 3, 2, 450, 8, 2, 282, 0, 0, 0],\n [5, 14, 435, 8, 2, 77, 0, 0, 0, 0],\n [780, 24, 1349, 32, 0, 0, 0, 0, 0, 0],\n [4, 26, 9, 18, 3, 6, 0, 0, 0, 0],\n [99, 5, 7, 2, 282, 0, 0, 0, 0, 0],\n [5, 2, 17, 7, 2, 101, 1040, 624, 973, 1503],\n [4, 70, 5, 34, 65, 0, 0, 0, 0, 0],\n [11, 12, 275, 5, 69, 0, 0, 0, 0, 0],\n [4, 3, 485, 2, 78, 0, 0, 0, 0, 0],\n [148, 95, 323, 335, 10, 194, 153, 0, 0, 0],\n [3, 2, 106, 348, 105, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 280, 0, 0, 0, 0, 0],\n [4, 202, 3, 8, 2, 781, 52, 0, 0, 0],\n [4, 3, 2, 245, 685, 8, 0, 0, 0, 0],\n [3, 2, 35, 1754, 190, 2885, 0, 0, 0, 0],\n [3, 21, 10, 399, 8, 2, 246, 0, 0, 0],\n [3, 14, 10, 533, 0, 0, 0, 0, 0, 0],\n [11, 12, 155, 3, 2, 1755, 425, 0, 0, 0],\n [4, 3, 2, 118, 9, 2, 531, 8, 2, 534],\n [498, 2, 121, 247, 8, 6, 2886, 253, 1041, 686],\n [4, 13, 3, 2, 116, 552, 0, 0, 0, 0],\n [4, 13, 3, 2, 550, 0, 0, 0, 0, 0],\n [4, 3, 6, 167, 50, 0, 0, 0, 0, 0],\n [4, 3, 7, 2, 387, 254, 239, 2, 975, 0],\n [4, 37, 2887, 2, 47, 7, 2, 1756, 597, 40],\n [11, 12, 744, 5, 74, 0, 0, 0, 0, 0],\n [3, 2, 782, 860, 107, 105, 24, 375, 140, 0],\n [3, 6, 10, 463, 32, 0, 0, 0, 0, 0],\n [3, 14, 43, 188, 0, 0, 0, 0, 0, 0],\n [3, 2, 18, 7, 161, 96, 85, 0, 0, 0],\n [4, 3, 1221, 105, 86, 2, 78, 323, 123, 2],\n [4, 33, 9, 1042, 3, 8, 2, 60, 0, 0],\n [4, 13, 3, 2, 63, 0, 0, 0, 0, 0],\n [3, 6, 10, 228, 1757, 0, 0, 0, 0, 0],\n [3, 2, 18, 625, 0, 0, 0, 0, 0, 0],\n [54, 250, 15, 2, 48, 109, 19, 376, 0, 0],\n [4, 26, 9, 204, 3, 2, 16, 20, 0, 0],\n [4, 3, 2, 202, 8, 2, 63, 0, 0, 0],\n [3, 6, 200, 53, 8, 10, 63, 0, 0, 0],\n [179, 2, 67, 36, 2888, 1350, 0, 0, 0, 0],\n [4, 5, 2, 626, 17, 20, 8, 158, 713, 0],\n [3, 21, 137, 0, 0, 0, 0, 0, 0, 0],\n [3, 2, 129, 53, 8, 10, 209, 0, 0, 0],\n [3, 2, 92, 434, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 28, 163, 7, 2, 76, 0, 0],\n [3, 2, 154, 195, 0, 0, 0, 0, 0, 0],\n [4, 13, 5, 82, 205, 0, 0, 0, 0, 0],\n [4, 3, 7, 2, 58, 388, 0, 0, 0, 0],\n [4, 302, 3, 2, 16, 38, 0, 0, 0, 0],\n [11, 12, 2889, 5, 8, 2, 330, 0, 0, 0],\n [3, 49, 316, 745, 0, 0, 0, 0, 0, 0],\n [3, 49, 10, 98, 0, 0, 0, 0, 0, 0],\n [3, 49, 20, 10, 861, 0, 0, 0, 0, 0],\n [4, 3, 7, 2, 58, 88, 0, 0, 0, 0],\n [3, 6, 10, 208, 0, 0, 0, 0, 0, 0],\n [4, 147, 3, 142, 8, 2, 52, 9, 2, 16],\n [3, 2, 35, 91, 40, 2, 212, 0, 0, 0],\n [4, 6, 98, 3, 819, 0, 0, 0, 0, 0],\n [4, 3, 7, 2, 781, 388, 0, 0, 0, 0],\n [3, 2, 35, 8, 2, 462, 64, 9, 2, 93],\n [11, 12, 2890, 15, 2, 98, 25, 7, 82, 687],\n [4, 3, 40, 2, 84, 9, 2, 1758, 0, 0],\n [11, 12, 206, 5, 100, 7, 2, 66, 0, 0],\n [3, 21, 1043, 19, 500, 324, 8, 6, 81, 0],\n [3, 6, 28, 64, 820, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 18, 0, 0, 0],\n [3, 21, 862, 0, 0, 0, 0, 0, 0, 0],\n [4, 3, 211, 40, 2, 325, 9, 2, 27, 0],\n [4, 202, 3, 8, 2, 77, 0, 0, 0, 0],\n [11, 12, 206, 0, 0, 0, 0, 0, 0, 0],\n [4, 26, 9, 47, 3, 62, 7, 59, 448, 102],\n [3, 14, 1044, 37, 100, 51, 901, 10, 166, 0],\n [5, 14, 121, 426, 17, 7, 2, 18, 0, 0],\n [4, 26, 9, 261, 3, 2, 187, 53, 7, 0],\n [15, 6, 447, 172, 342, 0, 0, 0, 0, 0],\n [15, 6, 139, 1045, 355, 976, 9, 1759, 0, 0],\n [4, 90, 3, 8, 2, 101, 84, 9, 2, 44],\n [3, 2, 44, 285, 0, 0, 0, 0, 0, 0],\n [3, 2, 150, 7, 10, 334, 0, 0, 0, 0],\n [89, 1351, 167, 19, 281, 2, 863, 0, 0, 0],\n [4, 26, 9, 32, 5, 2, 17, 94, 7, 0],\n [4, 13, 3, 2, 226, 126, 0, 0, 0, 0],\n [5, 2, 308, 2147, 19, 319, 0, 0, 0, 0],\n [22, 3, 2, 85, 598, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 226, 126, 51, 41, 36, 131],\n [3, 2, 126, 1760, 226, 19, 2148, 0, 0, 0],\n [4, 3, 248, 190, 117, 9, 2, 39, 0, 0],\n [3, 21, 10, 137, 81, 0, 0, 0, 0, 0],\n [3, 14, 10, 18, 317, 8, 2, 77, 0, 0],\n [3, 2, 65, 0, 0, 0, 0, 0, 0, 0],\n [3, 14, 188, 7, 2, 93, 0, 0, 0, 0],\n [4, 70, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 267, 3, 2149, 8, 2, 472, 0, 0, 0],\n [7, 4, 252, 5, 34, 65, 0, 0, 0, 0],\n [4, 3, 746, 0, 0, 0, 0, 0, 0, 0],\n [11, 12, 714, 5, 8, 2, 60, 0, 0, 0],\n [3, 2, 71, 740, 2891, 24, 1761, 0, 0, 0],\n [3, 6, 7, 486, 0, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 208, 0, 0, 0],\n [4, 5, 2, 17, 535, 50, 0, 0, 0, 0],\n [11, 12, 255, 296, 5, 14, 7, 2, 18, 0],\n [87, 10, 715, 144, 75, 108, 9, 2, 255, 42],\n [4, 13, 5, 2, 349, 0, 0, 0, 0, 0],\n [3, 6, 10, 627, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 44, 7, 2, 18, 0, 0],\n [3, 6, 44, 400, 9, 10, 309, 652, 0, 0],\n [4, 3, 2, 436, 13, 0, 0, 0, 0, 0],\n [3, 2, 126, 8, 0, 0, 0, 0, 0, 0],\n [3, 2, 780, 902, 0, 0, 0, 0, 0, 0],\n [3, 2, 231, 716, 0, 0, 0, 0, 0, 0],\n [11, 12, 599, 9, 553, 427, 3, 100, 0, 0],\n [5, 14, 1762, 7, 6, 18, 0, 0, 0, 0],\n [4, 13, 3, 2, 2150, 222, 0, 0, 0, 0],\n [5, 23, 283, 24, 1504, 0, 0, 0, 0, 0],\n [3, 6, 10, 407, 45, 0, 0, 0, 0, 0],\n [3, 21, 10, 353, 81, 0, 0, 0, 0, 0],\n [4, 32, 89, 6, 75, 7, 0, 0, 0, 0],\n [11, 12, 232, 5, 14, 0, 0, 0, 0, 0],\n [11, 12, 232, 5, 80, 0, 0, 0, 0, 0],\n [5, 2, 198, 86, 2, 133, 628, 0, 0, 0],\n [4, 277, 9, 2, 501, 5, 34, 7, 0, 0],\n [4, 26, 9, 112, 5, 7, 2, 66, 0, 0],\n [3, 2, 57, 356, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 136, 0, 0, 0, 0, 0],\n [5, 117, 9, 2, 1118, 247, 10, 2892, 0, 0],\n [5, 14, 112, 7, 6, 128, 0, 0, 0, 0],\n [5, 23, 2893, 8, 10, 653, 0, 0, 0, 0],\n [4, 3, 2, 428, 8, 2, 48, 1352, 0, 0],\n [4, 13, 3, 2, 48, 0, 0, 0, 0, 0],\n [15, 49, 500, 10, 821, 204, 0, 0, 0, 0],\n [15, 2, 16, 172, 19, 36, 20, 10, 577, 654],\n [15, 6, 79, 102, 21, 3, 86, 59, 149, 1119],\n [5, 14, 168, 535, 19, 1763, 0, 0, 0, 0],\n [4, 3, 2, 35, 377, 0, 0, 0, 0, 0],\n [29, 30, 343, 6, 3, 10, 536, 250, 19, 2151],\n [4, 3, 2, 35, 7, 120, 31, 0, 0, 0],\n [11, 12, 113, 5, 80, 0, 0, 0, 0, 0],\n [4, 155, 5, 8, 2, 58, 903, 0, 0, 0],\n [4, 13, 3, 2, 134, 0, 0, 0, 0, 0],\n [3, 6, 59, 2894, 252, 0, 0, 0, 0, 0],\n [4, 3, 2, 324, 429, 0, 0, 0, 0, 0],\n [3, 2, 238, 268, 263, 24, 213, 2, 747, 0],\n [4, 3, 2, 114, 62, 9, 0, 0, 0, 0],\n [22, 3, 2, 37, 83, 1222, 0, 0, 0, 0],\n [4, 3, 485, 2, 132, 0, 0, 0, 0, 0],\n [5, 14, 711, 0, 0, 0, 0, 0, 0, 0],\n [3, 2, 747, 2, 133, 13, 455, 59, 150, 0],\n [3, 2, 124, 203, 190, 94, 0, 0, 0, 0],\n [22, 3, 2, 42, 356, 0, 0, 0, 0, 0],\n [4, 37, 3, 69, 0, 0, 0, 0, 0, 0],\n [3, 2, 202, 8, 2, 77, 235, 207, 456, 24],\n [3, 6, 7, 486, 0, 0, 0, 0, 0, 0],\n [4, 3, 90, 2152, 31, 0, 0, 0, 0, 0],\n [11, 12, 578, 5, 142, 0, 0, 0, 0, 0],\n [4, 125, 302, 3, 7, 6, 223, 0, 0, 0],\n [15, 6, 220, 25, 2153, 9, 2895, 0, 0, 0],\n [148, 2, 28, 516, 0, 0, 0, 0, 0, 0],\n [5, 183, 9, 23, 17, 94, 0, 0, 0, 0],\n [4, 26, 9, 129, 3, 51, 0, 0, 0, 0],\n [4, 5, 34, 288, 47, 108, 9, 7, 2, 2896],\n [4, 3, 2, 336, 9, 2, 42, 0, 0, 0],\n [4, 3, 2, 42, 377, 0, 0, 0, 0, 0],\n [22, 5, 34, 0, 0, 0, 0, 0, 0, 0],\n [3, 14, 10, 2897, 1764, 7, 2, 27, 0, 0],\n [3, 2, 169, 554, 1765, 0, 0, 0, 0, 0],\n [4, 3, 8, 2, 63, 0, 0, 0, 0, 0],\n [4, 33, 9, 125, 302, 3, 83, 464, 0, 0],\n [11, 149, 5, 2, 160, 0, 0, 0, 0, 0],\n [3, 117, 9, 2, 160, 91, 40, 2, 212, 0],\n [4, 13, 5, 2, 296, 2898, 0, 0, 0, 0],\n [3, 2, 42, 8, 2, 64, 331, 0, 0, 0],\n [11, 12, 194, 2154, 5, 14, 0, 0, 0, 0],\n [4, 3, 2, 166, 31, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 306, 134, 0, 0, 0, 0],\n [3, 6, 28, 53, 8, 2, 487, 0, 0, 0],\n [11, 12, 2155, 2156, 2, 579, 0, 0, 0, 0],\n [3, 2, 28, 20, 10, 2157, 0, 0, 0, 0],\n [4, 67, 9, 81, 3, 21, 0, 0, 0, 0],\n [4, 2899, 3, 2, 146, 282, 0, 0, 0, 0],\n [11, 12, 337, 5, 7, 2, 76, 0, 0, 0],\n [4, 13, 3, 2, 2900, 0, 0, 0, 0, 0],\n [3, 6, 977, 2901, 0, 0, 0, 0, 0, 0],\n [3, 6, 904, 24, 1766, 0, 0, 0, 0, 0],\n [3, 2, 415, 416, 24, 399, 0, 0, 0, 0],\n [3, 2, 35, 7, 684, 1046, 350, 0, 0, 0],\n [4, 116, 3, 7, 2, 200, 0, 0, 0, 0],\n [87, 162, 1109, 94, 6, 223, 656, 0, 0, 0],\n [4, 26, 9, 71, 3, 6, 0, 0, 0, 0],\n [22, 3, 2, 71, 86, 0, 0, 0, 0, 0],\n [11, 12, 101, 314, 29, 30, 55, 7, 326, 224],\n [3, 14, 2, 2902, 50, 10, 2903, 0, 0, 0],\n [5, 23, 17, 10, 555, 0, 0, 0, 0, 0],\n [4, 3, 2, 57, 269, 8, 0, 0, 0, 0],\n [4, 39, 5, 69, 0, 0, 0, 0, 0, 0],\n [4, 13, 52, 15, 2, 16, 25, 8, 0, 0],\n [4, 13, 134, 3, 2, 28, 8, 2, 74, 20],\n [3, 2, 175, 159, 0, 0, 0, 0, 0, 0],\n [22, 3, 2, 417, 0, 0, 0, 0, 0, 0],\n [3, 6, 16, 905, 0, 0, 0, 0, 0, 0],\n [4, 26, 9, 465, 5, 123, 2, 301, 0, 0],\n [5, 2, 17, 7, 2, 66, 2904, 0, 0, 0],\n [11, 12, 39, 5, 7, 6, 27, 0, 0, 0],\n [4, 37, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 347, 0, 0, 0, 0, 0],\n [5, 2, 113, 2905, 19, 2, 822, 0, 0, 0],\n [4, 13, 3, 2, 600, 9, 2, 229, 0, 0],\n [5, 14, 289, 7, 6, 18, 0, 0, 0, 0],\n [4, 70, 5, 34, 65, 0, 0, 0, 0, 0],\n [11, 149, 3, 2, 35, 0, 0, 0, 0, 0],\n [3, 6, 10, 864, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 657, 16, 8, 10, 224, 0, 0],\n [4, 15, 6, 58, 688, 0, 0, 0, 0, 0],\n [4, 3, 823, 8, 2, 181, 0, 0, 0, 0],\n [11, 12, 174, 5, 100, 7, 6, 93, 0, 0],\n [15, 2, 16, 25, 8, 10, 134, 0, 0, 0],\n [3, 14, 10, 210, 185, 7, 6, 27, 0, 0],\n [11, 12, 629, 5, 452, 8, 0, 0, 0, 0],\n [4, 13, 3, 2, 362, 0, 0, 0, 0, 0],\n [5, 23, 906, 0, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 214, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 77, 0, 0, 0, 0, 0],\n [4, 202, 3, 8, 2, 580, 0, 0, 0, 0],\n [11, 12, 17, 5, 53, 140, 0, 0, 0, 0],\n [3, 14, 10, 115, 8, 2, 437, 0, 0, 0],\n [4, 13, 3, 2, 184, 310, 0, 0, 0, 0],\n [4, 13, 5, 2, 515, 0, 0, 0, 0, 0],\n [4, 336, 9, 42, 3, 6, 0, 0, 0, 0],\n [11, 12, 39, 5, 269, 140, 0, 0, 0, 0],\n [29, 30, 55, 43, 112, 7, 2, 27, 0, 0],\n [3, 2, 16, 7, 2, 56, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 66, 0, 0, 0],\n [4, 26, 9, 153, 3, 51, 0, 0, 0, 0],\n [11, 12, 2906, 5, 7, 2, 191, 0, 0, 0],\n [22, 5, 34, 0, 0, 0, 0, 0, 0, 0],\n [3, 21, 190, 19, 783, 0, 0, 0, 0, 0],\n [3, 2, 16, 907, 24, 743, 2, 274, 0, 0],\n [22, 3, 2, 115, 0, 0, 0, 0, 0, 0],\n [2907, 1223, 24, 2908, 2909, 0, 0, 0, 0, 0],\n [3, 6, 16, 905, 0, 0, 0, 0, 0, 0],\n [4, 3, 6, 16, 94, 0, 0, 0, 0, 0],\n [3, 14, 272, 375, 389, 2, 175, 0, 0, 0],\n [3, 6, 128, 75, 251, 40, 318, 24, 784, 2],\n [3, 2, 18, 7, 13, 0, 0, 0, 0, 0],\n [4, 26, 9, 818, 3, 6, 0, 0, 0, 0],\n [4, 5, 2, 161, 96, 230, 398, 8, 2, 785],\n [3, 2, 178, 502, 0, 0, 0, 0, 0, 0],\n [3, 51, 10, 655, 51, 2, 16, 3, 38, 0],\n [4, 418, 3, 10, 1217, 9, 6, 385, 0, 0],\n [3, 6, 10, 194, 1505, 7, 2910, 0, 0, 0],\n [3, 2, 908, 2911, 0, 0, 0, 0, 0, 0],\n [11, 12, 39, 7, 6, 27, 0, 0, 0, 0],\n [3, 2, 272, 649, 8, 2, 2912, 0, 0, 0],\n [4, 1224, 5, 8, 2, 77, 0, 0, 0, 0],\n [11, 350, 3, 2, 210, 185, 0, 0, 0, 0],\n [4, 13, 3, 2, 210, 185, 0, 0, 0, 0],\n [3, 14, 10, 223, 8, 10, 223, 0, 0, 0],\n [4, 26, 9, 47, 3, 69, 0, 0, 0, 0],\n [68, 3, 2, 44, 285, 0, 0, 0, 0, 0],\n [3, 6, 16, 20, 305, 0, 0, 0, 0, 0],\n [4, 3, 8, 2, 58, 180, 0, 0, 0, 0],\n [3, 6, 16, 20, 205, 0, 0, 0, 0, 0],\n [3, 6, 16, 20, 151, 0, 0, 0, 0, 0],\n [3, 6, 10, 2913, 50, 2914, 0, 0, 0, 0],\n [3, 2, 127, 269, 8, 748, 0, 0, 0, 0],\n [4, 13, 3, 2, 114, 0, 0, 0, 0, 0],\n [11, 12, 822, 5, 69, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 77, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 38, 7, 46, 64, 88, 0],\n [3, 6, 2, 2158, 9, 10, 630, 0, 0, 0],\n [4, 13, 3, 2, 77, 0, 0, 0, 0, 0],\n [5, 2, 262, 94, 188, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 209, 1047, 0, 0, 0, 0],\n [4, 5, 2, 503, 900, 7, 2, 363, 50, 0],\n [3, 2, 61, 7, 1048, 0, 0, 0, 0, 0],\n [3, 2, 67, 9, 81, 2159, 117, 1506, 9, 1225],\n [3, 2, 42, 203, 0, 0, 0, 0, 0, 0],\n [4, 3, 1507, 8, 2, 77, 0, 0, 0, 0],\n [4, 3, 211, 8, 84, 9, 2, 319, 48, 0],\n [3, 21, 355, 1508, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 42, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 2915, 115, 0, 0, 0, 0, 0],\n [3, 14, 10, 175, 7, 6, 27, 0, 0, 0],\n [3, 14, 10, 282, 7, 2, 32, 0, 0, 0],\n [3, 226, 195, 2916, 239, 824, 0, 0, 0, 0],\n [3, 6, 28, 20, 1049, 0, 0, 0, 0, 0],\n [3, 2, 35, 20, 2160, 0, 0, 0, 0, 0],\n [4, 3, 19, 2, 64, 9, 2, 424, 0, 0],\n [3, 2, 126, 120, 24, 125, 0, 0, 0, 0],\n [4, 304, 3, 21, 0, 0, 0, 0, 0, 0],\n [3, 21, 137, 0, 0, 0, 0, 0, 0, 0],\n [3, 6, 187, 177, 24, 263, 1226, 371, 149, 0],\n [5, 17, 268, 217, 2, 45, 0, 0, 0, 0],\n [11, 12, 17, 5, 601, 7, 6, 1353, 0, 0],\n [4, 13, 3, 2, 143, 0, 0, 0, 0, 0],\n [54, 222, 3, 534, 19, 2, 64, 0, 0, 0],\n [4, 129, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 129, 290, 19, 55, 46, 450, 0],\n [4, 537, 9, 308, 5, 69, 0, 0, 0, 0],\n [3, 6, 59, 2161, 0, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 8, 2, 157, 0, 0, 0],\n [4, 202, 3, 2, 2917, 204, 0, 0, 0, 0],\n [3, 117, 28, 782, 239, 2, 254, 0, 0, 0],\n [4, 67, 9, 81, 3, 6, 169, 717, 474, 0],\n [11, 12, 280, 5, 14, 0, 0, 0, 0, 0],\n [4, 26, 9, 202, 3, 167, 8, 2, 275, 0],\n [22, 5, 34, 0, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 65, 0, 0, 0, 0, 0],\n [11, 12, 2918, 5, 8, 2, 330, 0, 0, 0],\n [4, 26, 9, 178, 3, 95, 357, 50, 0, 0],\n [3, 6, 10, 2162, 0, 0, 0, 0, 0, 0],\n [3, 2, 16, 269, 182, 19, 46, 347, 0, 0],\n [4, 3, 2, 136, 718, 0, 0, 0, 0, 0],\n [4, 786, 104, 281, 30, 2919, 6, 3, 10, 114],\n [15, 21, 79, 102, 10, 364, 2163, 8, 2, 517],\n [3, 2, 306, 130, 1509, 24, 749, 0, 0, 0],\n [3, 14, 10, 165, 153, 7, 6, 18, 0, 0],\n [15, 6, 28, 2921, 2922, 0, 0, 0, 0, 0],\n [4, 15, 2, 270, 98, 343, 3, 978, 190, 2],\n [4, 3, 2, 98, 94, 0, 0, 0, 0, 0],\n [5, 23, 39, 316, 0, 0, 0, 0, 0, 0],\n [4, 33, 9, 327, 3, 6, 0, 0, 0, 0],\n [4, 70, 29, 34, 378, 0, 0, 0, 0, 0],\n [22, 5, 2, 17, 53, 0, 0, 0, 0, 0],\n [15, 6, 28, 25, 10, 909, 0, 0, 0, 0],\n [4, 3, 95, 31, 0, 0, 0, 0, 0, 0],\n [3, 49, 107, 556, 24, 1768, 0, 0, 0, 0],\n [11, 12, 5, 416, 289, 0, 0, 0, 0, 0],\n [3, 2, 188, 125, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 1510, 138, 7, 2, 530, 9, 6],\n [4, 3, 2, 118, 9, 2, 2923, 979, 0, 0],\n [22, 3, 6, 0, 0, 0, 0, 0, 0, 0],\n [15, 2, 488, 475, 79, 225, 0, 0, 0, 0],\n [2924, 2, 178, 0, 0, 0, 0, 0, 0, 0],\n [4, 414, 5, 8, 2, 221, 0, 0, 0, 0],\n [4, 3, 2, 13, 9, 2, 425, 9, 2, 222],\n [11, 12, 750, 5, 8, 2, 66, 9, 2, 152],\n [4, 3, 7, 2, 221, 0, 0, 0, 0, 0],\n [11, 1354, 5, 2, 438, 0, 0, 0, 0, 0],\n [3, 6, 10, 1769, 1355, 0, 0, 0, 0, 0],\n [5, 14, 10, 475, 9, 438, 0, 0, 0, 0],\n [4, 489, 3, 8, 2, 284, 0, 0, 0, 0],\n [3, 2, 16, 107, 19, 516, 0, 0, 0, 0],\n [22, 5, 34, 80, 0, 0, 0, 0, 0, 0],\n [4, 15, 2, 980, 64, 48, 109, 0, 0, 0],\n [3, 21, 161, 96, 85, 0, 0, 0, 0, 0],\n [5, 23, 121, 206, 1227, 1511, 0, 0, 0, 0],\n [41, 30, 55, 2, 272, 0, 0, 0, 0, 0],\n [4, 2925, 3, 2, 35, 2164, 0, 0, 0, 0],\n [4, 3, 7, 2, 18, 0, 0, 0, 0, 0],\n [4, 1770, 5, 2, 825, 86, 0, 0, 0, 0],\n [4, 29, 2, 206, 500, 19, 1356, 158, 650, 0],\n [22, 3, 2, 28, 7, 120, 358, 24, 101, 0],\n [3, 6, 28, 80, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 2926, 0, 0, 0, 0, 0, 0],\n [4, 33, 9, 114, 3, 7, 2, 66, 0, 0],\n [22, 3, 6, 0, 0, 0, 0, 0, 0, 0],\n [3, 14, 10, 92, 126, 0, 0, 0, 0, 0],\n [498, 15, 2927, 9, 2, 2928, 159, 0, 0, 0],\n [4, 13, 3, 2, 143, 0, 0, 0, 0, 0],\n [4, 3, 213, 2, 262, 351, 0, 0, 0, 0],\n [11, 12, 174, 29, 30, 55, 0, 0, 0, 0],\n [104, 6, 181, 1050, 1512, 0, 0, 0, 0, 0],\n [4, 111, 3, 83, 300, 0, 0, 0, 0, 0],\n [11, 12, 17, 87, 865, 144, 464, 108, 9, 2],\n [4, 13, 5, 158, 490, 0, 0, 0, 0, 0],\n [5, 23, 17, 107, 105, 24, 140, 0, 0, 0],\n [11, 12, 504, 5, 159, 0, 0, 0, 0, 0],\n [11, 12, 2929, 5, 14, 7, 2, 32, 0, 0],\n [11, 12, 39, 5, 14, 0, 0, 0, 0, 0],\n [29, 30, 55, 43, 215, 0, 0, 0, 0, 0],\n [11, 148, 23, 354, 1771, 1772, 689, 0, 0, 0],\n [3, 6, 37, 10, 2165, 354, 0, 0, 0, 0],\n [4, 32, 9, 2, 229, 3, 6, 0, 0, 0],\n [4, 3, 8, 2, 152, 0, 0, 0, 0, 0],\n [4, 3, 2, 271, 581, 260, 0, 0, 0, 0],\n [3, 6, 10, 301, 0, 0, 0, 0, 0, 0],\n [25, 30, 1120, 131, 2166, 10, 319, 48, 0, 0],\n [4, 3, 2, 491, 53, 8, 0, 0, 0, 0],\n [11, 2930, 15, 2, 903, 79, 0, 0, 0, 0],\n [89, 6, 27, 75, 40, 318, 0, 0, 0, 0],\n [11, 12, 910, 5, 8, 6, 505, 0, 0, 0],\n [4, 26, 9, 139, 3, 51, 0, 0, 0, 0],\n [3, 6, 10, 307, 324, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 322, 0, 0, 0, 0, 0],\n [4, 26, 9, 135, 5, 23, 0, 0, 0, 0],\n [15, 2, 1513, 25, 981, 0, 0, 0, 0, 0],\n [189, 2, 98, 281, 10, 1773, 0, 0, 0, 0],\n [4, 13, 3, 82, 130, 0, 0, 0, 0, 0],\n [4, 3, 7, 101, 9, 2, 1345, 0, 0, 0],\n [11, 359, 29, 2, 2931, 2932, 506, 911, 0, 0],\n [11, 359, 5, 2, 247, 19, 2933, 0, 0, 0],\n [3, 6, 27, 161, 96, 85, 0, 0, 0, 0],\n [3, 14, 447, 110, 0, 0, 0, 0, 0, 0],\n [22, 3, 6, 16, 107, 19, 826, 0, 0, 0],\n [148, 95, 323, 335, 10, 194, 153, 0, 0, 0],\n [4, 5, 34, 31, 0, 0, 0, 0, 0, 0],\n [22, 3, 2, 44, 107, 0, 0, 0, 0, 0],\n [4, 3, 2, 138, 73, 314, 260, 0, 0, 0],\n [4, 3, 95, 38, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 824, 251, 19, 159, 59, 218, 0],\n [11, 12, 1228, 5, 7, 2, 18, 0, 0, 0],\n [4, 13, 3, 2, 1121, 518, 0, 0, 0, 0],\n [4, 406, 3, 8, 2, 58, 134, 0, 0, 0],\n [866, 181, 3, 21, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 58, 310, 0, 0, 0, 0],\n [4, 3, 2, 16, 685, 19, 0, 0, 0, 0],\n [5, 14, 1357, 0, 0, 0, 0, 0, 0, 0],\n [3, 21, 10, 328, 81, 0, 0, 0, 0, 0],\n [5, 14, 297, 7, 2, 66, 0, 0, 0, 0],\n [22, 3, 2, 129, 0, 0, 0, 0, 0, 0],\n [11, 12, 187, 243, 29, 30, 55, 0, 0, 0],\n [4, 147, 9, 867, 3, 7, 2, 18, 0, 0],\n [4, 3, 211, 8, 2, 246, 0, 0, 0, 0],\n [11, 12, 17, 5, 53, 8, 2, 78, 0, 0],\n [4, 3, 6, 28, 20, 8, 158, 170, 0, 0],\n [4, 13, 5, 2, 262, 0, 0, 0, 0, 0],\n [4, 3, 123, 2, 262, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 58, 234, 0, 0, 0, 0],\n [4, 13, 3, 2, 44, 0, 0, 0, 0, 0],\n [3, 6, 146, 225, 0, 0, 0, 0, 0, 0],\n [3, 6, 98, 20, 10, 827, 0, 0, 0, 0],\n [3, 10, 519, 9, 56, 237, 2, 17, 0, 0],\n [4, 104, 36, 236, 0, 0, 0, 0, 0, 0],\n [68, 3, 2, 483, 138, 2, 235, 1514, 0, 0],\n [3, 2, 129, 416, 24, 399, 551, 0, 0, 0],\n [54, 292, 3, 7, 2, 358, 0, 0, 0, 0],\n [3, 520, 1122, 211, 24, 2934, 8, 2, 242, 0],\n [4, 39, 5, 7, 2, 128, 0, 0, 0, 0],\n [5, 23, 39, 2935, 0, 0, 0, 0, 0, 0],\n [2, 28, 3, 658, 0, 0, 0, 0, 0, 0],\n [11, 12, 629, 5, 142, 0, 0, 0, 0, 0],\n [5, 23, 787, 0, 0, 0, 0, 0, 0, 0],\n [4, 90, 3, 8, 2, 184, 861, 0, 0, 0],\n [3, 6, 10, 136, 630, 653, 0, 0, 0, 0],\n [54, 88, 1051, 2, 396, 0, 0, 0, 0, 0],\n [4, 13, 5, 46, 205, 0, 0, 0, 0, 0],\n [4, 88, 3, 2, 16, 38, 2, 194, 1229, 7],\n [3, 14, 10, 2167, 182, 19, 2, 186, 0, 0],\n [11, 12, 276, 2168, 828, 5, 100, 0, 0, 0],\n [4, 33, 9, 70, 3, 6, 0, 0, 0, 0],\n [4, 2169, 6, 16, 55, 751, 1515, 0, 0, 0],\n [4, 5, 2, 17, 94, 0, 0, 0, 0, 0],\n [68, 3, 2, 1230, 2936, 2170, 105, 40, 2, 325],\n [3, 2, 2171, 9, 602, 1516, 0, 0, 0, 0],\n [5, 235, 17, 53, 24, 80, 0, 0, 0, 0],\n [3, 6, 10, 659, 18, 0, 0, 0, 0, 0],\n [68, 5, 2, 2937, 145, 8, 0, 0, 0, 0],\n [11, 12, 1774, 15, 2, 226, 376, 0, 0, 0],\n [3, 6, 40, 2, 201, 0, 0, 0, 0, 0],\n [4, 32, 7, 2, 229, 5, 2, 113, 53, 7],\n [3, 10, 16, 38, 10, 344, 221, 0, 0, 0],\n [5, 14, 17, 110, 0, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 20, 151, 0, 0, 0, 0],\n [22, 3, 2, 2938, 0, 0, 0, 0, 0, 0],\n [3, 2, 35, 20, 10, 118, 147, 912, 52, 0],\n [4, 26, 9, 47, 3, 8, 2, 63, 0, 0],\n [3, 14, 338, 660, 8, 60, 0, 0, 0, 0],\n [4, 219, 3, 2, 166, 268, 0, 0, 0, 0],\n [4, 3, 2, 655, 0, 0, 0, 0, 0, 0],\n [11, 12, 39, 5, 69, 0, 0, 0, 0, 0],\n [4, 29, 2, 538, 595, 0, 0, 0, 0, 0],\n [3, 2, 157, 1517, 0, 0, 0, 0, 0, 0],\n [29, 97, 2, 297, 25, 1518, 7, 158, 257, 0],\n [11, 12, 408, 365, 9, 139, 5, 69, 0, 0],\n [3, 14, 661, 139, 8, 2, 60, 0, 0, 0],\n [3, 6, 139, 50, 59, 492, 0, 0, 0, 0],\n [4, 3, 2, 2172, 138, 7, 2, 132, 0, 0],\n [4, 3, 2, 132, 62, 86, 0, 0, 0, 0],\n [4, 3, 123, 2, 57, 0, 0, 0, 0, 0],\n [4, 3, 2, 103, 2939, 0, 0, 0, 0, 0],\n [3, 6, 10, 1761, 71, 0, 0, 0, 0, 0],\n [3, 2, 28, 94, 73, 1519, 0, 0, 0, 0],\n [4, 26, 9, 47, 3, 2, 557, 507, 0, 0],\n [5, 14, 360, 8, 2, 63, 0, 0, 0, 0],\n [4, 5, 2, 1231, 8, 6, 71, 0, 0, 0],\n [15, 6, 79, 102, 59, 2940, 0, 0, 0, 0],\n [3, 117, 9, 2, 2173, 69, 110, 355, 7, 2174],\n [4, 26, 9, 71, 3, 6, 0, 0, 0, 0],\n [29, 30, 55, 1123, 0, 0, 0, 0, 0, 0],\n [11, 12, 349, 5, 982, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 453, 0, 0, 0, 0, 0],\n [11, 12, 2175, 5, 8, 46, 246, 0, 0, 0],\n [41, 30, 55, 2, 321, 244, 0, 0, 0, 0],\n [5, 2, 1124, 80, 0, 0, 0, 0, 0, 0],\n [4, 3, 6, 0, 0, 0, 0, 0, 0, 0],\n [87, 2, 354, 144, 94, 188, 0, 0, 0, 0],\n [15, 6, 28, 25, 183, 253, 8, 2, 78, 0],\n [4, 147, 197, 3, 49, 38, 0, 0, 0, 0],\n [11, 12, 2176, 2177, 29, 30, 55, 0, 0, 0],\n [4, 32, 3, 2, 16, 7, 0, 0, 0, 0],\n [3, 14, 10, 406, 2941, 8, 2, 58, 52, 0],\n [5, 34, 38, 2942, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 103, 31, 0, 0, 0, 0, 0],\n [3, 2, 122, 51, 3, 352, 123, 2, 439, 103],\n [4, 33, 9, 129, 3, 6, 0, 0, 0, 0],\n [99, 5, 119, 2, 386, 0, 0, 0, 0, 0],\n [5, 97, 2, 629, 8, 0, 0, 0, 0, 0],\n [4, 37, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 72, 80, 8, 0, 0, 0, 0],\n [4, 5, 97, 9, 2, 690, 53, 8, 0, 0],\n [4, 3, 984, 379, 2, 2943, 0, 0, 0, 0],\n [4, 13, 3, 2, 186, 8, 2, 64, 0, 0],\n [4, 293, 3, 2, 320, 62, 9, 0, 0, 0],\n [4, 3, 177, 2, 2179, 351, 0, 0, 0, 0],\n [11, 12, 829, 145, 5, 14, 0, 0, 0, 0],\n [11, 12, 168, 788, 25, 117, 1743, 0, 0, 0],\n [4, 13, 603, 3, 49, 20, 0, 0, 0, 0],\n [4, 293, 3, 2, 132, 62, 86, 0, 0, 0],\n [3, 6, 59, 440, 24, 222, 0, 0, 0, 0],\n [3, 2, 76, 434, 0, 0, 0, 0, 0, 0],\n [11, 12, 662, 0, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 13, 9, 2, 229, 0, 0, 0],\n [4, 3, 2, 913, 31, 0, 0, 0, 0, 0],\n [5, 34, 40, 10, 339, 0, 0, 0, 0, 0],\n [4, 401, 3, 2, 16, 31, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 56, 0, 0, 0],\n [5, 14, 112, 753, 0, 0, 0, 0, 0, 0],\n [5, 2, 286, 20, 1125, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 286, 0, 0, 0, 0, 0],\n [4, 70, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 70, 3, 6, 28, 31, 0, 0, 0, 0],\n [5, 2, 121, 17, 7, 6, 93, 9, 2, 133],\n [68, 104, 49, 36, 357, 102, 6, 0, 0, 0],\n [4, 13, 3, 2, 77, 0, 0, 0, 0, 0],\n [3, 6, 18, 75, 199, 0, 0, 0, 0, 0],\n [15, 6, 663, 102, 10, 251, 51, 179, 2944, 0],\n [25, 23, 17, 144, 464, 47, 656, 0, 0, 0],\n [11, 12, 206, 5, 20, 85, 1775, 0, 0, 0],\n [99, 3, 80, 0, 0, 0, 0, 0, 0, 0],\n [4, 37, 3, 456, 8, 2, 45, 0, 0, 0],\n [4, 13, 3, 2, 129, 0, 0, 0, 0, 0],\n [3, 6, 71, 2945, 0, 0, 0, 0, 0, 0],\n [4, 5, 23, 39, 0, 0, 0, 0, 0, 0],\n [11, 12, 160, 5, 14, 0, 0, 0, 0, 0],\n [5, 183, 160, 80, 0, 0, 0, 0, 0, 0],\n [5, 2, 160, 332, 2, 133, 219, 0, 0, 0],\n [22, 3, 2, 122, 285, 0, 0, 0, 0, 0],\n [22, 5, 2, 286, 53, 0, 0, 0, 0, 0],\n [29, 23, 39, 25, 1126, 0, 0, 0, 0, 0],\n [4, 13, 5, 23, 39, 0, 0, 0, 0, 0],\n [4, 3, 2, 232, 80, 123, 0, 0, 0, 0],\n [3, 2, 175, 159, 24, 345, 0, 0, 0, 0],\n [3, 2, 16, 20, 10, 204, 0, 0, 0, 0],\n [3, 2, 18, 7, 914, 0, 0, 0, 0, 0],\n [4, 3, 2, 57, 31, 0, 0, 0, 0, 0],\n [3, 6, 57, 1358, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 57, 316, 108, 9, 0, 0, 0],\n [3, 6, 57, 356, 0, 0, 0, 0, 0, 0],\n [4, 138, 3, 2, 42, 830, 73, 0, 0, 0],\n [4, 266, 3, 2, 321, 664, 0, 0, 0, 0],\n [3, 2, 57, 789, 0, 0, 0, 0, 0, 0],\n [3, 51, 10, 44, 0, 0, 0, 0, 0, 0],\n [68, 3, 2, 35, 268, 7, 101, 9, 2, 308],\n [4, 33, 9, 37, 457, 30, 55, 7, 2, 521],\n [3, 14, 10, 165, 576, 41, 0, 0, 0, 0],\n [11, 12, 553, 2946, 5, 7, 2, 180, 0, 0],\n [4, 3, 2, 48, 1037, 0, 0, 0, 0, 0],\n [4, 1233, 123, 2, 476, 284, 0, 0, 0, 0],\n [4, 3, 8, 2, 16, 8, 2, 2180, 2947, 0],\n [3, 2, 157, 62, 0, 0, 0, 0, 0, 0],\n [4, 5, 2, 409, 19, 2, 64, 0, 0, 0],\n [4, 3, 2181, 259, 9, 2, 218, 0, 0, 0],\n [15, 6, 169, 172, 19, 36, 915, 0, 0, 0],\n [4, 3, 2, 235, 898, 138, 7, 2, 18, 0],\n [11, 12, 39, 5, 7, 2, 209, 0, 0, 0],\n [4, 3, 2, 35, 377, 0, 0, 0, 0, 0],\n [3, 14, 10, 156, 182, 19, 2, 45, 315, 0],\n [3, 2, 28, 620, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 31, 8, 2, 681, 0, 0],\n [4, 13, 3, 2, 2948, 258, 0, 0, 0, 0],\n [3, 6, 10, 339, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 31, 0, 0, 0, 0, 0],\n [4, 5, 2, 178, 1234, 40, 2, 501, 0, 0],\n [4, 13, 3, 2, 310, 0, 0, 0, 0, 0],\n [11, 149, 3, 2, 28, 0, 0, 0, 0, 0],\n [4, 32, 7, 2, 229, 3, 6, 0, 0, 0],\n [3, 6, 10, 208, 24, 466, 1235, 0, 0, 0],\n [3, 49, 7, 10, 868, 1520, 0, 0, 0, 0],\n [3, 2, 57, 199, 2, 231, 0, 0, 0, 0],\n [99, 3, 123, 2, 231, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 136, 0, 0, 0, 0, 0],\n [22, 3, 2, 136, 80, 7, 2, 27, 0, 0],\n [4, 3, 2, 44, 573, 177, 0, 0, 0, 0],\n [5, 14, 43, 173, 7, 2, 76, 0, 0, 0],\n [3, 14, 1776, 1359, 7, 6, 27, 0, 0, 0],\n [11, 12, 198, 5, 14, 0, 0, 0, 0, 0],\n [3, 14, 196, 7, 6, 27, 0, 0, 0, 0],\n [3, 6, 2, 467, 0, 0, 0, 0, 0, 0],\n [4, 13, 539, 5, 8, 2, 347, 0, 0, 0],\n [4, 13, 3, 2, 916, 8, 2, 78, 0, 0],\n [4, 3, 49, 38, 0, 0, 0, 0, 0, 0],\n [3, 6, 16, 40, 402, 0, 0, 0, 0, 0],\n [3, 2, 42, 255, 0, 0, 0, 0, 0, 0],\n [4, 5, 2, 286, 268, 8, 0, 0, 0, 0],\n [4, 13, 3, 2, 56, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 2182, 9, 2, 135, 0, 0],\n [3, 2, 214, 8, 24, 259, 0, 0, 0, 0],\n [4, 3, 2, 35, 2183, 19, 29, 0, 0, 0],\n [4, 3, 2, 831, 245, 38, 7, 82, 257, 0],\n [4, 3, 2, 35, 31, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 38, 0, 0, 0, 0, 0],\n [5, 34, 7, 2184, 0, 0, 0, 0, 0, 0],\n [3, 2, 76, 328, 0, 0, 0, 0, 0, 0],\n [4, 401, 15, 95, 663, 19, 36, 7, 2, 358],\n [4, 1127, 3, 2, 338, 7, 6, 18, 0, 0],\n [4, 13, 3, 2, 654, 0, 0, 0, 0, 0],\n [3, 51, 10, 310, 0, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 314, 8, 2, 273, 0, 0],\n [5, 14, 12, 17, 0, 0, 0, 0, 0, 0],\n [3, 14, 10, 2949, 8, 2, 240, 0, 0, 0],\n [11, 12, 85, 135, 0, 0, 0, 0, 0, 0],\n [4, 26, 9, 122, 3, 6, 0, 0, 0, 0],\n [4, 3, 2, 165, 143, 0, 0, 0, 0, 0],\n [4, 691, 1128, 3, 7, 2, 66, 0, 0, 0],\n [3, 21, 137, 81, 0, 0, 0, 0, 0, 0],\n [4, 3, 8, 2, 58, 170, 0, 0, 0, 0],\n [5, 2, 112, 125, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 540, 156, 0, 0, 0, 0, 0],\n [179, 6, 36, 10, 2950, 1521, 0, 0, 0, 0],\n [11, 12, 17, 5, 20, 151, 0, 0, 0, 0],\n [4, 754, 5, 34, 1236, 0, 0, 0, 0, 0],\n [54, 3, 1360, 7, 2, 76, 2, 440, 24, 2],\n [22, 3, 6, 0, 0, 0, 0, 0, 0, 0],\n [3, 6, 1522, 1777, 0, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 20, 120, 0, 0, 0, 0],\n [3, 14, 196, 0, 0, 0, 0, 0, 0, 0],\n [4, 5, 2, 17, 31, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 27, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 80, 8, 0, 0, 0, 0],\n [3, 14, 235, 207, 10, 2185, 7, 6, 61, 0],\n [4, 70, 3, 49, 65, 0, 0, 0, 0, 0],\n [4, 493, 9, 1237, 3, 6, 0, 0, 0, 0],\n [4, 754, 3, 83, 2186, 0, 0, 0, 0, 0],\n [4, 67, 3, 8, 2, 115, 0, 0, 0, 0],\n [11, 12, 173, 5, 7, 2, 76, 0, 0, 0],\n [11, 12, 174, 0, 0, 0, 0, 0, 0, 0],\n [4, 32, 3, 6, 0, 0, 0, 0, 0, 0],\n [22, 3, 2, 424, 0, 0, 0, 0, 0, 0],\n [11, 12, 275, 5, 40, 2, 60, 0, 0, 0],\n [11, 12, 171, 5, 14, 0, 0, 0, 0, 0],\n [15, 6, 136, 25, 1361, 213, 403, 490, 0, 0],\n [11, 12, 256, 5, 14, 110, 0, 0, 0, 0],\n [4, 26, 9, 44, 3, 51, 0, 0, 0, 0],\n [4, 143, 3, 123, 2, 39, 0, 0, 0, 0],\n [3, 14, 10, 604, 37, 7, 2, 27, 0, 0],\n [68, 104, 162, 2187, 6, 1778, 8, 2, 441, 0],\n [3, 14, 10, 251, 8, 2, 522, 24, 1779, 2188],\n [15, 95, 79, 203, 19, 36, 7, 10, 27, 0],\n [11, 12, 523, 9, 344, 5, 8, 2, 366, 0],\n [4, 13, 3, 2, 1230, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 77, 0, 0, 0, 0, 0],\n [11, 12, 253, 5, 14, 0, 0, 0, 0, 0],\n [41, 2, 210, 1523, 390, 6, 0, 0, 0, 0],\n [22, 3, 2, 2189, 0, 0, 0, 0, 0, 0],\n [3, 14, 10, 1524, 387, 0, 0, 0, 0, 0],\n [22, 5, 2, 917, 0, 0, 0, 0, 0, 0],\n [3, 21, 2952, 50, 6, 37, 19, 36, 8, 2],\n [3, 14, 520, 8, 2, 366, 0, 0, 0, 0],\n [4, 13, 5, 2, 582, 0, 0, 0, 0, 0],\n [11, 12, 92, 145, 5, 69, 0, 0, 0, 0],\n [4, 3, 2, 974, 1362, 0, 0, 0, 0, 0],\n [11, 12, 112, 41, 30, 55, 0, 0, 0, 0],\n [11, 12, 120, 226, 145, 5, 100, 7, 6, 18],\n [3, 2, 32, 1517, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 72, 24, 10, 98, 0, 0, 0],\n [3, 14, 10, 790, 8, 2, 1129, 0, 0, 0],\n [15, 2, 692, 25, 314, 0, 0, 0, 0, 0],\n [11, 41, 30, 524, 2, 72, 87, 144, 53, 140],\n [3, 21, 829, 7, 14, 0, 0, 0, 0, 0],\n [22, 5, 2, 17, 91, 40, 0, 0, 0, 0],\n [3, 192, 7, 2, 157, 0, 0, 0, 0, 0],\n [3, 2, 35, 20, 151, 0, 0, 0, 0, 0],\n [11, 12, 17, 25, 750, 0, 0, 0, 0, 0],\n [3, 2, 16, 119, 10, 224, 0, 0, 0, 0],\n [4, 13, 3, 2, 58, 56, 341, 0, 0, 0],\n [4, 3, 2, 33, 9, 293, 167, 50, 2, 2953],\n [3, 14, 10, 201, 7, 6, 128, 0, 0, 0],\n [4, 3, 182, 19, 2, 200, 0, 0, 0, 0],\n [4, 26, 9, 200, 5, 23, 0, 0, 0, 0],\n [3, 6, 10, 869, 1780, 169, 0, 0, 0, 0],\n [11, 12, 275, 5, 7, 6, 18, 0, 0, 0],\n [4, 13, 3, 2, 458, 7, 2, 27, 0, 0],\n [4, 13, 3, 2, 985, 0, 0, 0, 0, 0],\n [4, 489, 3, 8, 2, 27, 0, 0, 0, 0],\n [3, 2, 150, 268, 0, 0, 0, 0, 0, 0],\n [54, 37, 3, 356, 7, 2, 458, 0, 0, 0],\n [3, 2, 42, 356, 0, 0, 0, 0, 0, 0],\n [3, 2, 918, 898, 0, 0, 0, 0, 0, 0],\n [4, 3, 6, 494, 260, 0, 0, 0, 0, 0],\n [3, 2, 129, 2954, 0, 0, 0, 0, 0, 0],\n [3, 2, 103, 237, 112, 0, 0, 0, 0, 0],\n [5, 14, 572, 112, 8, 6, 1363, 0, 0, 0],\n [29, 30, 55, 10, 1781, 8, 2, 78, 0, 0],\n [4, 3, 216, 2, 282, 0, 0, 0, 0, 0],\n [3, 2, 106, 631, 105, 0, 0, 0, 0, 0],\n [3, 2, 576, 41, 434, 0, 0, 0, 0, 0],\n [3, 6, 146, 19, 384, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 919, 305, 0, 0, 0, 0],\n [5, 2, 17, 357, 50, 2, 178, 0, 0, 0],\n [4, 147, 3, 2, 2190, 0, 0, 0, 0, 0],\n [3, 14, 10, 1130, 8, 2, 476, 60, 0, 0],\n [4, 3, 2, 16, 80, 7, 0, 0, 0, 0],\n [3, 2, 57, 380, 0, 0, 0, 0, 0, 0],\n [87, 6, 71, 865, 144, 1131, 0, 0, 0, 0],\n [4, 3, 2, 118, 9, 2, 208, 423, 51, 3],\n [5, 2, 39, 7, 158, 419, 521, 0, 0, 0],\n [4, 90, 3, 6, 693, 252, 548, 0, 0, 0],\n [11, 12, 17, 73, 165, 558, 0, 0, 0, 0],\n [4, 13, 3, 2, 48, 0, 0, 0, 0, 0],\n [4, 13, 3, 82, 52, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 208, 0, 0, 0],\n [4, 33, 9, 37, 3, 6, 0, 0, 0, 0],\n [15, 2, 42, 25, 307, 583, 0, 0, 0, 0],\n [15, 2, 166, 25, 755, 0, 0, 0, 0, 0],\n [4, 694, 9, 427, 3, 8, 2, 254, 141, 9],\n [3, 6, 10, 442, 71, 0, 0, 0, 0, 0],\n [4, 3, 2, 28, 31, 0, 0, 0, 0, 0],\n [99, 3, 2, 28, 8, 2, 246, 0, 0, 0],\n [68, 3, 2, 16, 1782, 8, 10, 347, 0, 0],\n [3, 6, 59, 467, 24, 665, 0, 0, 0, 0],\n [5, 14, 43, 173, 7, 2, 76, 0, 0, 0],\n [4, 3, 95, 31, 0, 0, 0, 0, 0, 0],\n [22, 3, 2, 57, 0, 0, 0, 0, 0, 0],\n [3, 6, 18, 7, 13, 0, 0, 0, 0, 0],\n [4, 3, 2955, 108, 9, 2, 56, 7, 2, 363],\n [4, 3, 2, 230, 138, 7, 2, 56, 0, 0],\n [4, 15, 21, 172, 51, 2, 16, 8, 2, 417],\n [3, 6, 86, 2956, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 63, 0, 0, 0, 0, 0],\n [3, 6, 47, 340, 50, 30, 0, 0, 0, 0],\n [5, 311, 1525, 247, 50, 2957, 0, 0, 0, 0],\n [15, 6, 28, 25, 10, 2958, 1364, 2191, 2192, 0],\n [148, 2, 61, 513, 259, 0, 0, 0, 0, 0],\n [3, 49, 7, 10, 45, 0, 0, 0, 0, 0],\n [3, 6, 10, 463, 0, 0, 0, 0, 0, 0],\n [11, 12, 1365, 0, 0, 0, 0, 0, 0, 0],\n [11, 12, 2959, 9, 116, 5, 391, 278, 0, 0],\n [4, 3, 50, 921, 177, 6, 1345, 0, 0, 0],\n [4, 5, 2, 17, 53, 8, 0, 0, 0, 0],\n [15, 6, 2193, 25, 2194, 1783, 0, 0, 0, 0],\n [11, 12, 251, 1784, 5, 100, 0, 0, 0, 0],\n [11, 12, 248, 922, 5, 100, 0, 0, 0, 0],\n [3, 6, 10, 495, 48, 0, 0, 0, 0, 0],\n [3, 2, 71, 477, 0, 0, 0, 0, 0, 0],\n [29, 30, 343, 2, 525, 3, 1526, 1785, 19, 2],\n [4, 2, 16, 38, 0, 0, 0, 0, 0, 0],\n [15, 2, 42, 25, 10, 688, 0, 0, 0, 0],\n [41, 30, 55, 43, 168, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 1366, 101, 256, 0, 0, 0],\n [4, 37, 3, 14, 0, 0, 0, 0, 0, 0],\n [68, 457, 117, 2960, 2, 1786, 3, 2961, 110, 0],\n [22, 3, 2, 58, 909, 0, 0, 0, 0, 0],\n [87, 2, 16, 584, 1787, 10, 2195, 0, 0, 0],\n [4, 3, 986, 263, 2, 58, 170, 0, 0, 0],\n [4, 708, 247, 5, 8, 2, 60, 0, 0, 0],\n [4, 5, 2, 155, 8, 6, 354, 0, 0, 0],\n [4, 33, 9, 1132, 3, 7, 2, 221, 0, 0],\n [3, 6, 10, 137, 81, 0, 0, 0, 0, 0],\n [3, 14, 10, 666, 44, 8, 2, 156, 0, 0],\n [22, 15, 6, 478, 496, 0, 0, 0, 0, 0],\n [4, 141, 9, 2, 410, 5, 2, 231, 870, 8],\n [4, 13, 3, 2, 56, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 27, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 301, 0, 0, 0, 0, 0],\n [4, 5, 34, 107, 19, 281, 73, 23, 302, 0],\n [22, 3, 2, 57, 0, 0, 0, 0, 0, 0],\n [15, 2, 72, 361, 2962, 0, 0, 0, 0, 0],\n [11, 12, 2963, 5, 7, 2, 18, 0, 0, 0],\n [4, 911, 2964, 0, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 6, 127, 0, 0, 0, 0, 0],\n [4, 521, 3, 6, 127, 7, 0, 0, 0, 0],\n ...]"}, "metadata": {}}]}, {"cell_type": "markdown", "source": "## 3.\u8bad\u7ec3\u8fc7\u7a0b", "metadata": {}}, {"cell_type": "markdown", "source": "### 3.1 \u8d85\u53c2\u6570\u8bbe\u7f6e", "metadata": {}}, {"cell_type": "code", "source": "#from easydict import EasyDict as edict\noptions = OrderedDict()\n# data related\noptions['data_path'] = './data/'\n#options['feature_file'] = 'trainval_feat.h5'\n#options['expt_folder'] = 'expt_1'\noptions['model_name'] = 'imageqa'\noptions['train_split'] = 'trainval1'\noptions['val_split'] = 'val2'\noptions['shuffle'] = True\noptions['reverse'] = True\noptions['sample_answer'] = True\n\noptions['num_region'] = 196\noptions['region_dim'] = 512\n\n#`13746\noptions['n_words'] = 6620\noptions['n_output'] = 1000\n\n# structure options\noptions['combined_num_mlp'] = 1\noptions['combined_mlp_drop_0'] = True\noptions['combined_mlp_act_0'] = 'linear'\noptions['sent_drop'] = False\noptions['use_tanh'] = False\n\noptions['use_attention_drop'] = False\n\n# dimensions\noptions['n_emb'] = 500\noptions['n_dim'] = 1024\noptions['n_image_feat'] = options['region_dim']\noptions['n_common_feat'] = 500\noptions['n_attention'] = 512\n\n# initialization\noptions['init_type'] = 'uniform'\noptions['range'] = 0.01\noptions['std'] = 0.01\noptions['init_lstm_svd'] = False\n\noptions['forget_bias'] = 1.0\n\n# learning parameters\noptions['optimization'] = 'sgd' # choices\noptions['batch_size'] = 32\noptions['lr'] = 0.05\noptions['w_emb_lr'] = 80\noptions['momentum'] = 0.9\noptions['gamma'] = 1\noptions['step'] = 10\noptions['step_start'] = 100\noptions['max_epochs'] = 50\noptions['weight_decay'] = 0.0005\noptions['decay_rate'] = 0.999\noptions['drop_ratio'] = 0.5\noptions['smooth'] = 1e-8\noptions['grad_clip'] = 0.1\n\n# log params\noptions['disp_interval'] = 10\noptions['eval_interval'] = 1000\noptions['save_interval'] = 500\n\n#new\noptions['dict_size'] = 6620", "metadata": {"trusted": true}, "execution_count": 10, "outputs": []}, {"cell_type": "code", "source": "# vgg\u6a21\u578b\u5bfc\u5165\u76f8\u5173\u5305\n# mox.file.copy_parallel(src_url=\"obs://nlp-kim/project/code/image_model/src\",dst_url=\"./src/\")\nfrom PIL import Image, ImageFile\nfrom src.utils.logging import get_logger\nfrom src.dataset import classification_dataset\nfrom easydict import EasyDict as edict\nfrom src.config import imagenet_cfg as vgg_cfg\n# from data_vqa.vqa_config import model_cfg\nfrom src.vgg import vgg16\n\nimport time\nimport datetime\nimport mindspore.dataset.vision.py_transforms as vision", "metadata": {"trusted": true}, "execution_count": 11, "outputs": []}, {"cell_type": "code", "source": "model_cfg = edict({\n    \"cnn_ckpt_19\":\"./data/vgg19_ascend_v111_imagenet2012_research_cv_bs64_acc74.ckpt\",\n    \"cnn_ckpt_16\":\"./data/vgg16_ascend_v120_imagenet2012_official_cv_bs32_acc73.ckpt\",\n    \"log_path\":\"./outputs\",\n\n    \"device_target\": 'Ascend',\n    \"per_batch_size\": 32,\n    \"graph_ckpt\":1,\n    \"rank\": 0,\n    \"group_size\":1\n})", "metadata": {"trusted": true}, "execution_count": 12, "outputs": []}, {"cell_type": "code", "source": "image_path = {\n    \"train\":\"./data/images/train\",\n    \"test\":\"./data/images/test\",\n    \"val\":\"./data/images/val\"\n}\n\nannotation_path = {\n    \"train\":\"./data/annotation/train.json\",\n    \"test\":\"./data/annotation/test.json\",\n    \"val\":\"./data/annotation/val.json\"\n}\n\nmodel_cfg= edict({\n    \"annotation\":annotation_path,\n    \"image\":image_path,\n    \"cnn_ckpt_19\":\"./data/vgg19_ascend_v111_imagenet2012_research_cv_bs64_acc74.ckpt\",\n    \"cnn_ckpt_16\":\"./data/vgg16_ascend_v120_imagenet2012_official_cv_bs32_acc73.ckpt\",\n    \"log_path\":\"./outputs\",\n\n    \"device_target\": 'Ascend',\n    \"per_batch_size\": 32,\n    \"graph_ckpt\":1,\n    \"rank\": 0,\n    \"group_size\":1\n})", "metadata": {"trusted": true}, "execution_count": 13, "outputs": []}, {"cell_type": "code", "source": "context.set_context(mode=context.GRAPH_MODE, device_target=model_cfg.device_target, device_id=0,enable_auto_mixed_precision=True,save_graphs=False)", "metadata": {"trusted": true}, "execution_count": 14, "outputs": []}, {"cell_type": "code", "source": "model_cfg.outputs_dir = os.path.join(model_cfg.log_path,\n                                    datetime.datetime.now().strftime('%Y-%m-%d_time_%H_%M_%S'))\n\nmodel_cfg.logger = get_logger(model_cfg.outputs_dir, model_cfg.rank)", "metadata": {"trusted": true}, "execution_count": 15, "outputs": []}, {"cell_type": "markdown", "source": "### 3.2\u6a21\u578b\u642d\u5efa", "metadata": {}}, {"cell_type": "code", "source": "# \u5bfc\u5165vgg\u6a21\u578b\nmodel_cfg.logger.important_info('start create vgg')\nvgg = vgg16(vgg_cfg.num_classes, vgg_cfg, phase=\"test\",include_top = False)\nvgg.add_flags_recursive(fp32=True)\nvgg.set_train(False)\nmodel_cfg.logger.important_info('start load checkpoint')\nparam_dict = load_checkpoint(model_cfg.cnn_ckpt_16)\nload_param_into_net(vgg, param_dict)", "metadata": {"trusted": true}, "execution_count": 16, "outputs": [{"name": "stdout", "text": "2021-07-15 06:44:53,289:INFO:\n**********************************************************************\n**********************************************************************\n**\n**\n**        start create vgg\n**\n**\n**********************************************************************\n**********************************************************************\n\n2021-07-15 06:44:53,851:INFO:\n**********************************************************************\n**********************************************************************\n**\n**\n**        start load checkpoint\n**\n**\n**********************************************************************\n**********************************************************************\n\n", "output_type": "stream"}, {"execution_count": 16, "output_type": "execute_result", "data": {"text/plain": "[]"}, "metadata": {}}]}, {"cell_type": "code", "source": "# def img2tensor(img_root,img_prefix,img_id):\n#         img_path = os.path.join(img_root,img_prefix+\"_\"+str(img_id).zfill(12)+\".jpg\")\n#         print(\"img_path:\",img_path)\n#         img = Image.open(img_path).convert('RGB')\n#         transform = edict({\n# #             \"Decode\": vision.Decode(),\n#             \"Resize\": vision.Resize((512, 512)),\n#             \"CenterCrop\": vision.CenterCrop(448),\n# #             \"Normalize\": vision.Normalize(mean=mean, std=std),\n# #             \"HWC2CHW\": vision.HWC2CHW(),\n#             \"ToTensor\":vision.ToTensor()\n#         })\n#         # img = transform.Decode(img)\n#         img = transform.Resize(img)\n#         img = transform.CenterCrop(img)\n#         img = transform.ToTensor(img)\n#         print(\"totensor:\",img)\n#     #     img = transform.Normalize(img) # CHW\n#     #     print(\"normalized:\",img)\n#     #     img = transform.HWC2CHW(img)\n#         img = [img]\n#         tensor = Tensor(img,mstype.float32)\n#         return tensor", "metadata": {"trusted": true}, "execution_count": 17, "outputs": []}, {"cell_type": "code", "source": "def get_feature_map(tensor):\n    model_cfg.logger.important_info('start get feature map')\n    output = vgg(tensor)  \n    return output", "metadata": {"trusted": true}, "execution_count": 18, "outputs": []}, {"cell_type": "code", "source": "# img = img2tensor(model_cfg.image.train,\"COCO_train2014\",9)\n# image_feat = get_feature_map(img)", "metadata": {"trusted": true}, "execution_count": 19, "outputs": []}, {"cell_type": "code", "source": "# image_feat = image_feat.transpose(0,2,3,1)\n# image_feat = image_feat.reshape(1, 196, 512)", "metadata": {"trusted": true}, "execution_count": 20, "outputs": []}, {"cell_type": "code", "source": "from collections import Counter\nimport numpy as np\nimport random\nfrom collections import OrderedDict\nimport math\n\nimport mindspore\nimport mindspore.nn as nn\nfrom mindspore import Tensor\n\n#from mindspore.ops import operations as ops\nfrom mindspore import ops\nfrom mindspore import dtype as mstype\n\nfloatX = np.float32\n\ndef init_weight(n, d, options):\n    ''' initialize weight matrix\n    options['init_type'] determines\n    gaussian or uniform initlizaiton\n    '''\n    if options['init_type'] == 'gaussian':\n        return Tensor((np.random.randn(n, d)).astype(floatX)) * options['std']\n    elif options['init_type'] == 'uniform':\n        # [-range, range]\n        return Tensor(((np.random.rand(n, d) * 2 - 1) * \\\n                options['range']).astype(floatX))\n    \ndef ortho_weight(ndim):\n    \"\"\"\n    Random orthogonal weights, we take\n    the right matrix in the SVD.\n\n    Remember in SVD, u has the same # rows as W\n    and v has the same # of cols as W. So we\n    are ensuring that the rows are\n    orthogonal.\n    \"\"\"\n    W = np.random.randn(ndim, ndim)\n    u, _, _ = np.linalg.svd(W)\n    return Tensor(u).astype('float32')\n\ndef init_fflayer(params, nin, nout, options, prefix='ff'):\n    ''' initialize ff layer\n    '''\n    params[prefix + '_w'] = init_weight(nin, nout, options)\n    params[prefix + '_b'] = Tensor(np.zeros(nout, dtype='float32'))\n    return params\n\n# def init_lstm_layer(params, nin, ndim, options, prefix='lstm'):\n#     ''' initializt lstm layer\n#     '''\n#     params[prefix + '_w_x'] = init_weight(nin, 4 * ndim, options)\n#     # use svd trick to initializ\n#     if options['init_lstm_svd']:\n#         params[prefix + '_w_h'] = Tensor(np.concatenate([ortho_weight(ndim),\n#                                                   ortho_weight(ndim),\n#                                                   ortho_weight(ndim),\n#                                                   ortho_weight(ndim)],\n#                                                  axis=1))\n#     else:\n#         params[prefix + '_w_h'] = init_weight(ndim, 4 * ndim, options)\n#     params[prefix + '_b_h'] = Tensor(np.zeros(4 * ndim, dtype='float32'))\n#     # set forget bias to be positive\n#     params[prefix + '_b_h'][ndim : 2*ndim] = Tensor(np.float32(options.get('forget_bias', 0)))\n#     return params\n\n# initialize the parmaters\ndef init_params(options):\n    ''' Initialize all the parameters\n    '''\n    params = OrderedDict()\n    n_words = options['n_words']\n    n_emb = options['n_emb']\n    n_dim = options['n_dim']\n    n_image_feat = options['n_image_feat']\n    n_common_feat = options['n_common_feat']\n    n_output = options['n_output']\n    n_attention = options['n_attention']\n\n    params['w_emb'] = Tensor((np.random.rand(n_words, n_emb) * 2 - 1) * 0.5).astype(floatX)\n\n    params = init_fflayer(params, n_image_feat, n_dim, options,\n                          prefix='image_mlp')\n\n    # attention model based parameters\n    params = init_fflayer(params, n_dim, n_attention, options,\n                          prefix='image_att_mlp_1')\n    params = init_fflayer(params, n_dim, n_attention, options,\n                          prefix='sent_att_mlp_1')\n    params = init_fflayer(params, n_attention, 1, options,\n                          prefix='combined_att_mlp_1')\n    params = init_fflayer(params, n_dim, n_attention, options,\n                          prefix='image_att_mlp_2')\n    params = init_fflayer(params, n_dim, n_attention, options,\n                          prefix='sent_att_mlp_2')\n    params = init_fflayer(params, n_attention, 1, options,\n                          prefix='combined_att_mlp_2')\n\n\n    # params for sentence image mlp\n    for i in range(options['combined_num_mlp']):\n        if i == 0 and options['combined_num_mlp'] == 1:\n            params = init_fflayer(params, n_dim, n_output,\n                                  options, prefix='combined_mlp_%d'%(i))\n        elif i == 0 and options['combined_num_mlp'] != 1:\n            params = init_fflayer(params, n_dim, n_common_feat,\n                                  options, prefix='combined_mlp_%d'%(i))\n        elif i == options['combined_num_mlp'] - 1 :\n            params = init_fflayer(params, n_common_feat, n_output,\n                                  options, prefix='combined_mlp_%d'%(i))\n        else:\n            params = init_fflayer(params, n_common_feat, n_common_feat,\n                                  options, prefix='combined_mlp_%d'%(i))\n\n    # lstm layer\n    #params = init_lstm_layer(params, n_emb, n_dim, options, prefix='sent_lstm')\n\n    return params\n\ndef init_shared_params(params):\n    ''' return a shared version of all parameters\n    '''\n    global shared_params\n    shared_params = OrderedDict()\n    for k, p in params.items():\n        shared_params[k] = params[k]\n\n    return shared_params\n\ndef fflayer(shared_params, x, options, prefix='ff', act_func='tanh'):\n    ''' fflayer: multiply weight then add bias\n    '''\n    tanh = nn.Tanh()\n    input = ops.dot(x, Tensor(shared_params[prefix + '_w'])) + \\\n                          Tensor(shared_params[prefix + '_b'])\n    return tanh(input)\n\ndef fflayer1(shared_params, x, options, prefix='ff'):\n    ''' fflayer: multiply weight then add bias\n    '''\n    input = ops.dot(x, Tensor(shared_params[prefix + '_w'])) + \\\n                          Tensor(shared_params[prefix + '_b'])\n    return input\n\ndef get_lr(options, curr_epoch):\n    if options['optimization'] == 'sgd':\n        power = max((curr_epoch - options['step_start']) / options['step'], 0)\n        power = math.ceil(power)\n        return options['lr'] * (options['gamma'] ** power)  #\n    else:\n        return options['lr']", "metadata": {"trusted": true}, "execution_count": 21, "outputs": []}, {"cell_type": "code", "source": "floatX = np.float32\nbatch_size = options['batch_size']\nmax_epochs = options['max_epochs']\n\n###############\n# build model #\n###############\nparams = init_params(options)\nshared_params = init_shared_params(params)", "metadata": {"trusted": true}, "execution_count": 22, "outputs": []}, {"cell_type": "code", "source": "# input_idx = np.ones((6618,100),dtype = 'int32')\n# shared_params['w_emb'] = ((np.random.rand(6620, 500) * 2 - 1) * 0.5).astype(floatX)\n# empty_word = np.zeros((1, 500), dtype='float32')\n# w_emb_extend = shared_params['w_emb']\n# input_emb = w_emb_extend[input_idx]", "metadata": {"trusted": true}, "execution_count": 23, "outputs": []}, {"cell_type": "code", "source": "class LSTM(nn.Cell):\n    def __init__(self, options, is_training=True):\n        super(LSTM, self).__init__()\n        if is_training:\n            self.batch_size = options['batch_size']\n        else:\n            self.batch_size = 1\n            \n        self.n_dim = options['n_dim']\n        self.n_emb = options['n_emb']\n        self.dropout = options['drop_ratio']\n        \n        # TODO\n        self.h = Tensor(np.zeros((1,self.batch_size, self.n_dim), dtype='float32'))\n        self.c = Tensor(np.zeros((1,self.batch_size, self.n_dim), dtype='float32'))\n        \n        self.rnn = nn.LSTM(self.n_emb,self.n_dim,1,True,True,self.dropout)\n        #self.cast = P.Cast()\n\n    def construct(self, x):\n        #x = self.cast(x, mstype.float16)\n        output,(h1,c1) = self.rnn(x, (self.h,self.c))\n        return output,(h1,c1)\n\nclass Question(nn.Cell):\n    def __init__(self, options, is_training=True):\n        super(Question, self).__init__()\n        #dict_size(vocab_size)\n        self.dict_size = options['dict_size']\n        #n_dim (hidden_size)\n        self.n_dim = options['n_dim']\n        self.n_emb = options['n_emb']\n        \n        if is_training:\n            self.batch_size = options['batch_size']\n        else:\n            self.batch_size = 1\n\n        #self.trans = P.Transpose()\n        #self.perm = (1, 0, 2)\n        \n        #HIGHLIGHT \u7b2c\u4e8c\u4e2a\u53c2\u6570n_dim -> n_emb\n        self.embedding = nn.Embedding(self.dict_size, self.n_emb)\n        #?\n        self.lstm = LSTM(options, is_training=is_training).to_float(mstype.float16)\n        #self.h = Tensor(np.zeros((self.batch_size, self.n_dim)).astype(np.float16))\n        #self.c = Tensor(np.zeros((self.batch_size, self.n_dim)).astype(np.float16))\n\n    def construct(self, question_input):\n        embeddings = self.embedding(question_input)\n        #embeddings = self.trans(embeddings, self.perm)\n        output, (hn,cn) = self.lstm(embeddings)\n        return output, hn, cn\n", "metadata": {"trusted": true}, "execution_count": 24, "outputs": []}, {"cell_type": "code", "source": "from mindspore.ops import operations as P", "metadata": {"trusted": true}, "execution_count": 25, "outputs": []}, {"cell_type": "code", "source": "class VQA(nn.Cell):\n    def __init__(self, options, is_train=True):\n        super(VQA, self).__init__()\n        #         self.max_len = config.max_seq_length\n        self.is_train = is_train\n        self.batch_size = options['batch_size']\n        #self.encoder = Encoder(config, is_train)\n        #self.decoder = Decoder(config, is_train)\n        self.expanddims = P.ExpandDims()\n        self.squeeze = P.Squeeze(axis=0)\n        self.argmax = P.ArgMaxWithValue(axis=int(2), keep_dims=True)\n        self.concat = P.Concat(axis=1)\n        self.concat2 = P.Concat(axis=0)\n        self.select = P.Select()\n        self.softmax = nn.Softmax()\n        self.print = P.Print()\n        self.dense1 = nn.Dense(1024,1000)\n        self.dense2 = nn.Dense(512,1024)\n        self.mul = ops.Mul()\n        \n        \n        ##### my #####\n        self.question = Question(options, is_train)\n        self.vgg = vgg\n\n    def construct(self, x, src):\n        self.print(\"enter construct\")\n        #         self.print(\"x:\",type(x))\n        image_feat = self.vgg(x)\n        image_feat = image_feat.transpose(0,2,3,1)\n        image_feat = image_feat.reshape(self.batch_size,196,512)\n        image_feat = image_feat.mean(axis = (1),keep_dims = False)\n        image_feat = self.dense2(image_feat)\n        \n        output,h_encode,c_encode = self.question(src)\n\n        h_encode = h_encode[0]\n        #         h_encode = h_encode[None,:]\n        # h_encode.shape 1,1024\n        output = self.mul(h_encode,image_feat)\n        output = self.dense1(output)\n        prob = self.softmax(output)\n        return prob\n#         image_feat = fflayer(shared_params, image_feat, options,\n#                              prefix='image_mlp',\n#                               act_func='tanh')\n#         image_feat = image_feat[0]\n#         #image_feat.shape 196,1024\n        \n#         image_feat_down = image_feat\n#         #image_feat_down.shape 196,1024\n        \n#         image_feat_attention_1 = fflayer(shared_params, image_feat_down, options,\n#                                          prefix='image_att_mlp_1',\n#                                          act_func='tanh')\n#         #image_feat_attention_1.shape 196,512\n\n        \n#         h_encode_attention_1 = fflayer(shared_params, h_encode, options,\n#                                        prefix='sent_att_mlp_1',\n#                                        act_func='tanh')\n#         #h_encode_attentioshapehape 1,512\n        \n#         combined_feat_attention_1 = image_feat_attention_1 + \\\n#                             h_encode_attention_1[:, None, :]\n#         #combined_feat_attention_1.shape 1,196,512\n\n#         #if options['use_attention_drop']:\n#         #combined_feat_attention_1 = dropout_layer(combined_feat_attention_1,\n#                                                 #dropout, trng, drop_ratio)\n#         combined_feat_attention_1 = fflayer1(shared_params,\n#                                     combined_feat_attention_1, options,\n#                                     prefix='combined_att_mlp_1',)\n#         #combined_feat_attention_1.shape 1,196,1\n        \n#         prob_attention_1 = self.softmax(combined_feat_attention_1[:, :, 0])\n#         #prob_attention_1.shape 1,196\n\n#         image_feat_ave_1 = (prob_attention_1[:, :, None] * image_feat_down).asnumpy().sum(axis=1)\n#         image_feat_ave_1 = Tensor(image_feat_ave_1)\n        \n#         combined_hidden_1 = image_feat_ave_1 + h_encode\n#         #combined_hidden_1 1,1024\n        \n#         # second layer attention model\n#         image_feat_attention_2 = fflayer(shared_params, image_feat_down, options,\n#                                      prefix='image_att_mlp_2',\n#                                      act_func=options.get('image_att_mlp_act',\n#                                                           'tanh'))\n\n#         h_encode_attention_2 = fflayer(shared_params, combined_hidden_1, options,\n#                                    prefix='sent_att_mlp_2',\n#                                    act_func=options.get('sent_att_mlp_act',\n#                                                         'tanh'))\n        \n#         combined_feat_attention_2 = image_feat_attention_2 + \\\n#                                 h_encode_attention_2[:, None, :]\n        \n#         combined_feat_attention_2 = fflayer(shared_params,\n#                                         combined_feat_attention_2, options,\n#                                         prefix='combined_att_mlp_2',\n#                                         act_func=options.get(\n#                                             'combined_att_mlp_act', 'tanh'))\n        \n#         prob_attention_2 = self.softmax(combined_feat_attention_2[:, :, 0])\n        \n#         image_feat_ave_2 = (prob_attention_2[:, :, None] * image_feat_down).asnumpy().sum(axis=1)\n#         image_feat_ave_2 = Tensor(image_feat_ave_2)\n        \n#         combined_hidden = image_feat_ave_2 + combined_hidden_1\n        \n#         prob = self.softmax(combined_hidden)\n        \n        \n#         return image_feat", "metadata": {"trusted": true}, "execution_count": 50, "outputs": []}, {"cell_type": "code", "source": "vqa = VQA(options)\nds = create_dataset(options['batch_size'], mode='val',q_dict = question_key,a_dict = answer_top_k)", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 63, "outputs": []}, {"cell_type": "code", "source": "i = 0\nfor data in ds.create_dict_iterator():\n    i+=1\n    if i<5:\n        print(\"question:\",type(data['question']))\n        print('{}'.format(data['question']),'{}'.format(data['label']))\n    else:\n        break", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 52, "outputs": [{"name": "stdout", "text": "question: <class 'mindspore.common.tensor.Tensor'>\n[[   4    3    2  129   80    8    0    0    0    0]\n [   3    6   47    7   10  284    0    0    0    0]\n [  11   12  171    0    0    0    0    0    0    0]\n [   4    3   14   19  858    8    0    0    0    0]\n [   4    3    2   16   20    0    0    0    0    0]\n [  11   12  373    5    7    2   27    0    0    0]\n [   4    3    2   44   31    0    0    0    0    0]\n [   3    6   10  393  111    0    0    0    0    0]\n [  11   12  135    5    7    2  240    0    0    0]\n [   3    2   37   10  187    0    0    0    0    0]\n [   5   23   17   40   10  432 1299    0    0    0]\n [   3    2  231  471    0    0    0    0    0    0]\n [ 866  533    3    8    2 1665   64 1600    0    0]\n [   3    2   16  830   50    2   18    0    0    0]\n [   3   14   10 1030    8    2  141    9    2  164]\n [  15    6  172   19   36   10 2926    0    0    0]\n [   5   14   43   39    7    2  645    0    0    0]\n [  15    2   47   79 1311    0    0    0    0    0]\n [   5   14 2325    7    2   18    0    0    0    0]\n [  11   12   17    5    7    6   18    0    0    0]\n [   3    6   10  579    0    0    0    0    0    0]\n [   3   14   59 1543   35    0    0    0    0    0]\n [  11   12  243    5    7    2  188    0    0    0]\n [   4   70    3    2   16   65    0    0    0    0]\n [  11   12 1500    5    8    2  303    0    0    0]\n [   4  304    3   21    0    0    0    0    0    0]\n [   3    6  957    7    2  191    0    0    0    0]\n [   4   26    9  138    3    6    0    0    0    0]\n [   4    5    2  372   31    0    0    0    0    0]\n [   3    2   72   20  234    0    0    0    0    0]\n [   4    3    2   72   38    0    0    0    0    0]\n [   3   14   10 1508    0    0    0    0    0    0]] [ 54   0   3 132 475  79 449   1   2   0   0   0 853   1   1   0   0   1\n   1   2   1   1   3  23   3  88   0 613 301   0  40   1]\nquestion: <class 'mindspore.common.tensor.Tensor'>\n[[  22   89    2   18   75    9    2  440    0    0]\n [   4    5   34   94    0    0    0    0    0    0]\n [   3   49 1072    0    0    0    0    0    0    0]\n [  11   89    6   18   75    0    0    0    0    0]\n [   4   15    2   28   25    8   46  241    0    0]\n [  22   89    2   18   75    0    0    0    0    0]\n [   3   21  353    0    0    0    0    0    0    0]\n [   3    6   75    7    2  334    0    0    0    0]\n [  11   12   17    5    8    2   85   37    0    0]\n [   4  111    3    6    0    0    0    0    0    0]\n [   3   21  294  199    0    0    0    0    0    0]\n [   3   51   10  347    8    2 1353    0    0    0]\n [   4   13    3    2  354    0    0    0    0    0]\n [   4   13    3    2  233    0    0    0    0    0]\n [   5   14   43  308  182   19    2   61    0    0]\n [   3    6   10  880   27    0    0    0    0    0]\n [  11   12   17    5    8    2  704    0    0    0]\n [   4   13    3    2  781  218    0    0    0    0]\n [   4   26    9   70    3   83  300    0    0    0]\n [   4    3    2   16   31   19    2  448    0    0]\n [   3   21 2198    0    0    0    0    0    0    0]\n [   3    2   42  788   25  117    9   46  244  609]\n [   4   13    5    2 3991    0    0    0    0    0]\n [  11   12  168    5  100    0    0    0    0    0]\n [   4    5   34  316    0    0    0    0    0    0]\n [   3  192  119    8    2  161  136    0    0    0]\n [   3    6   45    2  439    7  652    0    0    0]\n [   3    6   10 1726    0    0    0    0    0    0]\n [   4   13    3    2  103    0    0    0    0    0]\n [   3   49   40   10  312    0    0    0    0    0]\n [   3  344   83  464    0    0    0    0    0    0]\n [   4   13    5    2  349    0    0    0    0    0]] [748  39   1 101 532  95   1   0   2  23   1   1  11   9   1   0 534   9\n  23 687   0   1   4  10 671   1   0   0   8   1   0   4]\nquestion: <class 'mindspore.common.tensor.Tensor'>\n[[   4    3    2   17   31  110    0    0    0    0]\n [   5    2 1270  332    2  133  219    0    0    0]\n [   4   13    3    2  197    0    0    0    0    0]\n [   4    3 2625    2 3936    0    0    0    0    0]\n [  54  141    3    2 1862  166    8    0    0    0]\n [   4    3    2 1557    0    0    0    0    0    0]\n [   4   29   30  497    6   32    0    0    0    0]\n [  11   12  165  373    5    7    2   66    0    0]\n [   4   37    3    6    0    0    0    0    0    0]\n [   4    3    7    2  249    0    0    0    0    0]\n [   3    2  157   62    0    0    0    0    0    0]\n [   4    3    2  132   62  108    9    0    0    0]\n [   4   13    3    2  760  223    0    0    0    0]\n [   3    2  501  848    0    0    0    0    0    0]\n [  99    3  119    2  224    0    0    0    0    0]\n [   3    6  468  227  407   24 1725    0    0    0]\n [   4   13    3    2   45    0    0    0    0    0]\n [  15   51   79  102  228 1585    0    0    0    0]\n [   3   21   10  648   81    0    0    0    0    0]\n [   3   14  188    7    2  301    0    0    0    0]\n [  11   12  372    5   14    0    0    0    0    0]\n [   5   14   43   17   40    2   45  636    0    0]\n [   3    2   57  404   19  559   10  459    0    0]\n [   3    2  193  340    0    0    0    0    0    0]\n [   4    3    2  178  102    0    0    0    0    0]\n [   4   33    9   44    3    6    0    0    0    0]\n [   4   13    3    2  894    0    0    0    0    0]\n [   4   13    3    2  394  205    0    0    0    0]\n [   4   13    3    2   16   73    2  383    0    0]\n [   4   13    3    2  709  375   86    2   45    0]\n [  11   12   17   41   55    2  243    0    0    0]\n [   4    3    2  150   94    0    0    0    0    0]] [ 44   1   4 856  24 650  26   5  62 148   1 320  29   1 410 451   8   1\n   0   1  10   1   0   1 287 535   7   7   4   7  10 243]\nquestion: <class 'mindspore.common.tensor.Tensor'>\n[[  11   12  313    5   14    7    2   18    0    0]\n [  54    9    2  121   39    3  534    0    0    0]\n [  11   12 1275 3507    5    7    2  233    0    0]\n [   4    3    7    2  341  182   19    2  240    0]\n [   3   14   10  424  131    0    0    0    0    0]\n [   4   13    3    2  249    0    0    0    0    0]\n [  11   87    2  761   74   46  118    8    2   27]\n [   4   92    3    6    0    0    0    0    0    0]\n [   4   26    9   47    3    6    0    0    0    0]\n [  11   12  602    5  124 1364    0    0    0    0]\n [   4   13    3    2 2575  234    0    0    0    0]\n [  15    6   79  102   10  265  169    0    0    0]\n [  68    3   82   88 1883   19   82  241    0    0]\n [   4   13    3    2   58   52    0    0    0    0]\n [   3    2   57  356    0    0    0    0    0    0]\n [  11   12   17    5    7    6   27    0    0    0]\n [   4   13    3    2  383    0    0    0    0    0]\n [   4   13    3    2   42    0    0    0    0    0]\n [   5    2 2748 1016   40   46 1210    0    0    0]\n [   5    2 1547  100    0    0    0    0    0    0]\n [   4   13    3    2  184   52    8    2   74    0]\n [   3    2   18    7   13    0    0    0    0    0]\n [   3    2  152  616 1327    8    0    0    0    0]\n [  99   15    2  200  496   19    0    0    0    0]\n [   3    2  178  328    0    0    0    0    0    0]\n [   4   13    3    2 1561  612    0    0    0    0]\n [   4   13    3    2  126    0    0    0    0    0]\n [   4    3    7    2  363    0    0    0    0    0]\n [   3    2   42  588    0    0    0    0    0    0]\n [   3    2   35 1543    0    0    0    0    0    0]\n [   3    6   10  384  851    0    0    0    0    0]\n [   3   14   10  233    7    2   66    0    0    0]] [  6  54   5  82   0   4   0  75 119   3   4   0 254   9   0   2  13   4\n   0   1  15   1   1  33   1   9   8 207   0   0   0   0]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "class MyWithLossCell(nn.Cell):\n    def __init__(self, network, loss_fn):\n        super(MyWithLossCell, self).__init__(auto_prefix=False)\n        self._backbone = network\n        self._loss_fn = loss_fn\n\n    def construct(self, image, question, label):\n        out = self._backbone(image, question)\n        return self._loss_fn(out, label)\n        # return out\n\n    @property\n    def backbone_network(self):\n        return self._backbone", "metadata": {"trusted": true}, "execution_count": 54, "outputs": []}, {"cell_type": "code", "source": "opt = nn.Momentum(params=vqa.trainable_params(), learning_rate=0.1, momentum=0.9)\nloss = nn.MSELoss()\nnet_with_loss = MyWithLossCell(vqa, loss)\nnet_one_step = nn.TrainOneStepCell(net_with_loss, optimizer=opt)", "metadata": {"trusted": true}, "execution_count": 64, "outputs": []}, {"cell_type": "code", "source": "vqa.trainable_params()", "metadata": {"trusted": true}, "execution_count": 68, "outputs": [{"execution_count": 68, "output_type": "execute_result", "data": {"text/plain": "[Parameter (name=dense1.weight, shape=(1000, 1024), dtype=Float32, requires_grad=True),\n Parameter (name=dense1.bias, shape=(1000,), dtype=Float32, requires_grad=True),\n Parameter (name=dense2.weight, shape=(1024, 512), dtype=Float32, requires_grad=True),\n Parameter (name=dense2.bias, shape=(1024,), dtype=Float32, requires_grad=True),\n Parameter (name=question.embedding.embedding_table, shape=(6620, 500), dtype=Float32, requires_grad=True),\n Parameter (name=question.lstm.rnn.weight_fw0, shape=(1524, 4096), dtype=Float16, requires_grad=True),\n Parameter (name=question.lstm.rnn.bias_fw0, shape=(4096,), dtype=Float16, requires_grad=True),\n Parameter (name=vgg.layers.0.weight, shape=(64, 3, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.2.weight, shape=(64, 64, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.5.weight, shape=(128, 64, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.7.weight, shape=(128, 128, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.10.weight, shape=(256, 128, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.12.weight, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.14.weight, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.17.weight, shape=(512, 256, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.19.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.21.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.24.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.26.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n Parameter (name=vgg.layers.28.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True)]"}, "metadata": {}}]}, {"cell_type": "code", "source": "def train_eval():\n    \"\"\"Train model.\"\"\"\n    train_net = net_one_step\n    loss_list = []\n    epoch = 0\n    \n    for data in ds.create_dict_iterator():\n        epoch+=1\n        if epoch< 5:\n            train_net.set_train()\n            train_result = train_net(data['image'],data['question'],data['label'])\n            print(\"Epoch:{0}\\n loss:{1}:\".format(epoch,train_result))\n        else:\n            break", "metadata": {"trusted": true}, "execution_count": 65, "outputs": []}, {"cell_type": "code", "source": "train_eval()", "metadata": {"trusted": true}, "execution_count": 66, "outputs": [{"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)", "\u001b[0;32m<ipython-input-66-8d6533c980f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m<ipython-input-65-e95662321e72>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m#         t = time.time()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtrain_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch:{0}\\n loss:{1}:\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_hook\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The graph mode does not support hook function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_and_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36mcompile_and_run\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \"\"\"\n\u001b[1;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_parallel_compile_and_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mnew_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInput\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \"\"\"\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_parallel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_parallel_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_and_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/common/api.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, obj, phase, do_convert, auto_parallel_mode, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0menable_ge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enable_ge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0muse_vm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menable_ge\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menable_debug_runtime\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPYNATIVE_MODE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_vm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mRuntimeError\u001b[0m: mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_parallel_build.cc:99 TbeOpParallelBuild] task compile Failed, task id:201, cause:TBEException:ERROR:\n\nTraceback (most recent call last):\n  File \"/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py\", line 128, in build_op\n    res = op_func(*inputs_args, *outputs_args, *attrs_args, kernel_name=kernel_name)\n  File \"/usr/local/Ascend/nnae/latest/fwkacllib/python/site-packages/tbe/common/utils/para_check.py\", line 529, in _in_wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/Ascend/nnae/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_grad_d.py\", line 1071, in strided_slice_grad_d\n    _check_mask(shrink_axis_mask, True)\n  File \"/usr/local/Ascend/nnae/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_grad_d.py\", line 977, in _check_mask\n    raise RuntimeError(\"shrink_axis_mask only support {} currently\".format(str(supported_shrink_masks)))\nRuntimeError: shrink_axis_mask only support {0, 2, 4} currently\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py\", line 173, in <module>\n    result = compile_with_json(in_args)\n  File \"/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py\", line 167, in compile_with_json\n    ret = build_op(op_build, json_str, None)\n  File \"/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py\", line 134, in build_op\n    raise RuntimeError(e)\nRuntimeError: shrink_axis_mask only support {0, 2, 4} currently\n\ninput_args: {\"SocInfo\":{\"autoTilingMode\":\"NO_TUNE\",\"coreNum\":\"\",\"coreType\":\"\",\"l1Fusion\":\"false\",\"l2Fusion\":\"false\",\"l2Mode\":\"2\",\"op_debug_level\":\"\",\"op_impl_mode\":\"\",\"op_impl_mode_list\":[],\"socVersion\":\"Ascend910A\"},\"impl_path\":\"\",\"op_info\":{\"Type\":\"StridedSliceGrad\",\"attr_desc\":[[1,32,1024],[0,0,0],[1,32,1024],[1,1,1],0,0,0,0,1],\"attrs\":[{\"name\":\"shapex\",\"valid\":true,\"value\":[1,32,1024]},{\"name\":\"begin\",\"valid\":true,\"value\":[0,0,0]},{\"name\":\"end\",\"valid\":true,\"value\":[1,32,1024]},{\"name\":\"strides\",\"valid\":true,\"value\":[1,1,1]},{\"name\":\"begin_mask\",\"valid\":true,\"value\":0},{\"name\":\"end_mask\",\"valid\":true,\"value\":0},{\"name\":\"ellipsis_mask\",\"valid\":true,\"value\":0},{\"name\":\"new_axis_mask\",\"valid\":true,\"value\":0},{\"name\":\"shrink_axis_mask\",\"valid\":true,\"value\":1}],\"full_name\":\"Gradients/Default/network-MyWithLossCell/_backbone-VQA/gradStridedSlice/StridedSliceGrad-op816\",\"gen_model\":\"single\",\"graph_id\":67,\"inputs\":[[{\"dtype\":\"float16\",\"format\":\"NCHW\",\"name\":\"dy_0\",\"ori_format\":\"NCHW\",\"ori_shape\":[32,1024],\"param_type\":\"required\",\"range\":[[32,32],[1024,1024]],\"shape\":[32,1024],\"valid\":true}]],\"is_dynamic_shape\":false,\"kernel_name\":\"StridedSliceGrad_11066002694720751291_0\",\"module_name\":\"impl.strided_slice_grad_d\",\"name\":\"strided_slice_grad_d\",\"outputs\":[[{\"dtype\":\"float16\",\"format\":\"NCHW\",\"name\":\"output\",\"ori_format\":\"NCHW\",\"ori_shape\":[1,32,1024],\"param_type\":\"required\",\"range\":[[1,1],[32,32],[1024,1024]],\"shape\":[1,32,1024],\"valid\":true}]],\"py_module_path\":\"/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe\",\"socVersion\":\"Ascend910A\"},\"platform\":\"TBE\"} trace: \nIn file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/ops/_grad/grad_array_ops.py(627)/        dx = input_grad(dout, shape_op(x), begin, end, strides)/\n\n\n# "], "ename": "RuntimeError", "evalue": "mindspore/ccsrc/backend/kernel_compiler/tbe/tbe_kernel_parallel_build.cc:99 TbeOpParallelBuild] task compile Failed, task id:201, cause:TBEException:ERROR:\n\nTraceback (most recent call last):\n  File \"/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py\", line 128, in build_op\n    res = op_func(*inputs_args, *outputs_args, *attrs_args, kernel_name=kernel_name)\n  File \"/usr/local/Ascend/nnae/latest/fwkacllib/python/site-packages/tbe/common/utils/para_check.py\", line 529, in _in_wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/Ascend/nnae/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_grad_d.py\", line 1071, in strided_slice_grad_d\n    _check_mask(shrink_axis_mask, True)\n  File \"/usr/local/Ascend/nnae/latest/opp/op_impl/built-in/ai_core/tbe/impl/strided_slice_grad_d.py\", line 977, in _check_mask\n    raise RuntimeError(\"shrink_axis_mask only support {} currently\".format(str(supported_shrink_masks)))\nRuntimeError: shrink_axis_mask only support {0, 2, 4} currently\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py\", line 173, in <module>\n    result = compile_with_json(in_args)\n  File \"/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py\", line 167, in compile_with_json\n    ret = build_op(op_build, json_str, None)\n  File \"/home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/_extends/parallel_compile/tbe_compiler/compiler.py\", line 134, in build_op\n    raise RuntimeError(e)\nRuntimeError: shrink_axis_mask only support {0, 2, 4} currently\n\ninput_args: {\"SocInfo\":{\"autoTilingMode\":\"NO_TUNE\",\"coreNum\":\"\",\"coreType\":\"\",\"l1Fusion\":\"false\",\"l2Fusion\":\"false\",\"l2Mode\":\"2\",\"op_debug_level\":\"\",\"op_impl_mode\":\"\",\"op_impl_mode_list\":[],\"socVersion\":\"Ascend910A\"},\"impl_path\":\"\",\"op_info\":{\"Type\":\"StridedSliceGrad\",\"attr_desc\":[[1,32,1024],[0,0,0],[1,32,1024],[1,1,1],0,0,0,0,1],\"attrs\":[{\"name\":\"shapex\",\"valid\":true,\"value\":[1,32,1024]},{\"name\":\"begin\",\"valid\":true,\"value\":[0,0,0]},{\"name\":\"end\",\"valid\":true,\"value\":[1,32,1024]},{\"name\":\"strides\",\"valid\":true,\"value\":[1,1,1]},{\"name\":\"begin_mask\",\"valid\":true,\"value\":0},{\"name\":\"end_mask\",\"valid\":true,\"value\":0},{\"name\":\"ellipsis_mask\",\"valid\":true,\"value\":0},{\"name\":\"new_axis_mask\",\"valid\":true,\"value\":0},{\"name\":\"shrink_axis_mask\",\"valid\":true,\"value\":1}],\"full_name\":\"Gradients/Default/network-MyWithLossCell/_backbone-VQA/gradStridedSlice/StridedSliceGrad-op816\",\"gen_model\":\"single\",\"graph_id\":67,\"inputs\":[[{\"dtype\":\"float16\",\"format\":\"NCHW\",\"name\":\"dy_0\",\"ori_format\":\"NCHW\",\"ori_shape\":[32,1024],\"param_type\":\"required\",\"range\":[[32,32],[1024,1024]],\"shape\":[32,1024],\"valid\":true}]],\"is_dynamic_shape\":false,\"kernel_name\":\"StridedSliceGrad_11066002694720751291_0\",\"module_name\":\"impl.strided_slice_grad_d\",\"name\":\"strided_slice_grad_d\",\"outputs\":[[{\"dtype\":\"float16\",\"format\":\"NCHW\",\"name\":\"output\",\"ori_format\":\"NCHW\",\"ori_shape\":[1,32,1024],\"param_type\":\"required\",\"range\":[[1,1],[32,32],[1024,1024]],\"shape\":[1,32,1024],\"valid\":true}]],\"py_module_path\":\"/usr/local/Ascend/opp/op_impl/built-in/ai_core/tbe\",\"socVersion\":\"Ascend910A\"},\"platform\":\"TBE\"} trace: \nIn file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/ops/_grad/grad_array_ops.py(627)/        dx = input_grad(dout, shape_op(x), begin, end, strides)/\n\n\n# ", "output_type": "error"}]}, {"cell_type": "code", "source": "model = Model(net_one_step)\nmodel.train(1,ds)", "metadata": {}, "execution_count": 167, "outputs": [{"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)", "\u001b[0;32m<ipython-input-167-486dda2f5abb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_one_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size)\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                     \u001b[0mdataset_sink_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_sink_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                     sink_size=sink_size)\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_eval_dataset_sink_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, epoch, train_dataset, callbacks, dataset_sink_mode, sink_size)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_dataset_sink_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msink_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/train/model.py\u001b[0m in \u001b[0;36m_train_dataset_sink_process\u001b[0;34m(self, epoch, train_dataset, list_callback, cb_params, sink_size)\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mcb_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataset_element\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m                 \u001b[0mlist_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mis_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                     \u001b[0mcb_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcur_step_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdataset_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msink_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_hook\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The graph mode does not support hook function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_and_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36mcompile_and_run\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \"\"\"\n\u001b[1;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_parallel_compile_and_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mnew_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInput\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m         \"\"\"\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_parallel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_parallel_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_and_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/common/api.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, obj, phase, do_convert, auto_parallel_mode, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0menable_ge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enable_ge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0muse_vm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menable_ge\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menable_debug_runtime\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPYNATIVE_MODE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_vm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mRuntimeError\u001b[0m: mindspore/ccsrc/backend/session/ascend_session.cc:905 BuildKernel] Kernel build error.\n\n# "], "ename": "RuntimeError", "evalue": "mindspore/ccsrc/backend/session/ascend_session.cc:905 BuildKernel] Kernel build error.\n\n# ", "output_type": "error"}]}, {"cell_type": "code", "source": "from mindspore import dtype as mstype\ntest_batch = 8\nall_question_idx = Tensor(np.array(all_question_idx),mstype.int32)\nx = all_question_idx[0:8,]\n#modify\nembedding = nn.Embedding(options['dict_size'], options['n_emb'],True)\nembeddings = embedding(x)\n#\u8fd9\u91cc\u76848\u662fbatch_size\nh = Tensor(np.zeros((1,8, options['n_dim']), dtype='float32'))\nc = Tensor(np.zeros((1,8, options['n_dim']), dtype='float32'))\n        \nnet = nn.LSTM(options['n_emb'],options['n_dim'],1,True,True)\noutput,(h1,c1) = net(embeddings, (h,c))\nh_encode = h1[0][-1]\nh_encode = h_encode[None,:]\n# h_encode.shape 1,1024", "metadata": {}, "execution_count": 1, "outputs": [{"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[0;32m<ipython-input-1-d71561f3e0b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmindspore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmstype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_question_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_question_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmstype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_question_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#modify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mNameError\u001b[0m: name 'Tensor' is not defined"], "ename": "NameError", "evalue": "name 'Tensor' is not defined", "output_type": "error"}]}, {"cell_type": "code", "source": "image_feat = fflayer(shared_params, image_feat, options,\n                        prefix='image_mlp',\n                        act_func='tanh')\nimage_feat = image_feat[0]\n#image_feat.shape 196,1024\n        \nimage_feat_down = image_feat\n#image_feat_down.shape 196,1024\n        \nimage_feat_attention_1 = fflayer(shared_params, image_feat_down, options,\n                                    prefix='image_att_mlp_1',\n                                    act_func='tanh')\n        #image_feat_attention_1.shape 196,512\n\n        \nh_encode_attention_1 = fflayer(shared_params, h_encode, options,\n                                prefix='sent_att_mlp_1',\n                                act_func='tanh')\n        #h_encode_attentioshapehape 1,512\n        \ncombined_feat_attention_1 = image_feat_attention_1 + \\\n                    h_encode_attention_1[:, None, :]\n        #combined_feat_attention_1.shape 1,196,512\n\n        #if options['use_attention_drop']:\n        #combined_feat_attention_1 = dropout_layer(combined_feat_attention_1,\n                                                #dropout, trng, drop_ratio)\ncombined_feat_attention_1 = fflayer1(shared_params,\n                            combined_feat_attention_1, options,\n                            prefix='combined_att_mlp_1',)\n        #combined_feat_attention_1.shape 1,196,1\n        \nsoftmax = nn.Softmax()\nprob_attention_1 = softmax(combined_feat_attention_1[:, :, 0])\n        #prob_attention_1.shape 1,196\n\nimage_feat_ave_1 = (prob_attention_1[:, :, None] * image_feat_down).asnumpy().sum(axis=1)\nimage_feat_ave_1 = Tensor(image_feat_ave_1)\n        \ncombined_hidden_1 = image_feat_ave_1 + h_encode\n        #combined_hidden_1 1,1024", "metadata": {}, "execution_count": 33, "outputs": []}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "def lstm_layer(shared_params, x, mask, h_0, c_0, options, prefix='lstm'):\n    ''' lstm layer:\n    :param shared_params: shared parameters\n    :param x: input, T x batch_size x n_emb\n    :param mask: mask for x, T x batch_size\n    '''\n    n_emb = options['n_emb']\n    n_dim = options['n_dim']\n    # weight matrix for x, n_emb x 4*n_dim (ifoc)\n    lstm_w_x = shared_params[prefix + '_w_x']\n    # weight matrix for h, n_dim x 4*n_dim\n    lstm_w_h = shared_params[prefix + '_w_h']\n    lstm_b_h = shared_params[prefix + '_b_h']\n    h_0 = h_0[:x.shape[1]]\n    c_0 = c_0[:x.shape[1]]\n    question_net = LSTM(n_emb, n_dim)\n    output, (h, c) = question_net(x, (h_0, c_0))\n    return h, c", "metadata": {}, "execution_count": 21, "outputs": []}, {"cell_type": "code", "source": "def build_model(shared_params, options):\n    #input_idx = Tensor.imatrix('input_idx')\n    input_idx = Tensor()\n    global empty_word\n    empty_word = np.zeros((1, options['n_emb']), dtype='float32')\n    w_emb_extend = Tensor.concatenate([empty_word, shared_params['w_emb']],\n                                 axis=0)\n    input_emb = w_emb_extend[input_idx]\n    \n    # get the transformed image feature\n    global h_0, c_0\n    h_0 = np.zeros((batch_size, n_dim), dtype='float32')\n    c_0 = np.zeros((batch_size, n_dim), dtype='float32')\n    h_encode, c_encode = lstm_layer(shared_params, input_emb, input_mask,\n                                    h_0, c_0, options, prefix='sent_lstm')\n    return h_encodem, c_encode", "metadata": {}, "execution_count": 22, "outputs": []}]}