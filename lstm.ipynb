{"metadata": {"language_info": {"name": "python", "version": "3.7.6", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "mindspore-python3.7-aarch64", "display_name": "MindSpore-python3.7-aarch64", "language": "python"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "## 1.\u5bfc\u5165\u6a21\u5757", "metadata": {}}, {"cell_type": "code", "source": "import moxing as mox\n\ndata_url = \"s3://nlp.final/san/data/\"\ncode_url = \"s3://nlp.final/san/code/image_model/src\"\n# mox.file.copy_parallel(src_url=\"obs://nlp-kim/project/data/\", dst_url='./data/') \n# mox.file.copy_parallel(src_url=\"s3://dl4nlp-my/project/data/\", dst_url='./data/') \nmox.file.copy_parallel(src_url = code_url,dst_url='./src/')", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 1, "outputs": [{"name": "stderr", "text": "INFO:root:Using MoXing-v1.17.3-d858ff4a\nINFO:root:Using OBS-Python-SDK-3.20.9.1\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=data_url, dst_url='./data/') ", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 2, "outputs": [{"name": "stderr", "text": "INFO:root:Listing OBS: 1000\nINFO:root:Listing OBS: 2000\nINFO:root:Listing OBS: 3000\nINFO:root:Listing OBS: 4000\nINFO:root:Listing OBS: 5000\nINFO:root:Listing OBS: 6000\nINFO:root:Listing OBS: 7000\nINFO:root:Listing OBS: 8000\nINFO:root:Listing OBS: 9000\nINFO:root:Listing OBS: 10000\nINFO:root:Listing OBS: 11000\nINFO:root:Listing OBS: 12000\nINFO:root:Listing OBS: 13000\nINFO:root:Listing OBS: 14000\nINFO:root:Listing OBS: 15000\nINFO:root:Listing OBS: 16000\nINFO:root:Listing OBS: 17000\nINFO:root:Listing OBS: 18000\nINFO:root:Listing OBS: 19000\nINFO:root:Listing OBS: 20000\nINFO:root:Listing OBS: 21000\nINFO:root:Listing OBS: 22000\nINFO:root:Listing OBS: 23000\nINFO:root:Listing OBS: 24000\nINFO:root:Listing OBS: 25000\nINFO:root:Listing OBS: 26000\nINFO:root:Listing OBS: 27000\nINFO:root:Listing OBS: 28000\nINFO:root:Listing OBS: 29000\nINFO:root:Listing OBS: 30000\nINFO:root:Listing OBS: 31000\nINFO:root:Listing OBS: 32000\nINFO:root:Listing OBS: 33000\nINFO:root:Listing OBS: 34000\nINFO:root:Listing OBS: 35000\nINFO:root:Listing OBS: 36000\nINFO:root:Listing OBS: 37000\nINFO:root:Listing OBS: 38000\nINFO:root:Listing OBS: 39000\nINFO:root:Listing OBS: 40000\nINFO:root:Listing OBS: 41000\nINFO:root:Listing OBS: 42000\nINFO:root:Listing OBS: 43000\nINFO:root:Listing OBS: 44000\nINFO:root:Listing OBS: 45000\nINFO:root:Listing OBS: 46000\nINFO:root:Listing OBS: 47000\nINFO:root:Listing OBS: 48000\nINFO:root:Listing OBS: 49000\nINFO:root:Listing OBS: 50000\nINFO:root:Listing OBS: 51000\nINFO:root:Listing OBS: 52000\nINFO:root:Listing OBS: 53000\nINFO:root:Listing OBS: 54000\nINFO:root:Listing OBS: 55000\nINFO:root:Listing OBS: 56000\nINFO:root:Listing OBS: 57000\nINFO:root:Listing OBS: 58000\nINFO:root:Listing OBS: 59000\nINFO:root:Listing OBS: 60000\nINFO:root:Listing OBS: 61000\nINFO:root:Listing OBS: 62000\nINFO:root:Listing OBS: 63000\nINFO:root:Listing OBS: 64000\nINFO:root:Listing OBS: 65000\nINFO:root:Listing OBS: 66000\nINFO:root:Listing OBS: 67000\nINFO:root:Listing OBS: 68000\nINFO:root:Listing OBS: 69000\nINFO:root:Listing OBS: 70000\nINFO:root:Listing OBS: 71000\nINFO:root:pid: None.\t1000/71899\nINFO:root:pid: None.\t2000/71899\nINFO:root:pid: None.\t3000/71899\nINFO:root:pid: None.\t4000/71899\nINFO:root:pid: None.\t5000/71899\nINFO:root:pid: None.\t6000/71899\nINFO:root:pid: None.\t7000/71899\nINFO:root:pid: None.\t8000/71899\nINFO:root:pid: None.\t9000/71899\nINFO:root:pid: None.\t10000/71899\nINFO:root:pid: None.\t11000/71899\nINFO:root:pid: None.\t12000/71899\nINFO:root:pid: None.\t13000/71899\nINFO:root:pid: None.\t14000/71899\nINFO:root:pid: None.\t15000/71899\nINFO:root:pid: None.\t16000/71899\nINFO:root:pid: None.\t17000/71899\nINFO:root:pid: None.\t18000/71899\nINFO:root:pid: None.\t19000/71899\nINFO:root:pid: None.\t20000/71899\nINFO:root:pid: None.\t21000/71899\nINFO:root:pid: None.\t22000/71899\nINFO:root:pid: None.\t23000/71899\nINFO:root:pid: None.\t24000/71899\nINFO:root:pid: None.\t25000/71899\nINFO:root:pid: None.\t26000/71899\nINFO:root:pid: None.\t27000/71899\nINFO:root:pid: None.\t28000/71899\nINFO:root:pid: None.\t29000/71899\nINFO:root:pid: None.\t30000/71899\nINFO:root:pid: None.\t31000/71899\nINFO:root:pid: None.\t32000/71899\nINFO:root:pid: None.\t33000/71899\nINFO:root:pid: None.\t34000/71899\nINFO:root:pid: None.\t35000/71899\nINFO:root:pid: None.\t36000/71899\nINFO:root:pid: None.\t37000/71899\nINFO:root:pid: None.\t38000/71899\nINFO:root:pid: None.\t39000/71899\nINFO:root:pid: None.\t40000/71899\nINFO:root:pid: None.\t41000/71899\nINFO:root:pid: None.\t42000/71899\nINFO:root:pid: None.\t43000/71899\nINFO:root:pid: None.\t44000/71899\nINFO:root:pid: None.\t45000/71899\nINFO:root:pid: None.\t46000/71899\nINFO:root:pid: None.\t47000/71899\nINFO:root:pid: None.\t48000/71899\nINFO:root:pid: None.\t49000/71899\nINFO:root:pid: None.\t50000/71899\nINFO:root:pid: None.\t51000/71899\nINFO:root:pid: None.\t52000/71899\nINFO:root:pid: None.\t53000/71899\nINFO:root:pid: None.\t54000/71899\nINFO:root:pid: None.\t55000/71899\nINFO:root:pid: None.\t56000/71899\nINFO:root:pid: None.\t57000/71899\nINFO:root:pid: None.\t58000/71899\nINFO:root:pid: None.\t59000/71899\nINFO:root:pid: None.\t60000/71899\nINFO:root:pid: None.\t61000/71899\nINFO:root:pid: None.\t62000/71899\nINFO:root:pid: None.\t63000/71899\nINFO:root:pid: None.\t64000/71899\nINFO:root:pid: None.\t65000/71899\nINFO:root:pid: None.\t66000/71899\nINFO:root:pid: None.\t67000/71899\nINFO:root:pid: None.\t68000/71899\nINFO:root:pid: None.\t69000/71899\nINFO:root:pid: None.\t70000/71899\nINFO:root:pid: None.\t71000/71899\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "import sys\nimport os\nimport json\nimport pickle as pkl\nimport re\nfrom collections import Counter\nimport numpy as np\nimport random\n\nfrom collections import OrderedDict\nimport math\n\nimport mindspore\nimport mindspore.nn as nn\nfrom mindspore import Tensor,Model\nfrom mindspore import context\nfrom mindspore.train.model import Model\nfrom mindspore.nn.metrics import Accuracy\nfrom mindspore.train.serialization import load_checkpoint, load_param_into_net\nfrom mindspore.train.callback import ModelCheckpoint, CheckpointConfig, LossMonitor, TimeMonitor\n#from mindspore.ops import operations as ops\nfrom mindspore import ops\nfrom mindspore import dtype as mstype", "metadata": {"trusted": true}, "execution_count": 3, "outputs": []}, {"cell_type": "markdown", "source": "## 2.\u6570\u636e\u9884\u5904\u7406", "metadata": {}}, {"cell_type": "markdown", "source": "### 2.1 \u5904\u7406\u51fd\u6570\u53ca\u521d\u59cb\u5316\u51fd\u6570", "metadata": {}}, {"cell_type": "code", "source": "# mox.file.copy_parallel(src_url=\"obs://nlp-kim/project/code/data_vqa/process_func.py\", dst_url='./process_func.py')\n# mox.file.copy_parallel(src_url=\"obs://nlp-kim/project/code/data_vqa/initialization.py\", dst_url='./initialization.py')\nmox.file.copy_parallel(src_url = \"s3://nlp.final/san/code/data_vqa\",dst_url=\"./data_vqa\")\nfrom data_vqa.process_func import *\n#from data_vqa.initialization import *\nfrom data_vqa.vqa_dataset_by_api import create_dataset\nfrom data_vqa.vqa_config import train,test,val", "metadata": {"trusted": true}, "execution_count": 4, "outputs": []}, {"cell_type": "markdown", "source": "### 2.2 \u53d8\u91cf\u8bf4\u660e", "metadata": {}}, {"cell_type": "code", "source": "#qa\uff1aquestion\u548c\u5bf9\u5e94\u7684annotions\n#train_question_ids\uff1aquestion\u7684id\u7684\u6570\u7ec4\n\n#question_dict_count\uff1a question\u4e2d\u7684\u5355\u8bcd\u51fa\u73b0\u6b21\u6570\u7edf\u8ba1\n#train_questions\uff1a question\u8bed\u53e5split\u4e3aword\u7684\u6570\u7ec4\u7684\u6570\u7ec4\n#answer_dict_count\uff1a answer\u4e2d\u7684\u5355\u8bcd\u51fa\u73b0\u6b21\u6570\u7edf\u8ba1\n#train_answers\uff1a answer\u88absplit\u4e3aword\u7684\u6570\u7ec4\u7684\u6570\u7ec4\n\n#question_key\uff1a\u6309\u7167question\u4e2d\u51fa\u73b0\u6b21\u6570\u8fdb\u884c\u6392\u5e8f\n#answer_top_k: \u6309\u7167answer\u4e2d\u51fa\u73b0\u7684\u6b21\u6570\u8fdb\u884c\u6392\u5e8f\n", "metadata": {"trusted": true}, "execution_count": 5, "outputs": []}, {"cell_type": "markdown", "source": "### 2.3 \u9884\u5904\u7406\u7ec6\u8282", "metadata": {}}, {"cell_type": "code", "source": "f = open(\"./data/questions/train.json\", \"r\")\nf1 = open(\"./data/annotations/train.json\", \"r\")\nfile = json.load(f)\nfile1 = json.load(f1)\nannotations = file1['annotations']\ntrain_question_ids = []\ntrain_image_ids = []\ntrain_questions = []\ntrain_answers = []\nquestion_dict_count = dict()\nanswer_dict_count = dict()\n\n# \u5f62\u6210qa\uff1a\u4e00\u4e2a\u5b57\u5178\uff0c\u6574\u7406\u51fa\u5bf9\u5e94question_id\u7684annotation\nqa = {ann['question_id']: [] for ann in annotations}\nfor ann in annotations:\n    qa[ann['question_id']] = ann\n\n#\u83b7\u53d6image_id question_id\n# \u9700\u8981\u8fdb\u884c\u5c01\u88c5\u4ee5\u9002\u7528\u4e8e\u8bad\u7ec3\u3001\u6d4b\u8bd5\u3001\u8bc4\u4f30\nimg_not_exist_count = 0\nfor idx, item in enumerate(file['questions']):\n    img_path = os.path.join(\"./data/images/train\",\"COCO_{0}2014_{1}.jpg\".format(\"train\",str(item['image_id']).zfill(12)))\n    if not os.path.exists(img_path):\n        img_not_exist_count += 1\n        continue\n\n    train_question_ids.append(item['question_id'])\n    train_image_ids.append(item['image_id'])\n    \n    #process question\n    question = item['question']\n    question = process_sentence(question)\n    question = question.split()\n    for word in question:\n        question_dict_count[word] = question_dict_count.get(word, 0) + 1\n    train_questions.append(question)\n    answer = qa[item['question_id']]['answers']\n    answer_new = [process_answer(ans['answer']) for ans in answer]\n    ans_array = []\n    for ans in answer:\n        ans_array.append(ans['answer'])\n    for word in answer_new:\n        answer_dict_count[word] = answer_dict_count.get(word, 0) + 1\n    train_answers.append(ans_array)\n    if idx % 10000 == 0:\n        print ('finished processing %d in train' %(idx))\n\n# sort question dict\nquestion_count = question_dict_count.values()\nsorted_index = [count[0] for count in\n                sorted(enumerate(question_count),\n                       key = lambda x : x[1],\n                       reverse=True)]\nsorted_count = sorted(question_count, reverse=True)\nquestion_key = list(question_dict_count.keys())\n# \u5bf9question_key\u91cd\u65b0\u6392\u5e8f\nquestion_key = [question_key[idx] for idx in sorted_index]\n# add '<unk>' to the begining\nquestion_key.insert(0, '<unk>')\n# '<unk>' begins at 1, 0 is reserved for empty words\nquestion_key = dict((key, idx + 1) for idx, key in enumerate(question_key))\n\nk = 1000\n# sort answer dict and get top k answers\n\n#\u56e0\u62a5\u9519\u6682\u5220\n# del answer_dict_count['']\nanswer_count = answer_dict_count.values()\nsorted_index = [count[0] for count in\n                sorted(enumerate(answer_count),\n                       key = lambda x : x[1],\n                       reverse=True)]\nsorted_count = sorted(answer_count, reverse=True)\nanswer_key = list(answer_dict_count.keys())\nanswer_key = [answer_key[idx] for idx in sorted_index]\nanswer_top_k = answer_key[:k]\nanswer_top_k = dict((key, idx) for idx, key in enumerate(answer_top_k))\n\n# convert words to idx and remove some\ntrain_question_idx = []\ntrain_answer_idx = []\ntrain_answer_counter = []\nidx_to_remove = []\nfor idx, answer in enumerate(train_answers):\n    question_idx = [question_key[word] for word in train_questions[idx]]\n    #print(question_idx)\n    #print('\\n')\n    #print(train_questions[idx])\n    train_question_idx.append(question_idx)\n    answer_idx = [answer_top_k[ans] for ans in answer\n                 if ans in answer_top_k]\n    answer_counter = Counter(answer_idx)\n    train_answer_counter.append(answer_counter)\n    train_answer_idx.append(answer_idx)\n    if not answer_idx:\n        idx_to_remove.append(idx)\nprint ('%d out of %d, %f of the question in train are removed'\\\n    %(len(idx_to_remove), len(train_question_ids),\n      len(idx_to_remove) / float(len(train_question_ids))))\n\n# transform to array and delete all the empty answer\ntrain_question_ids = np.array(train_question_ids)\ntrain_image_ids = np.array(train_image_ids)\ntrain_question_idx = np.array(train_question_idx)\ntrain_answer_idx = np.array(train_answer_idx)\ntrain_answer_counter = np.array(train_answer_counter)\n\ntrain_question_ids = np.delete(train_question_ids, idx_to_remove)\ntrain_image_ids = np.delete(train_image_ids, idx_to_remove)\ntrain_question_idx = np.delete(train_question_idx, idx_to_remove)\ntrain_answer_idx = np.delete(train_answer_idx, idx_to_remove)\ntrain_answer_counter = np.delete(train_answer_counter, idx_to_remove)\n\n# reshuffle the train data\nidx_shuffle = list(range(train_question_ids.shape[0]))\nrandom.shuffle(idx_shuffle)\ntrain_question_ids = train_question_ids[idx_shuffle]\ntrain_image_ids = train_image_ids[idx_shuffle]\ntrain_question_idx = train_question_idx[idx_shuffle]\ntrain_answer_idx = train_answer_idx[idx_shuffle]\ntrain_answer_counter = train_answer_counter[idx_shuffle]\n\n# the most frequent as label\ntrain_answer_label = [counter.most_common(1)[0][0]\n                      for counter in train_answer_counter]\ntrain_answer_label = np.array(train_answer_label)\n\n# transform from counter to dict\ntrain_answer_counter = [dict(counter) for counter in train_answer_counter]\ntrain_answer_counter = np.array(train_answer_counter)\n\nprint ('finished processing train')\n\nprint('{0} images not exist'.format(img_not_exist_count))", "metadata": {"trusted": true}, "execution_count": 6, "outputs": [{"name": "stdout", "text": "finished processing 10000 in train\nfinished processing 20000 in train\n950 out of 23071, 0.041177 of the question in train are removed\nfinished processing train\n21304 images not exist\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "import math\nimport os\nimport json\nimport numpy as np\n\n\nimport mindspore.dataset.vision.py_transforms as vision\nimport mindspore.dataset as de\nfrom PIL import Image\nfrom easydict import EasyDict as edict\n\ndef img2tensor(img):\n    # mean = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n    # std = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n    mean = [0.485, 0.456, 0.406]\n    std = [0.229, 0.224, 0.225]\n    transform = edict({\n        \"ToPIL\": vision.ToPIL(),\n        \"Decode\": vision.Decode(),\n        \"Resize\": vision.Resize((512, 512)),\n        \"CenterCrop\": vision.CenterCrop(448),\n        \"ToTensor\":vision.ToTensor(),\n        # \"Rescale\":vision.Rescale(1.0/255.0,0.0),\n        \"Normalize\": vision.Normalize(mean=mean, std=std),\n        \"HWC2CHW\": vision.HWC2CHW(),\n    })\n    # print(\"input image:\",img.shape)\n    img = transform.HWC2CHW(img) / 255\n    # print(\"before normaize\",img)\n    # img = (img - mean[:, None, None]) / std[:, None, None]\n    img = transform.Normalize(img)\n    # print('img after normalize:',img)\n    # print(\"totensor:\",img)\n    # img = [img]\n    # tensor = Tensor(img,mstype.float32)\n    # return tensor\n    return img\n    \ndef create_dataset(batch_size,mode = 'train',drop_remainder=True,q_dict = None,a_dict=None):\n    dataset = VQADataset(mode,q_dict = q_dict,a_dict = a_dict)\n    sampler = DistributedSampler(dataset)\n\n    de_dataset = de.GeneratorDataset(dataset, [\"image\", \"question\",\"label\"],shuffle=False,sampler=sampler)\n    de_dataset = de_dataset.map(operations=img2tensor, input_columns=\"image\", num_parallel_workers=8)\n    # de_dataset = de_dataset.map(operations=None, input_columns=\"question\", num_parallel_workers=8)\n    # de_dataset = de_dataset.map(operations=None, input_columns=\"label\", num_parallel_workers=8)\n    de_dataset = de_dataset.project(columns=['image','question','label'])\n    de_dataset = de_dataset.batch(batch_size, drop_remainder=drop_remainder)\n    \n    return de_dataset\n    \nclass DistributedSampler():\n    \"\"\"\n    sampling the dataset.\n    Args:\n    Returns:\n        num_samples, number of samples.\n    \"\"\"\n    def __init__(self, dataset, rank=0, group_size=1, shuffle=True, seed=0):\n        self.dataset = dataset\n        self.rank = rank\n        self.group_size = group_size\n        self.dataset_length = len(self.dataset)\n        self.num_samples = int(math.ceil(self.dataset_length * 1.0 / self.group_size))\n        self.total_size = self.num_samples * self.group_size\n        self.shuffle = shuffle\n        self.seed = seed\n\n    def __iter__(self):\n        if self.shuffle:\n            self.seed = (self.seed + 1) & 0xffffffff\n            np.random.seed(self.seed)\n            indices = np.random.permutation(self.dataset_length).tolist()\n        else:\n            indices = list(range(len(self.dataset_length)))\n\n        indices += indices[:(self.total_size - len(indices))]\n        indices = indices[self.rank::self.group_size]\n        return iter(indices)\n\n    def __len__(self):\n        return self.num_samples\n\nclass VQADataset:\n    \"\"\"\n    Args:\n    mode: train/val/test\n    cfg: \n    Returns:\n        de_dataset.\n    \"\"\"\n    def __init__(self, mode = \"train\",q_dict =None,a_dict = None):\n        super(VQADataset, self).__init__()\n        self.Resize =  vision.Resize((512, 512))\n        self.CenterCrop =  vision.CenterCrop(448)\n        self.images = []   # image paths\n        self.questions = []   #  questions \u5e94\u8be5\u662f\u5df2\u7ecf\u8f6c\u6362\u6210one-hot\u7684\u7f16\u7801\n        self.answers = []   # answers   \u5bf9\u5e94\u7684\u6b63\u786e\u7b54\u6848\n        self.q_dict = q_dict\n        self.a_dict = a_dict\n        ann = {}\n        ques = {}\n        if mode == \"train\":\n            ann = json.load(open(train.annotation,'r'))\n            ques = json.load(open(train.question,'r'))\n        elif mode == 'test':\n            ann = json.load(open(test.annotation,'r'))\n            ques = json.load(open(test.question,'r'))\n        else:\n            ann = json.load(open(val.annotation,'r'))\n            ques = json.load(open(val.question,'r'))\n        \n        self.question_dict = {item['question_id']:item['question'] for item in ques['questions']}\n        annotations = ann['annotations']\n        img_not_exist_count = 0\n        for index,item in enumerate(annotations):\n            img_path = os.path.join(train.image,\"COCO_{0}2014_{1}.jpg\".format(mode,str(item['image_id']).zfill(12)))\n            if not os.path.exists(img_path):  # filter non-existing image\n                img_not_exist_count += 1\n                continue\n            \n            answers = item['answers']     # filter blank answer\n            if len(answers) == 0:\n                continue\n            \n            election = dict() \n            for index,ans in enumerate(answers):\n                if ans['answer_confidence'] == 'yes':\n                    election[ans['answer']] = election.get(ans['answer'],0)+1\n            if not election:\n                continue\n                \n            elected = max(election, key=election.get)\n            if not elected in self.a_dict:\n                continue\n\n            self.answers.append(elected)\n            self.images.append(img_path)\n            self.questions.append(item['question_id'])\n            \n\n    def __getitem__(self, index):\n        image = Image.open(self.images[index]).convert('RGB')\n        image = self.Resize(image)\n        image = self.CenterCrop(image)\n        # image = self.images[index]\n\n        question_str = self.question_dict[self.questions[index]]\n        question = process_sentence(question_str)\n        question = question.split()\n        question = convert_sentence_to_vec(question,self.q_dict)\n\n        answer = self.a_dict[self.answers[index]]\n        return image, question,index\n\n    def __len__(self):\n        return len(self.questions)\n", "metadata": {"trusted": true}, "execution_count": 7, "outputs": []}, {"cell_type": "markdown", "source": "### 2.4 \u6784\u5efa\u8bcd\u5411\u91cf", "metadata": {}}, {"cell_type": "code", "source": "# #\u4e0d\u7528\u8dd1\u8fd9\u6bb5\n# #construct one hot vector\n# all_question_vector=[]\n# for idx,question in enumerate(train_questions):\n#     count = 0\n#     question_vector = []\n#     for word in question:\n#         count = count + 1\n#         if count > 10:\n#             break\n#         else:\n#             q_emb = np.zeros((len(question_key) + 1), dtype='int32')\n#             q_emb[question_key[word]] = 1\n#             question_vector.append(q_emb)\n#     while count < 10:\n#         padding = np.zeros((len(question_key) + 1), dtype='int32')\n#         question_vector.append(padding)\n#         count = count + 1\n#     all_question_vector.append(question_vector)", "metadata": {"trusted": true}, "execution_count": 8, "outputs": []}, {"cell_type": "code", "source": "#convert word to idx\nall_question_idx = []\nfor question in train_questions:\n    all_question_idx.append(convert_sentence_to_vec(question, question_key))\nall_question_idx", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 9, "outputs": [{"execution_count": 9, "output_type": "execute_result", "data": {"text/plain": "[[5, 2, 242, 1035, 7, 10, 2857, 13, 0, 0],\n [4, 3, 2, 16, 31, 0, 0, 0, 0, 0],\n [4, 3, 2, 28, 20, 0, 0, 0, 0, 0],\n [148, 162, 2134, 46, 447, 7, 2, 196, 0, 0],\n [22, 3, 2, 166, 0, 0, 0, 0, 0, 0],\n [3, 2, 61, 288, 259, 0, 0, 0, 0, 0],\n [4, 13, 136, 3, 1490, 19, 2, 212, 0, 0],\n [5, 34, 65, 2858, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 37, 0, 0, 0, 0, 0],\n [4, 5, 2, 739, 53, 8, 0, 0, 0, 0],\n [4, 26, 9, 47, 3, 69, 0, 0, 0, 0],\n [4, 3, 2, 740, 8, 2, 255, 42, 0, 0],\n [4, 740, 3, 8, 2, 255, 42, 0, 0, 0],\n [3, 6, 708, 0, 0, 0, 0, 0, 0, 0],\n [11, 12, 2859, 5, 14, 0, 0, 0, 0, 0],\n [87, 162, 1109, 94, 0, 0, 0, 0, 0, 0],\n [3, 14, 10, 1734, 7, 101, 9, 2, 114, 0],\n [3, 2, 272, 649, 0, 0, 0, 0, 0, 0],\n [3, 2, 115, 470, 121, 2135, 0, 0, 0, 0],\n [4, 13, 3, 2, 58, 134, 0, 0, 0, 0],\n [3, 2, 44, 779, 7, 6, 18, 897, 0, 0],\n [4, 13, 5, 2, 2860, 7, 2, 1036, 0, 0],\n [3, 6, 10, 117, 250, 92, 0, 0, 0, 0],\n [11, 12, 1735, 15, 6, 44, 25, 0, 0, 0],\n [4, 13, 3, 2, 63, 0, 0, 0, 0, 0],\n [4, 3, 2, 1212, 16, 2861, 19, 2, 1212, 35],\n [104, 30, 413, 10, 1736, 369, 30, 2862, 6, 48],\n [4, 3, 2, 16, 80, 8, 0, 0, 0, 0],\n [4, 3, 163, 7, 2, 191, 0, 0, 0, 0],\n [11, 12, 681, 5, 8, 2, 78, 0, 0, 0],\n [3, 6, 448, 2863, 0, 0, 0, 0, 0, 0],\n [4, 121, 449, 5, 182, 19, 2, 63, 0, 0],\n [11, 265, 15, 6, 169, 79, 0, 0, 0, 0],\n [54, 88, 3, 2, 28, 38, 2, 197, 7, 0],\n [22, 3, 2, 57, 53, 0, 0, 0, 0, 0],\n [4, 3, 2, 2136, 16, 7, 2, 1213, 260, 0],\n [11, 12, 299, 5, 7, 2, 18, 0, 0, 0],\n [54, 121, 5, 1491, 65, 0, 0, 0, 0, 0],\n [11, 12, 17, 1492, 25, 10, 273, 0, 0, 0],\n [11, 12, 373, 29, 30, 55, 0, 0, 0, 0],\n [4, 3, 1342, 2, 709, 0, 0, 0, 0, 0],\n [4, 13, 134, 3, 6, 16, 20, 0, 0, 0],\n [3, 10, 28, 20, 10, 2137, 1493, 0, 0, 0],\n [11, 12, 187, 243, 5, 14, 0, 0, 0, 0],\n [4, 13, 3, 2, 101, 164, 0, 0, 0, 0],\n [22, 15, 6, 18, 513, 251, 0, 0, 0, 0],\n [15, 2, 188, 79, 125, 0, 0, 0, 0, 0],\n [3, 6, 40, 2, 334, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 289, 0, 0, 0, 0, 0],\n [279, 7, 2, 116, 1494, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 57, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 321, 244, 0, 0, 0, 0],\n [189, 192, 36, 620, 0, 0, 0, 0, 0, 0],\n [4, 111, 3, 83, 300, 0, 0, 0, 0, 0],\n [5, 30, 1110, 9, 198, 0, 0, 0, 0, 0],\n [3, 2, 209, 7, 1737, 0, 0, 0, 0, 0],\n [68, 5, 594, 9, 2, 395, 471, 0, 0, 0],\n [4, 3, 2, 125, 8, 2, 64, 0, 0, 0],\n [4, 33, 9, 129, 3, 6, 0, 0, 0, 0],\n [4, 13, 3, 2, 2864, 0, 0, 0, 0, 0],\n [4, 327, 3, 65, 0, 0, 0, 0, 0, 0],\n [3, 14, 188, 0, 0, 0, 0, 0, 0, 0],\n [3, 2, 1343, 384, 572, 19, 1738, 236, 2, 274],\n [4, 13, 126, 5, 2, 226, 145, 2865, 0, 0],\n [4, 3, 2, 1495, 9, 2, 385, 0, 0, 0],\n [3, 6, 10, 741, 292, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 1111, 0, 0, 0, 0, 0],\n [5, 14, 1739, 1214, 8, 2, 63, 0, 0, 0],\n [15, 49, 25, 227, 130, 8, 46, 1496, 8, 46],\n [4, 3, 2, 111, 23, 17, 5, 65, 0, 0],\n [3, 1344, 2866, 498, 573, 0, 0, 0, 0, 0],\n [3, 6, 16, 20, 151, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 38, 0, 0, 0, 0, 0],\n [4, 13, 52, 3, 6, 16, 20, 0, 0, 0],\n [4, 3, 2, 406, 8, 2, 396, 0, 0, 0],\n [4, 2867, 61, 3, 7, 2, 175, 0, 0, 0],\n [4, 3, 2, 42, 31, 0, 0, 0, 0, 0],\n [3, 6, 621, 0, 0, 0, 0, 0, 0, 0],\n [3, 2, 71, 710, 2138, 0, 0, 0, 0, 0],\n [3, 6, 10, 450, 0, 0, 0, 0, 0, 0],\n [11, 12, 145, 5, 40, 2, 84, 101, 9, 2],\n [4, 3, 2, 13, 9, 2, 44, 0, 0, 0],\n [4, 3, 2, 48, 1037, 0, 0, 0, 0, 0],\n [11, 12, 711, 5, 8, 2, 48, 0, 0, 0],\n [3, 6, 10, 92, 48, 0, 0, 0, 0, 0],\n [3, 2, 304, 1215, 0, 0, 0, 0, 0, 0],\n [4, 15, 2, 483, 96, 85, 1345, 109, 8, 2],\n [11, 256, 5, 14, 0, 0, 0, 0, 0, 0],\n [3, 2, 16, 288, 10, 18, 9, 1497, 0, 0],\n [68, 5, 23, 17, 8, 158, 574, 970, 0, 0],\n [15, 2, 154, 25, 1740, 314, 0, 0, 0, 0],\n [3, 2, 98, 53, 1741, 8, 2, 154, 0, 0],\n [4, 3, 2, 472, 62, 9, 0, 0, 0, 0],\n [4, 111, 3, 83, 300, 0, 0, 0, 0, 0],\n [4, 266, 3, 2, 60, 0, 0, 0, 0, 0],\n [5, 34, 1498, 0, 0, 0, 0, 0, 0, 0],\n [4, 155, 5, 2, 548, 19, 2, 74, 20, 0],\n [4, 13, 3, 2, 196, 0, 0, 0, 0, 0],\n [3, 49, 65, 10, 70, 0, 0, 0, 0, 0],\n [4, 514, 5, 142, 0, 0, 0, 0, 0, 0],\n [4, 3, 8, 2, 58, 52, 0, 0, 0, 0],\n [3, 14, 10, 1112, 8, 82, 681, 0, 0, 0],\n [4, 423, 3, 142, 0, 0, 0, 0, 0, 0],\n [4, 3, 2139, 230, 13, 8, 2, 78, 0, 0],\n [3, 14, 10, 2868, 9, 243, 7, 6, 18, 0],\n [11, 12, 971, 5, 14, 0, 0, 0, 0, 0],\n [4, 116, 3, 8, 6, 549, 0, 0, 0, 0],\n [4, 5, 2, 120, 473, 8, 2, 71, 0, 0],\n [4, 3, 2, 2869, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 42, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 98, 7, 2, 2870, 305, 0],\n [4, 13, 3, 2, 210, 185, 0, 0, 0, 0],\n [3, 14, 10, 2140, 7, 2, 66, 0, 0, 0],\n [4, 13, 3, 2, 1742, 8, 2, 289, 0, 0],\n [5, 2, 397, 244, 2, 133, 13, 0, 0, 0],\n [3, 2, 2871, 1743, 2872, 8, 0, 0, 0, 0],\n [11, 12, 2873, 2874, 5, 7, 6, 18, 0, 0],\n [3, 2, 56, 328, 0, 0, 0, 0, 0, 0],\n [5, 23, 299, 24, 329, 65, 1216, 0, 0, 0],\n [4, 111, 5, 34, 65, 0, 0, 0, 0, 0],\n [4, 3, 2, 13, 9, 2, 188, 0, 0, 0],\n [4, 13, 3, 2, 122, 0, 0, 0, 0, 0],\n [4, 33, 9, 322, 3, 7, 2, 550, 0, 0],\n [3, 2, 193, 7, 2, 530, 472, 0, 0, 0],\n [4, 650, 1744, 3, 10, 1217, 9, 6, 385, 0],\n [3, 14, 10, 127, 0, 0, 0, 0, 0, 0],\n [11, 12, 1346, 5, 14, 0, 0, 0, 0, 0],\n [11, 12, 315, 41, 36, 131, 0, 0, 0, 0],\n [4, 13, 5, 2, 256, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 515, 0, 0, 0, 0, 0],\n [4, 5, 2, 414, 8, 2, 101, 9, 2, 45],\n [3, 2, 45, 857, 499, 0, 0, 0, 0, 0],\n [4, 1745, 6, 742, 0, 0, 0, 0, 0, 0],\n [4, 370, 9, 280, 5, 237, 2, 315, 0, 0],\n [4, 3, 2, 118, 9, 6, 1113, 45, 0, 0],\n [4, 13, 3, 2, 45, 742, 0, 0, 0, 0],\n [3, 2, 13, 9, 2, 146, 2141, 0, 0, 0],\n [68, 3, 2, 154, 1746, 19, 2, 575, 0, 0],\n [4, 202, 3, 8, 2, 306, 817, 99, 3, 8],\n [4, 15, 2, 1747, 48, 595, 0, 0, 0, 0],\n [4, 5, 972, 898, 398, 123, 2, 386, 0, 0],\n [3, 14, 10, 484, 0, 0, 0, 0, 0, 0],\n [4, 531, 3, 2, 61, 163, 50, 0, 0, 0],\n [11, 149, 3, 2, 98, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 45, 0, 0, 0, 0, 0],\n [4, 3, 49, 8, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 210, 185, 0, 0, 0, 0, 0],\n [3, 6, 10, 407, 103, 0, 0, 0, 0, 0],\n [4, 3, 2, 132, 62, 108, 9, 0, 0, 0],\n [3, 6, 32, 1114, 1499, 0, 0, 0, 0, 0],\n [5, 34, 107, 1115, 0, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 27, 0, 0, 0],\n [11, 12, 17, 5, 14, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 1038, 9, 6, 292, 0, 0],\n [11, 12, 191, 1347, 5, 14, 0, 0, 0, 0],\n [4, 252, 3, 1748, 0, 0, 0, 0, 0, 0],\n [11, 12, 972, 145, 5, 8, 2, 451, 0, 0],\n [4, 3, 2, 227, 2875, 2142, 9, 2, 1218, 138],\n [3, 14, 10, 175, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 532, 61, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 61, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 184, 234, 0, 0, 0, 0],\n [3, 2, 76, 353, 0, 0, 0, 0, 0, 0],\n [7, 4, 33, 9, 1500, 5, 2, 1749, 682, 0],\n [99, 5, 119, 2, 44, 0, 0, 0, 0, 0],\n [3, 14, 43, 2876, 8, 2, 60, 0, 0, 0],\n [3, 2, 424, 10, 2877, 424, 0, 0, 0, 0],\n [11, 12, 2143, 5, 434, 0, 0, 0, 0, 0],\n [3, 14, 173, 7, 2, 76, 0, 0, 0, 0],\n [11, 307, 3, 6, 61, 0, 0, 0, 0, 0],\n [3, 6, 27, 2878, 0, 0, 0, 0, 0, 0],\n [22, 89, 18, 75, 9, 2, 238, 0, 0, 0],\n [4, 293, 3, 2, 899, 0, 0, 0, 0, 0],\n [3, 14, 374, 7, 2, 66, 0, 0, 0, 0],\n [11, 12, 160, 5, 14, 0, 0, 0, 0, 0],\n [3, 2, 16, 20, 305, 0, 0, 0, 0, 0],\n [68, 29, 34, 500, 170, 1750, 0, 0, 0, 0],\n [3, 2, 56, 294, 0, 0, 0, 0, 0, 0],\n [3, 2, 415, 8, 2, 64, 10, 416, 24, 10],\n [3, 2, 712, 7, 101, 9, 2, 220, 0, 0],\n [4, 169, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 3, 7, 2, 221, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 306, 2144, 0, 0, 0, 0],\n [4, 26, 9, 301, 5, 2, 346, 8, 0, 0],\n [99, 3, 163, 6, 222, 0, 0, 0, 0, 0],\n [68, 3, 2, 295, 651, 2879, 0, 0, 0, 0],\n [4, 26, 9, 42, 3, 6, 0, 0, 0, 0],\n [4, 155, 3, 2, 42, 0, 0, 0, 0, 0],\n [4, 3, 2, 42, 53, 8, 0, 0, 0, 0],\n [4, 13, 3, 2, 306, 1219, 0, 0, 0, 0],\n [3, 2, 2880, 8, 2, 900, 7, 1116, 0, 0],\n [5, 2, 17, 2881, 0, 0, 0, 0, 0, 0],\n [22, 3, 2, 126, 375, 86, 0, 0, 0, 0],\n [4, 1501, 514, 5, 7, 2, 27, 0, 0, 0],\n [3, 2, 57, 276, 683, 0, 0, 0, 0, 0],\n [3, 2, 1751, 2145, 2, 136, 0, 0, 0, 0],\n [4, 26, 9, 818, 3, 49, 290, 0, 0, 0],\n [3, 2, 16, 203, 0, 0, 0, 0, 0, 0],\n [4, 302, 3, 51, 0, 0, 0, 0, 0, 0],\n [15, 2, 576, 41, 361, 19, 36, 2146, 0, 0],\n [22, 3, 2, 272, 7, 2, 76, 0, 0, 0],\n [3, 6, 10, 295, 1502, 0, 0, 0, 0, 0],\n [29, 30, 10, 1752, 7, 2, 76, 0, 0, 0],\n [11, 12, 684, 135, 5, 14, 0, 0, 0, 0],\n [4, 1039, 281, 105, 6, 223, 0, 0, 0, 0],\n [4, 3, 2, 98, 20, 0, 0, 0, 0, 0],\n [4, 26, 9, 354, 3, 2, 35, 1220, 0, 0],\n [11, 12, 238, 0, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 8, 2, 78, 119, 0, 0],\n [3, 2, 596, 622, 105, 24, 140, 0, 0, 0],\n [22, 3, 2, 61, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 27, 51, 104, 36, 7, 59, 2882],\n [68, 1348, 2, 16, 858, 7, 6, 26, 9, 261],\n [4, 3, 2, 16, 38, 0, 0, 0, 0, 0],\n [3, 2, 16, 290, 10, 152, 0, 0, 0, 0],\n [15, 6, 16, 79, 1117, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 181, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 362, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 743, 0, 0, 0, 0, 0],\n [4, 551, 3, 2, 28, 119, 2, 347, 0, 0],\n [3, 6, 199, 0, 0, 0, 0, 0, 0, 0],\n [3, 95, 20, 10, 2883, 623, 0, 0, 0, 0],\n [4, 3, 2, 28, 31, 0, 0, 0, 0, 0],\n [3, 2, 35, 20, 10, 2884, 0, 0, 0, 0],\n [4, 5, 34, 65, 0, 0, 0, 0, 0, 0],\n [5, 23, 859, 0, 0, 0, 0, 0, 0, 0],\n [5, 2, 262, 199, 0, 0, 0, 0, 0, 0],\n [15, 6, 146, 79, 407, 0, 0, 0, 0, 0],\n [4, 3, 2, 132, 62, 9, 0, 0, 0, 0],\n [4, 3, 2, 450, 8, 2, 282, 0, 0, 0],\n [5, 14, 435, 8, 2, 77, 0, 0, 0, 0],\n [780, 24, 1349, 32, 0, 0, 0, 0, 0, 0],\n [4, 26, 9, 18, 3, 6, 0, 0, 0, 0],\n [99, 5, 7, 2, 282, 0, 0, 0, 0, 0],\n [5, 2, 17, 7, 2, 101, 1040, 624, 973, 1503],\n [4, 70, 5, 34, 65, 0, 0, 0, 0, 0],\n [11, 12, 275, 5, 69, 0, 0, 0, 0, 0],\n [4, 3, 485, 2, 78, 0, 0, 0, 0, 0],\n [148, 95, 323, 335, 10, 194, 153, 0, 0, 0],\n [3, 2, 106, 348, 105, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 280, 0, 0, 0, 0, 0],\n [4, 202, 3, 8, 2, 781, 52, 0, 0, 0],\n [4, 3, 2, 245, 685, 8, 0, 0, 0, 0],\n [3, 2, 35, 1754, 190, 2885, 0, 0, 0, 0],\n [3, 21, 10, 399, 8, 2, 246, 0, 0, 0],\n [3, 14, 10, 533, 0, 0, 0, 0, 0, 0],\n [11, 12, 155, 3, 2, 1755, 425, 0, 0, 0],\n [4, 3, 2, 118, 9, 2, 531, 8, 2, 534],\n [498, 2, 121, 247, 8, 6, 2886, 253, 1041, 686],\n [4, 13, 3, 2, 116, 552, 0, 0, 0, 0],\n [4, 13, 3, 2, 550, 0, 0, 0, 0, 0],\n [4, 3, 6, 167, 50, 0, 0, 0, 0, 0],\n [4, 3, 7, 2, 387, 254, 239, 2, 975, 0],\n [4, 37, 2887, 2, 47, 7, 2, 1756, 597, 40],\n [11, 12, 744, 5, 74, 0, 0, 0, 0, 0],\n [3, 2, 782, 860, 107, 105, 24, 375, 140, 0],\n [3, 6, 10, 463, 32, 0, 0, 0, 0, 0],\n [3, 14, 43, 188, 0, 0, 0, 0, 0, 0],\n [3, 2, 18, 7, 161, 96, 85, 0, 0, 0],\n [4, 3, 1221, 105, 86, 2, 78, 323, 123, 2],\n [4, 33, 9, 1042, 3, 8, 2, 60, 0, 0],\n [4, 13, 3, 2, 63, 0, 0, 0, 0, 0],\n [3, 6, 10, 228, 1757, 0, 0, 0, 0, 0],\n [3, 2, 18, 625, 0, 0, 0, 0, 0, 0],\n [54, 250, 15, 2, 48, 109, 19, 376, 0, 0],\n [4, 26, 9, 204, 3, 2, 16, 20, 0, 0],\n [4, 3, 2, 202, 8, 2, 63, 0, 0, 0],\n [3, 6, 200, 53, 8, 10, 63, 0, 0, 0],\n [179, 2, 67, 36, 2888, 1350, 0, 0, 0, 0],\n [4, 5, 2, 626, 17, 20, 8, 158, 713, 0],\n [3, 21, 137, 0, 0, 0, 0, 0, 0, 0],\n [3, 2, 129, 53, 8, 10, 209, 0, 0, 0],\n [3, 2, 92, 434, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 28, 163, 7, 2, 76, 0, 0],\n [3, 2, 154, 195, 0, 0, 0, 0, 0, 0],\n [4, 13, 5, 82, 205, 0, 0, 0, 0, 0],\n [4, 3, 7, 2, 58, 388, 0, 0, 0, 0],\n [4, 302, 3, 2, 16, 38, 0, 0, 0, 0],\n [11, 12, 2889, 5, 8, 2, 330, 0, 0, 0],\n [3, 49, 316, 745, 0, 0, 0, 0, 0, 0],\n [3, 49, 10, 98, 0, 0, 0, 0, 0, 0],\n [3, 49, 20, 10, 861, 0, 0, 0, 0, 0],\n [4, 3, 7, 2, 58, 88, 0, 0, 0, 0],\n [3, 6, 10, 208, 0, 0, 0, 0, 0, 0],\n [4, 147, 3, 142, 8, 2, 52, 9, 2, 16],\n [3, 2, 35, 91, 40, 2, 212, 0, 0, 0],\n [4, 6, 98, 3, 819, 0, 0, 0, 0, 0],\n [4, 3, 7, 2, 781, 388, 0, 0, 0, 0],\n [3, 2, 35, 8, 2, 462, 64, 9, 2, 93],\n [11, 12, 2890, 15, 2, 98, 25, 7, 82, 687],\n [4, 3, 40, 2, 84, 9, 2, 1758, 0, 0],\n [11, 12, 206, 5, 100, 7, 2, 66, 0, 0],\n [3, 21, 1043, 19, 500, 324, 8, 6, 81, 0],\n [3, 6, 28, 64, 820, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 18, 0, 0, 0],\n [3, 21, 862, 0, 0, 0, 0, 0, 0, 0],\n [4, 3, 211, 40, 2, 325, 9, 2, 27, 0],\n [4, 202, 3, 8, 2, 77, 0, 0, 0, 0],\n [11, 12, 206, 0, 0, 0, 0, 0, 0, 0],\n [4, 26, 9, 47, 3, 62, 7, 59, 448, 102],\n [3, 14, 1044, 37, 100, 51, 901, 10, 166, 0],\n [5, 14, 121, 426, 17, 7, 2, 18, 0, 0],\n [4, 26, 9, 261, 3, 2, 187, 53, 7, 0],\n [15, 6, 447, 172, 342, 0, 0, 0, 0, 0],\n [15, 6, 139, 1045, 355, 976, 9, 1759, 0, 0],\n [4, 90, 3, 8, 2, 101, 84, 9, 2, 44],\n [3, 2, 44, 285, 0, 0, 0, 0, 0, 0],\n [3, 2, 150, 7, 10, 334, 0, 0, 0, 0],\n [89, 1351, 167, 19, 281, 2, 863, 0, 0, 0],\n [4, 26, 9, 32, 5, 2, 17, 94, 7, 0],\n [4, 13, 3, 2, 226, 126, 0, 0, 0, 0],\n [5, 2, 308, 2147, 19, 319, 0, 0, 0, 0],\n [22, 3, 2, 85, 598, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 226, 126, 51, 41, 36, 131],\n [3, 2, 126, 1760, 226, 19, 2148, 0, 0, 0],\n [4, 3, 248, 190, 117, 9, 2, 39, 0, 0],\n [3, 21, 10, 137, 81, 0, 0, 0, 0, 0],\n [3, 14, 10, 18, 317, 8, 2, 77, 0, 0],\n [3, 2, 65, 0, 0, 0, 0, 0, 0, 0],\n [3, 14, 188, 7, 2, 93, 0, 0, 0, 0],\n [4, 70, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 267, 3, 2149, 8, 2, 472, 0, 0, 0],\n [7, 4, 252, 5, 34, 65, 0, 0, 0, 0],\n [4, 3, 746, 0, 0, 0, 0, 0, 0, 0],\n [11, 12, 714, 5, 8, 2, 60, 0, 0, 0],\n [3, 2, 71, 740, 2891, 24, 1761, 0, 0, 0],\n [3, 6, 7, 486, 0, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 208, 0, 0, 0],\n [4, 5, 2, 17, 535, 50, 0, 0, 0, 0],\n [11, 12, 255, 296, 5, 14, 7, 2, 18, 0],\n [87, 10, 715, 144, 75, 108, 9, 2, 255, 42],\n [4, 13, 5, 2, 349, 0, 0, 0, 0, 0],\n [3, 6, 10, 627, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 44, 7, 2, 18, 0, 0],\n [3, 6, 44, 400, 9, 10, 309, 652, 0, 0],\n [4, 3, 2, 436, 13, 0, 0, 0, 0, 0],\n [3, 2, 126, 8, 0, 0, 0, 0, 0, 0],\n [3, 2, 780, 902, 0, 0, 0, 0, 0, 0],\n [3, 2, 231, 716, 0, 0, 0, 0, 0, 0],\n [11, 12, 599, 9, 553, 427, 3, 100, 0, 0],\n [5, 14, 1762, 7, 6, 18, 0, 0, 0, 0],\n [4, 13, 3, 2, 2150, 222, 0, 0, 0, 0],\n [5, 23, 283, 24, 1504, 0, 0, 0, 0, 0],\n [3, 6, 10, 407, 45, 0, 0, 0, 0, 0],\n [3, 21, 10, 353, 81, 0, 0, 0, 0, 0],\n [4, 32, 89, 6, 75, 7, 0, 0, 0, 0],\n [11, 12, 232, 5, 14, 0, 0, 0, 0, 0],\n [11, 12, 232, 5, 80, 0, 0, 0, 0, 0],\n [5, 2, 198, 86, 2, 133, 628, 0, 0, 0],\n [4, 277, 9, 2, 501, 5, 34, 7, 0, 0],\n [4, 26, 9, 112, 5, 7, 2, 66, 0, 0],\n [3, 2, 57, 356, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 136, 0, 0, 0, 0, 0],\n [5, 117, 9, 2, 1118, 247, 10, 2892, 0, 0],\n [5, 14, 112, 7, 6, 128, 0, 0, 0, 0],\n [5, 23, 2893, 8, 10, 653, 0, 0, 0, 0],\n [4, 3, 2, 428, 8, 2, 48, 1352, 0, 0],\n [4, 13, 3, 2, 48, 0, 0, 0, 0, 0],\n [15, 49, 500, 10, 821, 204, 0, 0, 0, 0],\n [15, 2, 16, 172, 19, 36, 20, 10, 577, 654],\n [15, 6, 79, 102, 21, 3, 86, 59, 149, 1119],\n [5, 14, 168, 535, 19, 1763, 0, 0, 0, 0],\n [4, 3, 2, 35, 377, 0, 0, 0, 0, 0],\n [29, 30, 343, 6, 3, 10, 536, 250, 19, 2151],\n [4, 3, 2, 35, 7, 120, 31, 0, 0, 0],\n [11, 12, 113, 5, 80, 0, 0, 0, 0, 0],\n [4, 155, 5, 8, 2, 58, 903, 0, 0, 0],\n [4, 13, 3, 2, 134, 0, 0, 0, 0, 0],\n [3, 6, 59, 2894, 252, 0, 0, 0, 0, 0],\n [4, 3, 2, 324, 429, 0, 0, 0, 0, 0],\n [3, 2, 238, 268, 263, 24, 213, 2, 747, 0],\n [4, 3, 2, 114, 62, 9, 0, 0, 0, 0],\n [22, 3, 2, 37, 83, 1222, 0, 0, 0, 0],\n [4, 3, 485, 2, 132, 0, 0, 0, 0, 0],\n [5, 14, 711, 0, 0, 0, 0, 0, 0, 0],\n [3, 2, 747, 2, 133, 13, 455, 59, 150, 0],\n [3, 2, 124, 203, 190, 94, 0, 0, 0, 0],\n [22, 3, 2, 42, 356, 0, 0, 0, 0, 0],\n [4, 37, 3, 69, 0, 0, 0, 0, 0, 0],\n [3, 2, 202, 8, 2, 77, 235, 207, 456, 24],\n [3, 6, 7, 486, 0, 0, 0, 0, 0, 0],\n [4, 3, 90, 2152, 31, 0, 0, 0, 0, 0],\n [11, 12, 578, 5, 142, 0, 0, 0, 0, 0],\n [4, 125, 302, 3, 7, 6, 223, 0, 0, 0],\n [15, 6, 220, 25, 2153, 9, 2895, 0, 0, 0],\n [148, 2, 28, 516, 0, 0, 0, 0, 0, 0],\n [5, 183, 9, 23, 17, 94, 0, 0, 0, 0],\n [4, 26, 9, 129, 3, 51, 0, 0, 0, 0],\n [4, 5, 34, 288, 47, 108, 9, 7, 2, 2896],\n [4, 3, 2, 336, 9, 2, 42, 0, 0, 0],\n [4, 3, 2, 42, 377, 0, 0, 0, 0, 0],\n [22, 5, 34, 0, 0, 0, 0, 0, 0, 0],\n [3, 14, 10, 2897, 1764, 7, 2, 27, 0, 0],\n [3, 2, 169, 554, 1765, 0, 0, 0, 0, 0],\n [4, 3, 8, 2, 63, 0, 0, 0, 0, 0],\n [4, 33, 9, 125, 302, 3, 83, 464, 0, 0],\n [11, 149, 5, 2, 160, 0, 0, 0, 0, 0],\n [3, 117, 9, 2, 160, 91, 40, 2, 212, 0],\n [4, 13, 5, 2, 296, 2898, 0, 0, 0, 0],\n [3, 2, 42, 8, 2, 64, 331, 0, 0, 0],\n [11, 12, 194, 2154, 5, 14, 0, 0, 0, 0],\n [4, 3, 2, 166, 31, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 306, 134, 0, 0, 0, 0],\n [3, 6, 28, 53, 8, 2, 487, 0, 0, 0],\n [11, 12, 2155, 2156, 2, 579, 0, 0, 0, 0],\n [3, 2, 28, 20, 10, 2157, 0, 0, 0, 0],\n [4, 67, 9, 81, 3, 21, 0, 0, 0, 0],\n [4, 2899, 3, 2, 146, 282, 0, 0, 0, 0],\n [11, 12, 337, 5, 7, 2, 76, 0, 0, 0],\n [4, 13, 3, 2, 2900, 0, 0, 0, 0, 0],\n [3, 6, 977, 2901, 0, 0, 0, 0, 0, 0],\n [3, 6, 904, 24, 1766, 0, 0, 0, 0, 0],\n [3, 2, 415, 416, 24, 399, 0, 0, 0, 0],\n [3, 2, 35, 7, 684, 1046, 350, 0, 0, 0],\n [4, 116, 3, 7, 2, 200, 0, 0, 0, 0],\n [87, 162, 1109, 94, 6, 223, 656, 0, 0, 0],\n [4, 26, 9, 71, 3, 6, 0, 0, 0, 0],\n [22, 3, 2, 71, 86, 0, 0, 0, 0, 0],\n [11, 12, 101, 314, 29, 30, 55, 7, 326, 224],\n [3, 14, 2, 2902, 50, 10, 2903, 0, 0, 0],\n [5, 23, 17, 10, 555, 0, 0, 0, 0, 0],\n [4, 3, 2, 57, 269, 8, 0, 0, 0, 0],\n [4, 39, 5, 69, 0, 0, 0, 0, 0, 0],\n [4, 13, 52, 15, 2, 16, 25, 8, 0, 0],\n [4, 13, 134, 3, 2, 28, 8, 2, 74, 20],\n [3, 2, 175, 159, 0, 0, 0, 0, 0, 0],\n [22, 3, 2, 417, 0, 0, 0, 0, 0, 0],\n [3, 6, 16, 905, 0, 0, 0, 0, 0, 0],\n [4, 26, 9, 465, 5, 123, 2, 301, 0, 0],\n [5, 2, 17, 7, 2, 66, 2904, 0, 0, 0],\n [11, 12, 39, 5, 7, 6, 27, 0, 0, 0],\n [4, 37, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 347, 0, 0, 0, 0, 0],\n [5, 2, 113, 2905, 19, 2, 822, 0, 0, 0],\n [4, 13, 3, 2, 600, 9, 2, 229, 0, 0],\n [5, 14, 289, 7, 6, 18, 0, 0, 0, 0],\n [4, 70, 5, 34, 65, 0, 0, 0, 0, 0],\n [11, 149, 3, 2, 35, 0, 0, 0, 0, 0],\n [3, 6, 10, 864, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 657, 16, 8, 10, 224, 0, 0],\n [4, 15, 6, 58, 688, 0, 0, 0, 0, 0],\n [4, 3, 823, 8, 2, 181, 0, 0, 0, 0],\n [11, 12, 174, 5, 100, 7, 6, 93, 0, 0],\n [15, 2, 16, 25, 8, 10, 134, 0, 0, 0],\n [3, 14, 10, 210, 185, 7, 6, 27, 0, 0],\n [11, 12, 629, 5, 452, 8, 0, 0, 0, 0],\n [4, 13, 3, 2, 362, 0, 0, 0, 0, 0],\n [5, 23, 906, 0, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 214, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 77, 0, 0, 0, 0, 0],\n [4, 202, 3, 8, 2, 580, 0, 0, 0, 0],\n [11, 12, 17, 5, 53, 140, 0, 0, 0, 0],\n [3, 14, 10, 115, 8, 2, 437, 0, 0, 0],\n [4, 13, 3, 2, 184, 310, 0, 0, 0, 0],\n [4, 13, 5, 2, 515, 0, 0, 0, 0, 0],\n [4, 336, 9, 42, 3, 6, 0, 0, 0, 0],\n [11, 12, 39, 5, 269, 140, 0, 0, 0, 0],\n [29, 30, 55, 43, 112, 7, 2, 27, 0, 0],\n [3, 2, 16, 7, 2, 56, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 66, 0, 0, 0],\n [4, 26, 9, 153, 3, 51, 0, 0, 0, 0],\n [11, 12, 2906, 5, 7, 2, 191, 0, 0, 0],\n [22, 5, 34, 0, 0, 0, 0, 0, 0, 0],\n [3, 21, 190, 19, 783, 0, 0, 0, 0, 0],\n [3, 2, 16, 907, 24, 743, 2, 274, 0, 0],\n [22, 3, 2, 115, 0, 0, 0, 0, 0, 0],\n [2907, 1223, 24, 2908, 2909, 0, 0, 0, 0, 0],\n [3, 6, 16, 905, 0, 0, 0, 0, 0, 0],\n [4, 3, 6, 16, 94, 0, 0, 0, 0, 0],\n [3, 14, 272, 375, 389, 2, 175, 0, 0, 0],\n [3, 6, 128, 75, 251, 40, 318, 24, 784, 2],\n [3, 2, 18, 7, 13, 0, 0, 0, 0, 0],\n [4, 26, 9, 818, 3, 6, 0, 0, 0, 0],\n [4, 5, 2, 161, 96, 230, 398, 8, 2, 785],\n [3, 2, 178, 502, 0, 0, 0, 0, 0, 0],\n [3, 51, 10, 655, 51, 2, 16, 3, 38, 0],\n [4, 418, 3, 10, 1217, 9, 6, 385, 0, 0],\n [3, 6, 10, 194, 1505, 7, 2910, 0, 0, 0],\n [3, 2, 908, 2911, 0, 0, 0, 0, 0, 0],\n [11, 12, 39, 7, 6, 27, 0, 0, 0, 0],\n [3, 2, 272, 649, 8, 2, 2912, 0, 0, 0],\n [4, 1224, 5, 8, 2, 77, 0, 0, 0, 0],\n [11, 350, 3, 2, 210, 185, 0, 0, 0, 0],\n [4, 13, 3, 2, 210, 185, 0, 0, 0, 0],\n [3, 14, 10, 223, 8, 10, 223, 0, 0, 0],\n [4, 26, 9, 47, 3, 69, 0, 0, 0, 0],\n [68, 3, 2, 44, 285, 0, 0, 0, 0, 0],\n [3, 6, 16, 20, 305, 0, 0, 0, 0, 0],\n [4, 3, 8, 2, 58, 180, 0, 0, 0, 0],\n [3, 6, 16, 20, 205, 0, 0, 0, 0, 0],\n [3, 6, 16, 20, 151, 0, 0, 0, 0, 0],\n [3, 6, 10, 2913, 50, 2914, 0, 0, 0, 0],\n [3, 2, 127, 269, 8, 748, 0, 0, 0, 0],\n [4, 13, 3, 2, 114, 0, 0, 0, 0, 0],\n [11, 12, 822, 5, 69, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 77, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 38, 7, 46, 64, 88, 0],\n [3, 6, 2, 2158, 9, 10, 630, 0, 0, 0],\n [4, 13, 3, 2, 77, 0, 0, 0, 0, 0],\n [5, 2, 262, 94, 188, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 209, 1047, 0, 0, 0, 0],\n [4, 5, 2, 503, 900, 7, 2, 363, 50, 0],\n [3, 2, 61, 7, 1048, 0, 0, 0, 0, 0],\n [3, 2, 67, 9, 81, 2159, 117, 1506, 9, 1225],\n [3, 2, 42, 203, 0, 0, 0, 0, 0, 0],\n [4, 3, 1507, 8, 2, 77, 0, 0, 0, 0],\n [4, 3, 211, 8, 84, 9, 2, 319, 48, 0],\n [3, 21, 355, 1508, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 42, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 2915, 115, 0, 0, 0, 0, 0],\n [3, 14, 10, 175, 7, 6, 27, 0, 0, 0],\n [3, 14, 10, 282, 7, 2, 32, 0, 0, 0],\n [3, 226, 195, 2916, 239, 824, 0, 0, 0, 0],\n [3, 6, 28, 20, 1049, 0, 0, 0, 0, 0],\n [3, 2, 35, 20, 2160, 0, 0, 0, 0, 0],\n [4, 3, 19, 2, 64, 9, 2, 424, 0, 0],\n [3, 2, 126, 120, 24, 125, 0, 0, 0, 0],\n [4, 304, 3, 21, 0, 0, 0, 0, 0, 0],\n [3, 21, 137, 0, 0, 0, 0, 0, 0, 0],\n [3, 6, 187, 177, 24, 263, 1226, 371, 149, 0],\n [5, 17, 268, 217, 2, 45, 0, 0, 0, 0],\n [11, 12, 17, 5, 601, 7, 6, 1353, 0, 0],\n [4, 13, 3, 2, 143, 0, 0, 0, 0, 0],\n [54, 222, 3, 534, 19, 2, 64, 0, 0, 0],\n [4, 129, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 129, 290, 19, 55, 46, 450, 0],\n [4, 537, 9, 308, 5, 69, 0, 0, 0, 0],\n [3, 6, 59, 2161, 0, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 8, 2, 157, 0, 0, 0],\n [4, 202, 3, 2, 2917, 204, 0, 0, 0, 0],\n [3, 117, 28, 782, 239, 2, 254, 0, 0, 0],\n [4, 67, 9, 81, 3, 6, 169, 717, 474, 0],\n [11, 12, 280, 5, 14, 0, 0, 0, 0, 0],\n [4, 26, 9, 202, 3, 167, 8, 2, 275, 0],\n [22, 5, 34, 0, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 65, 0, 0, 0, 0, 0],\n [11, 12, 2918, 5, 8, 2, 330, 0, 0, 0],\n [4, 26, 9, 178, 3, 95, 357, 50, 0, 0],\n [3, 6, 10, 2162, 0, 0, 0, 0, 0, 0],\n [3, 2, 16, 269, 182, 19, 46, 347, 0, 0],\n [4, 3, 2, 136, 718, 0, 0, 0, 0, 0],\n [4, 786, 104, 281, 30, 2919, 6, 3, 10, 114],\n [15, 21, 79, 102, 10, 364, 2163, 8, 2, 517],\n [3, 2, 306, 130, 1509, 24, 749, 0, 0, 0],\n [3, 14, 10, 165, 153, 7, 6, 18, 0, 0],\n [15, 6, 28, 2921, 2922, 0, 0, 0, 0, 0],\n [4, 15, 2, 270, 98, 343, 3, 978, 190, 2],\n [4, 3, 2, 98, 94, 0, 0, 0, 0, 0],\n [5, 23, 39, 316, 0, 0, 0, 0, 0, 0],\n [4, 33, 9, 327, 3, 6, 0, 0, 0, 0],\n [4, 70, 29, 34, 378, 0, 0, 0, 0, 0],\n [22, 5, 2, 17, 53, 0, 0, 0, 0, 0],\n [15, 6, 28, 25, 10, 909, 0, 0, 0, 0],\n [4, 3, 95, 31, 0, 0, 0, 0, 0, 0],\n [3, 49, 107, 556, 24, 1768, 0, 0, 0, 0],\n [11, 12, 5, 416, 289, 0, 0, 0, 0, 0],\n [3, 2, 188, 125, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 1510, 138, 7, 2, 530, 9, 6],\n [4, 3, 2, 118, 9, 2, 2923, 979, 0, 0],\n [22, 3, 6, 0, 0, 0, 0, 0, 0, 0],\n [15, 2, 488, 475, 79, 225, 0, 0, 0, 0],\n [2924, 2, 178, 0, 0, 0, 0, 0, 0, 0],\n [4, 414, 5, 8, 2, 221, 0, 0, 0, 0],\n [4, 3, 2, 13, 9, 2, 425, 9, 2, 222],\n [11, 12, 750, 5, 8, 2, 66, 9, 2, 152],\n [4, 3, 7, 2, 221, 0, 0, 0, 0, 0],\n [11, 1354, 5, 2, 438, 0, 0, 0, 0, 0],\n [3, 6, 10, 1769, 1355, 0, 0, 0, 0, 0],\n [5, 14, 10, 475, 9, 438, 0, 0, 0, 0],\n [4, 489, 3, 8, 2, 284, 0, 0, 0, 0],\n [3, 2, 16, 107, 19, 516, 0, 0, 0, 0],\n [22, 5, 34, 80, 0, 0, 0, 0, 0, 0],\n [4, 15, 2, 980, 64, 48, 109, 0, 0, 0],\n [3, 21, 161, 96, 85, 0, 0, 0, 0, 0],\n [5, 23, 121, 206, 1227, 1511, 0, 0, 0, 0],\n [41, 30, 55, 2, 272, 0, 0, 0, 0, 0],\n [4, 2925, 3, 2, 35, 2164, 0, 0, 0, 0],\n [4, 3, 7, 2, 18, 0, 0, 0, 0, 0],\n [4, 1770, 5, 2, 825, 86, 0, 0, 0, 0],\n [4, 29, 2, 206, 500, 19, 1356, 158, 650, 0],\n [22, 3, 2, 28, 7, 120, 358, 24, 101, 0],\n [3, 6, 28, 80, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 2926, 0, 0, 0, 0, 0, 0],\n [4, 33, 9, 114, 3, 7, 2, 66, 0, 0],\n [22, 3, 6, 0, 0, 0, 0, 0, 0, 0],\n [3, 14, 10, 92, 126, 0, 0, 0, 0, 0],\n [498, 15, 2927, 9, 2, 2928, 159, 0, 0, 0],\n [4, 13, 3, 2, 143, 0, 0, 0, 0, 0],\n [4, 3, 213, 2, 262, 351, 0, 0, 0, 0],\n [11, 12, 174, 29, 30, 55, 0, 0, 0, 0],\n [104, 6, 181, 1050, 1512, 0, 0, 0, 0, 0],\n [4, 111, 3, 83, 300, 0, 0, 0, 0, 0],\n [11, 12, 17, 87, 865, 144, 464, 108, 9, 2],\n [4, 13, 5, 158, 490, 0, 0, 0, 0, 0],\n [5, 23, 17, 107, 105, 24, 140, 0, 0, 0],\n [11, 12, 504, 5, 159, 0, 0, 0, 0, 0],\n [11, 12, 2929, 5, 14, 7, 2, 32, 0, 0],\n [11, 12, 39, 5, 14, 0, 0, 0, 0, 0],\n [29, 30, 55, 43, 215, 0, 0, 0, 0, 0],\n [11, 148, 23, 354, 1771, 1772, 689, 0, 0, 0],\n [3, 6, 37, 10, 2165, 354, 0, 0, 0, 0],\n [4, 32, 9, 2, 229, 3, 6, 0, 0, 0],\n [4, 3, 8, 2, 152, 0, 0, 0, 0, 0],\n [4, 3, 2, 271, 581, 260, 0, 0, 0, 0],\n [3, 6, 10, 301, 0, 0, 0, 0, 0, 0],\n [25, 30, 1120, 131, 2166, 10, 319, 48, 0, 0],\n [4, 3, 2, 491, 53, 8, 0, 0, 0, 0],\n [11, 2930, 15, 2, 903, 79, 0, 0, 0, 0],\n [89, 6, 27, 75, 40, 318, 0, 0, 0, 0],\n [11, 12, 910, 5, 8, 6, 505, 0, 0, 0],\n [4, 26, 9, 139, 3, 51, 0, 0, 0, 0],\n [3, 6, 10, 307, 324, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 322, 0, 0, 0, 0, 0],\n [4, 26, 9, 135, 5, 23, 0, 0, 0, 0],\n [15, 2, 1513, 25, 981, 0, 0, 0, 0, 0],\n [189, 2, 98, 281, 10, 1773, 0, 0, 0, 0],\n [4, 13, 3, 82, 130, 0, 0, 0, 0, 0],\n [4, 3, 7, 101, 9, 2, 1345, 0, 0, 0],\n [11, 359, 29, 2, 2931, 2932, 506, 911, 0, 0],\n [11, 359, 5, 2, 247, 19, 2933, 0, 0, 0],\n [3, 6, 27, 161, 96, 85, 0, 0, 0, 0],\n [3, 14, 447, 110, 0, 0, 0, 0, 0, 0],\n [22, 3, 6, 16, 107, 19, 826, 0, 0, 0],\n [148, 95, 323, 335, 10, 194, 153, 0, 0, 0],\n [4, 5, 34, 31, 0, 0, 0, 0, 0, 0],\n [22, 3, 2, 44, 107, 0, 0, 0, 0, 0],\n [4, 3, 2, 138, 73, 314, 260, 0, 0, 0],\n [4, 3, 95, 38, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 824, 251, 19, 159, 59, 218, 0],\n [11, 12, 1228, 5, 7, 2, 18, 0, 0, 0],\n [4, 13, 3, 2, 1121, 518, 0, 0, 0, 0],\n [4, 406, 3, 8, 2, 58, 134, 0, 0, 0],\n [866, 181, 3, 21, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 58, 310, 0, 0, 0, 0],\n [4, 3, 2, 16, 685, 19, 0, 0, 0, 0],\n [5, 14, 1357, 0, 0, 0, 0, 0, 0, 0],\n [3, 21, 10, 328, 81, 0, 0, 0, 0, 0],\n [5, 14, 297, 7, 2, 66, 0, 0, 0, 0],\n [22, 3, 2, 129, 0, 0, 0, 0, 0, 0],\n [11, 12, 187, 243, 29, 30, 55, 0, 0, 0],\n [4, 147, 9, 867, 3, 7, 2, 18, 0, 0],\n [4, 3, 211, 8, 2, 246, 0, 0, 0, 0],\n [11, 12, 17, 5, 53, 8, 2, 78, 0, 0],\n [4, 3, 6, 28, 20, 8, 158, 170, 0, 0],\n [4, 13, 5, 2, 262, 0, 0, 0, 0, 0],\n [4, 3, 123, 2, 262, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 58, 234, 0, 0, 0, 0],\n [4, 13, 3, 2, 44, 0, 0, 0, 0, 0],\n [3, 6, 146, 225, 0, 0, 0, 0, 0, 0],\n [3, 6, 98, 20, 10, 827, 0, 0, 0, 0],\n [3, 10, 519, 9, 56, 237, 2, 17, 0, 0],\n [4, 104, 36, 236, 0, 0, 0, 0, 0, 0],\n [68, 3, 2, 483, 138, 2, 235, 1514, 0, 0],\n [3, 2, 129, 416, 24, 399, 551, 0, 0, 0],\n [54, 292, 3, 7, 2, 358, 0, 0, 0, 0],\n [3, 520, 1122, 211, 24, 2934, 8, 2, 242, 0],\n [4, 39, 5, 7, 2, 128, 0, 0, 0, 0],\n [5, 23, 39, 2935, 0, 0, 0, 0, 0, 0],\n [2, 28, 3, 658, 0, 0, 0, 0, 0, 0],\n [11, 12, 629, 5, 142, 0, 0, 0, 0, 0],\n [5, 23, 787, 0, 0, 0, 0, 0, 0, 0],\n [4, 90, 3, 8, 2, 184, 861, 0, 0, 0],\n [3, 6, 10, 136, 630, 653, 0, 0, 0, 0],\n [54, 88, 1051, 2, 396, 0, 0, 0, 0, 0],\n [4, 13, 5, 46, 205, 0, 0, 0, 0, 0],\n [4, 88, 3, 2, 16, 38, 2, 194, 1229, 7],\n [3, 14, 10, 2167, 182, 19, 2, 186, 0, 0],\n [11, 12, 276, 2168, 828, 5, 100, 0, 0, 0],\n [4, 33, 9, 70, 3, 6, 0, 0, 0, 0],\n [4, 2169, 6, 16, 55, 751, 1515, 0, 0, 0],\n [4, 5, 2, 17, 94, 0, 0, 0, 0, 0],\n [68, 3, 2, 1230, 2936, 2170, 105, 40, 2, 325],\n [3, 2, 2171, 9, 602, 1516, 0, 0, 0, 0],\n [5, 235, 17, 53, 24, 80, 0, 0, 0, 0],\n [3, 6, 10, 659, 18, 0, 0, 0, 0, 0],\n [68, 5, 2, 2937, 145, 8, 0, 0, 0, 0],\n [11, 12, 1774, 15, 2, 226, 376, 0, 0, 0],\n [3, 6, 40, 2, 201, 0, 0, 0, 0, 0],\n [4, 32, 7, 2, 229, 5, 2, 113, 53, 7],\n [3, 10, 16, 38, 10, 344, 221, 0, 0, 0],\n [5, 14, 17, 110, 0, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 20, 151, 0, 0, 0, 0],\n [22, 3, 2, 2938, 0, 0, 0, 0, 0, 0],\n [3, 2, 35, 20, 10, 118, 147, 912, 52, 0],\n [4, 26, 9, 47, 3, 8, 2, 63, 0, 0],\n [3, 14, 338, 660, 8, 60, 0, 0, 0, 0],\n [4, 219, 3, 2, 166, 268, 0, 0, 0, 0],\n [4, 3, 2, 655, 0, 0, 0, 0, 0, 0],\n [11, 12, 39, 5, 69, 0, 0, 0, 0, 0],\n [4, 29, 2, 538, 595, 0, 0, 0, 0, 0],\n [3, 2, 157, 1517, 0, 0, 0, 0, 0, 0],\n [29, 97, 2, 297, 25, 1518, 7, 158, 257, 0],\n [11, 12, 408, 365, 9, 139, 5, 69, 0, 0],\n [3, 14, 661, 139, 8, 2, 60, 0, 0, 0],\n [3, 6, 139, 50, 59, 492, 0, 0, 0, 0],\n [4, 3, 2, 2172, 138, 7, 2, 132, 0, 0],\n [4, 3, 2, 132, 62, 86, 0, 0, 0, 0],\n [4, 3, 123, 2, 57, 0, 0, 0, 0, 0],\n [4, 3, 2, 103, 2939, 0, 0, 0, 0, 0],\n [3, 6, 10, 1761, 71, 0, 0, 0, 0, 0],\n [3, 2, 28, 94, 73, 1519, 0, 0, 0, 0],\n [4, 26, 9, 47, 3, 2, 557, 507, 0, 0],\n [5, 14, 360, 8, 2, 63, 0, 0, 0, 0],\n [4, 5, 2, 1231, 8, 6, 71, 0, 0, 0],\n [15, 6, 79, 102, 59, 2940, 0, 0, 0, 0],\n [3, 117, 9, 2, 2173, 69, 110, 355, 7, 2174],\n [4, 26, 9, 71, 3, 6, 0, 0, 0, 0],\n [29, 30, 55, 1123, 0, 0, 0, 0, 0, 0],\n [11, 12, 349, 5, 982, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 453, 0, 0, 0, 0, 0],\n [11, 12, 2175, 5, 8, 46, 246, 0, 0, 0],\n [41, 30, 55, 2, 321, 244, 0, 0, 0, 0],\n [5, 2, 1124, 80, 0, 0, 0, 0, 0, 0],\n [4, 3, 6, 0, 0, 0, 0, 0, 0, 0],\n [87, 2, 354, 144, 94, 188, 0, 0, 0, 0],\n [15, 6, 28, 25, 183, 253, 8, 2, 78, 0],\n [4, 147, 197, 3, 49, 38, 0, 0, 0, 0],\n [11, 12, 2176, 2177, 29, 30, 55, 0, 0, 0],\n [4, 32, 3, 2, 16, 7, 0, 0, 0, 0],\n [3, 14, 10, 406, 2941, 8, 2, 58, 52, 0],\n [5, 34, 38, 2942, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 103, 31, 0, 0, 0, 0, 0],\n [3, 2, 122, 51, 3, 352, 123, 2, 439, 103],\n [4, 33, 9, 129, 3, 6, 0, 0, 0, 0],\n [99, 5, 119, 2, 386, 0, 0, 0, 0, 0],\n [5, 97, 2, 629, 8, 0, 0, 0, 0, 0],\n [4, 37, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 72, 80, 8, 0, 0, 0, 0],\n [4, 5, 97, 9, 2, 690, 53, 8, 0, 0],\n [4, 3, 984, 379, 2, 2943, 0, 0, 0, 0],\n [4, 13, 3, 2, 186, 8, 2, 64, 0, 0],\n [4, 293, 3, 2, 320, 62, 9, 0, 0, 0],\n [4, 3, 177, 2, 2179, 351, 0, 0, 0, 0],\n [11, 12, 829, 145, 5, 14, 0, 0, 0, 0],\n [11, 12, 168, 788, 25, 117, 1743, 0, 0, 0],\n [4, 13, 603, 3, 49, 20, 0, 0, 0, 0],\n [4, 293, 3, 2, 132, 62, 86, 0, 0, 0],\n [3, 6, 59, 440, 24, 222, 0, 0, 0, 0],\n [3, 2, 76, 434, 0, 0, 0, 0, 0, 0],\n [11, 12, 662, 0, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 13, 9, 2, 229, 0, 0, 0],\n [4, 3, 2, 913, 31, 0, 0, 0, 0, 0],\n [5, 34, 40, 10, 339, 0, 0, 0, 0, 0],\n [4, 401, 3, 2, 16, 31, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 56, 0, 0, 0],\n [5, 14, 112, 753, 0, 0, 0, 0, 0, 0],\n [5, 2, 286, 20, 1125, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 286, 0, 0, 0, 0, 0],\n [4, 70, 3, 6, 0, 0, 0, 0, 0, 0],\n [4, 70, 3, 6, 28, 31, 0, 0, 0, 0],\n [5, 2, 121, 17, 7, 6, 93, 9, 2, 133],\n [68, 104, 49, 36, 357, 102, 6, 0, 0, 0],\n [4, 13, 3, 2, 77, 0, 0, 0, 0, 0],\n [3, 6, 18, 75, 199, 0, 0, 0, 0, 0],\n [15, 6, 663, 102, 10, 251, 51, 179, 2944, 0],\n [25, 23, 17, 144, 464, 47, 656, 0, 0, 0],\n [11, 12, 206, 5, 20, 85, 1775, 0, 0, 0],\n [99, 3, 80, 0, 0, 0, 0, 0, 0, 0],\n [4, 37, 3, 456, 8, 2, 45, 0, 0, 0],\n [4, 13, 3, 2, 129, 0, 0, 0, 0, 0],\n [3, 6, 71, 2945, 0, 0, 0, 0, 0, 0],\n [4, 5, 23, 39, 0, 0, 0, 0, 0, 0],\n [11, 12, 160, 5, 14, 0, 0, 0, 0, 0],\n [5, 183, 160, 80, 0, 0, 0, 0, 0, 0],\n [5, 2, 160, 332, 2, 133, 219, 0, 0, 0],\n [22, 3, 2, 122, 285, 0, 0, 0, 0, 0],\n [22, 5, 2, 286, 53, 0, 0, 0, 0, 0],\n [29, 23, 39, 25, 1126, 0, 0, 0, 0, 0],\n [4, 13, 5, 23, 39, 0, 0, 0, 0, 0],\n [4, 3, 2, 232, 80, 123, 0, 0, 0, 0],\n [3, 2, 175, 159, 24, 345, 0, 0, 0, 0],\n [3, 2, 16, 20, 10, 204, 0, 0, 0, 0],\n [3, 2, 18, 7, 914, 0, 0, 0, 0, 0],\n [4, 3, 2, 57, 31, 0, 0, 0, 0, 0],\n [3, 6, 57, 1358, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 57, 316, 108, 9, 0, 0, 0],\n [3, 6, 57, 356, 0, 0, 0, 0, 0, 0],\n [4, 138, 3, 2, 42, 830, 73, 0, 0, 0],\n [4, 266, 3, 2, 321, 664, 0, 0, 0, 0],\n [3, 2, 57, 789, 0, 0, 0, 0, 0, 0],\n [3, 51, 10, 44, 0, 0, 0, 0, 0, 0],\n [68, 3, 2, 35, 268, 7, 101, 9, 2, 308],\n [4, 33, 9, 37, 457, 30, 55, 7, 2, 521],\n [3, 14, 10, 165, 576, 41, 0, 0, 0, 0],\n [11, 12, 553, 2946, 5, 7, 2, 180, 0, 0],\n [4, 3, 2, 48, 1037, 0, 0, 0, 0, 0],\n [4, 1233, 123, 2, 476, 284, 0, 0, 0, 0],\n [4, 3, 8, 2, 16, 8, 2, 2180, 2947, 0],\n [3, 2, 157, 62, 0, 0, 0, 0, 0, 0],\n [4, 5, 2, 409, 19, 2, 64, 0, 0, 0],\n [4, 3, 2181, 259, 9, 2, 218, 0, 0, 0],\n [15, 6, 169, 172, 19, 36, 915, 0, 0, 0],\n [4, 3, 2, 235, 898, 138, 7, 2, 18, 0],\n [11, 12, 39, 5, 7, 2, 209, 0, 0, 0],\n [4, 3, 2, 35, 377, 0, 0, 0, 0, 0],\n [3, 14, 10, 156, 182, 19, 2, 45, 315, 0],\n [3, 2, 28, 620, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 31, 8, 2, 681, 0, 0],\n [4, 13, 3, 2, 2948, 258, 0, 0, 0, 0],\n [3, 6, 10, 339, 0, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 31, 0, 0, 0, 0, 0],\n [4, 5, 2, 178, 1234, 40, 2, 501, 0, 0],\n [4, 13, 3, 2, 310, 0, 0, 0, 0, 0],\n [11, 149, 3, 2, 28, 0, 0, 0, 0, 0],\n [4, 32, 7, 2, 229, 3, 6, 0, 0, 0],\n [3, 6, 10, 208, 24, 466, 1235, 0, 0, 0],\n [3, 49, 7, 10, 868, 1520, 0, 0, 0, 0],\n [3, 2, 57, 199, 2, 231, 0, 0, 0, 0],\n [99, 3, 123, 2, 231, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 136, 0, 0, 0, 0, 0],\n [22, 3, 2, 136, 80, 7, 2, 27, 0, 0],\n [4, 3, 2, 44, 573, 177, 0, 0, 0, 0],\n [5, 14, 43, 173, 7, 2, 76, 0, 0, 0],\n [3, 14, 1776, 1359, 7, 6, 27, 0, 0, 0],\n [11, 12, 198, 5, 14, 0, 0, 0, 0, 0],\n [3, 14, 196, 7, 6, 27, 0, 0, 0, 0],\n [3, 6, 2, 467, 0, 0, 0, 0, 0, 0],\n [4, 13, 539, 5, 8, 2, 347, 0, 0, 0],\n [4, 13, 3, 2, 916, 8, 2, 78, 0, 0],\n [4, 3, 49, 38, 0, 0, 0, 0, 0, 0],\n [3, 6, 16, 40, 402, 0, 0, 0, 0, 0],\n [3, 2, 42, 255, 0, 0, 0, 0, 0, 0],\n [4, 5, 2, 286, 268, 8, 0, 0, 0, 0],\n [4, 13, 3, 2, 56, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 2182, 9, 2, 135, 0, 0],\n [3, 2, 214, 8, 24, 259, 0, 0, 0, 0],\n [4, 3, 2, 35, 2183, 19, 29, 0, 0, 0],\n [4, 3, 2, 831, 245, 38, 7, 82, 257, 0],\n [4, 3, 2, 35, 31, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 38, 0, 0, 0, 0, 0],\n [5, 34, 7, 2184, 0, 0, 0, 0, 0, 0],\n [3, 2, 76, 328, 0, 0, 0, 0, 0, 0],\n [4, 401, 15, 95, 663, 19, 36, 7, 2, 358],\n [4, 1127, 3, 2, 338, 7, 6, 18, 0, 0],\n [4, 13, 3, 2, 654, 0, 0, 0, 0, 0],\n [3, 51, 10, 310, 0, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 314, 8, 2, 273, 0, 0],\n [5, 14, 12, 17, 0, 0, 0, 0, 0, 0],\n [3, 14, 10, 2949, 8, 2, 240, 0, 0, 0],\n [11, 12, 85, 135, 0, 0, 0, 0, 0, 0],\n [4, 26, 9, 122, 3, 6, 0, 0, 0, 0],\n [4, 3, 2, 165, 143, 0, 0, 0, 0, 0],\n [4, 691, 1128, 3, 7, 2, 66, 0, 0, 0],\n [3, 21, 137, 81, 0, 0, 0, 0, 0, 0],\n [4, 3, 8, 2, 58, 170, 0, 0, 0, 0],\n [5, 2, 112, 125, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 540, 156, 0, 0, 0, 0, 0],\n [179, 6, 36, 10, 2950, 1521, 0, 0, 0, 0],\n [11, 12, 17, 5, 20, 151, 0, 0, 0, 0],\n [4, 754, 5, 34, 1236, 0, 0, 0, 0, 0],\n [54, 3, 1360, 7, 2, 76, 2, 440, 24, 2],\n [22, 3, 6, 0, 0, 0, 0, 0, 0, 0],\n [3, 6, 1522, 1777, 0, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 20, 120, 0, 0, 0, 0],\n [3, 14, 196, 0, 0, 0, 0, 0, 0, 0],\n [4, 5, 2, 17, 31, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 27, 0, 0, 0, 0, 0],\n [4, 3, 2, 16, 80, 8, 0, 0, 0, 0],\n [3, 14, 235, 207, 10, 2185, 7, 6, 61, 0],\n [4, 70, 3, 49, 65, 0, 0, 0, 0, 0],\n [4, 493, 9, 1237, 3, 6, 0, 0, 0, 0],\n [4, 754, 3, 83, 2186, 0, 0, 0, 0, 0],\n [4, 67, 3, 8, 2, 115, 0, 0, 0, 0],\n [11, 12, 173, 5, 7, 2, 76, 0, 0, 0],\n [11, 12, 174, 0, 0, 0, 0, 0, 0, 0],\n [4, 32, 3, 6, 0, 0, 0, 0, 0, 0],\n [22, 3, 2, 424, 0, 0, 0, 0, 0, 0],\n [11, 12, 275, 5, 40, 2, 60, 0, 0, 0],\n [11, 12, 171, 5, 14, 0, 0, 0, 0, 0],\n [15, 6, 136, 25, 1361, 213, 403, 490, 0, 0],\n [11, 12, 256, 5, 14, 110, 0, 0, 0, 0],\n [4, 26, 9, 44, 3, 51, 0, 0, 0, 0],\n [4, 143, 3, 123, 2, 39, 0, 0, 0, 0],\n [3, 14, 10, 604, 37, 7, 2, 27, 0, 0],\n [68, 104, 162, 2187, 6, 1778, 8, 2, 441, 0],\n [3, 14, 10, 251, 8, 2, 522, 24, 1779, 2188],\n [15, 95, 79, 203, 19, 36, 7, 10, 27, 0],\n [11, 12, 523, 9, 344, 5, 8, 2, 366, 0],\n [4, 13, 3, 2, 1230, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 77, 0, 0, 0, 0, 0],\n [11, 12, 253, 5, 14, 0, 0, 0, 0, 0],\n [41, 2, 210, 1523, 390, 6, 0, 0, 0, 0],\n [22, 3, 2, 2189, 0, 0, 0, 0, 0, 0],\n [3, 14, 10, 1524, 387, 0, 0, 0, 0, 0],\n [22, 5, 2, 917, 0, 0, 0, 0, 0, 0],\n [3, 21, 2952, 50, 6, 37, 19, 36, 8, 2],\n [3, 14, 520, 8, 2, 366, 0, 0, 0, 0],\n [4, 13, 5, 2, 582, 0, 0, 0, 0, 0],\n [11, 12, 92, 145, 5, 69, 0, 0, 0, 0],\n [4, 3, 2, 974, 1362, 0, 0, 0, 0, 0],\n [11, 12, 112, 41, 30, 55, 0, 0, 0, 0],\n [11, 12, 120, 226, 145, 5, 100, 7, 6, 18],\n [3, 2, 32, 1517, 0, 0, 0, 0, 0, 0],\n [3, 6, 10, 72, 24, 10, 98, 0, 0, 0],\n [3, 14, 10, 790, 8, 2, 1129, 0, 0, 0],\n [15, 2, 692, 25, 314, 0, 0, 0, 0, 0],\n [11, 41, 30, 524, 2, 72, 87, 144, 53, 140],\n [3, 21, 829, 7, 14, 0, 0, 0, 0, 0],\n [22, 5, 2, 17, 91, 40, 0, 0, 0, 0],\n [3, 192, 7, 2, 157, 0, 0, 0, 0, 0],\n [3, 2, 35, 20, 151, 0, 0, 0, 0, 0],\n [11, 12, 17, 25, 750, 0, 0, 0, 0, 0],\n [3, 2, 16, 119, 10, 224, 0, 0, 0, 0],\n [4, 13, 3, 2, 58, 56, 341, 0, 0, 0],\n [4, 3, 2, 33, 9, 293, 167, 50, 2, 2953],\n [3, 14, 10, 201, 7, 6, 128, 0, 0, 0],\n [4, 3, 182, 19, 2, 200, 0, 0, 0, 0],\n [4, 26, 9, 200, 5, 23, 0, 0, 0, 0],\n [3, 6, 10, 869, 1780, 169, 0, 0, 0, 0],\n [11, 12, 275, 5, 7, 6, 18, 0, 0, 0],\n [4, 13, 3, 2, 458, 7, 2, 27, 0, 0],\n [4, 13, 3, 2, 985, 0, 0, 0, 0, 0],\n [4, 489, 3, 8, 2, 27, 0, 0, 0, 0],\n [3, 2, 150, 268, 0, 0, 0, 0, 0, 0],\n [54, 37, 3, 356, 7, 2, 458, 0, 0, 0],\n [3, 2, 42, 356, 0, 0, 0, 0, 0, 0],\n [3, 2, 918, 898, 0, 0, 0, 0, 0, 0],\n [4, 3, 6, 494, 260, 0, 0, 0, 0, 0],\n [3, 2, 129, 2954, 0, 0, 0, 0, 0, 0],\n [3, 2, 103, 237, 112, 0, 0, 0, 0, 0],\n [5, 14, 572, 112, 8, 6, 1363, 0, 0, 0],\n [29, 30, 55, 10, 1781, 8, 2, 78, 0, 0],\n [4, 3, 216, 2, 282, 0, 0, 0, 0, 0],\n [3, 2, 106, 631, 105, 0, 0, 0, 0, 0],\n [3, 2, 576, 41, 434, 0, 0, 0, 0, 0],\n [3, 6, 146, 19, 384, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 919, 305, 0, 0, 0, 0],\n [5, 2, 17, 357, 50, 2, 178, 0, 0, 0],\n [4, 147, 3, 2, 2190, 0, 0, 0, 0, 0],\n [3, 14, 10, 1130, 8, 2, 476, 60, 0, 0],\n [4, 3, 2, 16, 80, 7, 0, 0, 0, 0],\n [3, 2, 57, 380, 0, 0, 0, 0, 0, 0],\n [87, 6, 71, 865, 144, 1131, 0, 0, 0, 0],\n [4, 3, 2, 118, 9, 2, 208, 423, 51, 3],\n [5, 2, 39, 7, 158, 419, 521, 0, 0, 0],\n [4, 90, 3, 6, 693, 252, 548, 0, 0, 0],\n [11, 12, 17, 73, 165, 558, 0, 0, 0, 0],\n [4, 13, 3, 2, 48, 0, 0, 0, 0, 0],\n [4, 13, 3, 82, 52, 0, 0, 0, 0, 0],\n [11, 12, 17, 5, 7, 2, 208, 0, 0, 0],\n [4, 33, 9, 37, 3, 6, 0, 0, 0, 0],\n [15, 2, 42, 25, 307, 583, 0, 0, 0, 0],\n [15, 2, 166, 25, 755, 0, 0, 0, 0, 0],\n [4, 694, 9, 427, 3, 8, 2, 254, 141, 9],\n [3, 6, 10, 442, 71, 0, 0, 0, 0, 0],\n [4, 3, 2, 28, 31, 0, 0, 0, 0, 0],\n [99, 3, 2, 28, 8, 2, 246, 0, 0, 0],\n [68, 3, 2, 16, 1782, 8, 10, 347, 0, 0],\n [3, 6, 59, 467, 24, 665, 0, 0, 0, 0],\n [5, 14, 43, 173, 7, 2, 76, 0, 0, 0],\n [4, 3, 95, 31, 0, 0, 0, 0, 0, 0],\n [22, 3, 2, 57, 0, 0, 0, 0, 0, 0],\n [3, 6, 18, 7, 13, 0, 0, 0, 0, 0],\n [4, 3, 2955, 108, 9, 2, 56, 7, 2, 363],\n [4, 3, 2, 230, 138, 7, 2, 56, 0, 0],\n [4, 15, 21, 172, 51, 2, 16, 8, 2, 417],\n [3, 6, 86, 2956, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 63, 0, 0, 0, 0, 0],\n [3, 6, 47, 340, 50, 30, 0, 0, 0, 0],\n [5, 311, 1525, 247, 50, 2957, 0, 0, 0, 0],\n [15, 6, 28, 25, 10, 2958, 1364, 2191, 2192, 0],\n [148, 2, 61, 513, 259, 0, 0, 0, 0, 0],\n [3, 49, 7, 10, 45, 0, 0, 0, 0, 0],\n [3, 6, 10, 463, 0, 0, 0, 0, 0, 0],\n [11, 12, 1365, 0, 0, 0, 0, 0, 0, 0],\n [11, 12, 2959, 9, 116, 5, 391, 278, 0, 0],\n [4, 3, 50, 921, 177, 6, 1345, 0, 0, 0],\n [4, 5, 2, 17, 53, 8, 0, 0, 0, 0],\n [15, 6, 2193, 25, 2194, 1783, 0, 0, 0, 0],\n [11, 12, 251, 1784, 5, 100, 0, 0, 0, 0],\n [11, 12, 248, 922, 5, 100, 0, 0, 0, 0],\n [3, 6, 10, 495, 48, 0, 0, 0, 0, 0],\n [3, 2, 71, 477, 0, 0, 0, 0, 0, 0],\n [29, 30, 343, 2, 525, 3, 1526, 1785, 19, 2],\n [4, 2, 16, 38, 0, 0, 0, 0, 0, 0],\n [15, 2, 42, 25, 10, 688, 0, 0, 0, 0],\n [41, 30, 55, 43, 168, 0, 0, 0, 0, 0],\n [4, 13, 5, 2, 1366, 101, 256, 0, 0, 0],\n [4, 37, 3, 14, 0, 0, 0, 0, 0, 0],\n [68, 457, 117, 2960, 2, 1786, 3, 2961, 110, 0],\n [22, 3, 2, 58, 909, 0, 0, 0, 0, 0],\n [87, 2, 16, 584, 1787, 10, 2195, 0, 0, 0],\n [4, 3, 986, 263, 2, 58, 170, 0, 0, 0],\n [4, 708, 247, 5, 8, 2, 60, 0, 0, 0],\n [4, 5, 2, 155, 8, 6, 354, 0, 0, 0],\n [4, 33, 9, 1132, 3, 7, 2, 221, 0, 0],\n [3, 6, 10, 137, 81, 0, 0, 0, 0, 0],\n [3, 14, 10, 666, 44, 8, 2, 156, 0, 0],\n [22, 15, 6, 478, 496, 0, 0, 0, 0, 0],\n [4, 141, 9, 2, 410, 5, 2, 231, 870, 8],\n [4, 13, 3, 2, 56, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 27, 0, 0, 0, 0, 0],\n [4, 13, 3, 2, 301, 0, 0, 0, 0, 0],\n [4, 5, 34, 107, 19, 281, 73, 23, 302, 0],\n [22, 3, 2, 57, 0, 0, 0, 0, 0, 0],\n [15, 2, 72, 361, 2962, 0, 0, 0, 0, 0],\n [11, 12, 2963, 5, 7, 2, 18, 0, 0, 0],\n [4, 911, 2964, 0, 0, 0, 0, 0, 0, 0],\n [4, 13, 3, 6, 127, 0, 0, 0, 0, 0],\n [4, 521, 3, 6, 127, 7, 0, 0, 0, 0],\n ...]"}, "metadata": {}}]}, {"cell_type": "markdown", "source": "## 3.\u8bad\u7ec3\u8fc7\u7a0b", "metadata": {}}, {"cell_type": "markdown", "source": "### 3.1 \u8d85\u53c2\u6570\u8bbe\u7f6e", "metadata": {}}, {"cell_type": "code", "source": "#from easydict import EasyDict as edict\noptions = OrderedDict()\n# data related\noptions['data_path'] = './data/'\n#options['feature_file'] = 'trainval_feat.h5'\n#options['expt_folder'] = 'expt_1'\noptions['model_name'] = 'imageqa'\noptions['train_split'] = 'trainval1'\noptions['val_split'] = 'val2'\noptions['shuffle'] = True\noptions['reverse'] = True\noptions['sample_answer'] = True\n\noptions['num_region'] = 196\noptions['region_dim'] = 512\n\n#`13746\noptions['n_words'] = 6620\noptions['n_output'] = 1000\n\n# structure options\noptions['combined_num_mlp'] = 1\noptions['combined_mlp_drop_0'] = True\noptions['combined_mlp_act_0'] = 'linear'\noptions['sent_drop'] = False\noptions['use_tanh'] = False\n\noptions['use_attention_drop'] = False\n\n# dimensions\noptions['n_emb'] = 500\noptions['n_dim'] = 1024\noptions['n_image_feat'] = options['region_dim']\noptions['n_common_feat'] = 500\noptions['n_attention'] = 512\n\n# initialization\noptions['init_type'] = 'uniform'\noptions['range'] = 0.01\noptions['std'] = 0.01\noptions['init_lstm_svd'] = False\n\noptions['forget_bias'] = np.float32(1.0)\n\n# learning parameters\noptions['optimization'] = 'sgd' # choices\noptions['batch_size'] = 100\noptions['lr'] = np.float32(0.05)\noptions['w_emb_lr'] = np.float32(80)\noptions['momentum'] = np.float32(0.9)\noptions['gamma'] = 1\noptions['step'] = 10\noptions['step_start'] = 100\noptions['max_epochs'] = 50\noptions['weight_decay'] = 0.0005\noptions['decay_rate'] = np.float32(0.999)\noptions['drop_ratio'] = np.float32(0.5)\noptions['smooth'] = np.float32(1e-8)\noptions['grad_clip'] = np.float32(0.1)\n\n# log params\noptions['disp_interval'] = 10\noptions['eval_interval'] = 1000\noptions['save_interval'] = 500\n\n#new\noptions['dict_size'] = 6620", "metadata": {"trusted": true}, "execution_count": 10, "outputs": []}, {"cell_type": "code", "source": "# vgg\u6a21\u578b\u5bfc\u5165\u76f8\u5173\u5305\n# mox.file.copy_parallel(src_url=\"obs://nlp-kim/project/code/image_model/src\",dst_url=\"./src/\")\nfrom PIL import Image, ImageFile\nfrom src.utils.logging import get_logger\nfrom src.dataset import classification_dataset\nfrom easydict import EasyDict as edict\nfrom src.config import imagenet_cfg as vgg_cfg\n# from data_vqa.vqa_config import model_cfg\nfrom src.vgg import vgg16\n\nimport time\nimport datetime\nimport mindspore.dataset.vision.py_transforms as vision", "metadata": {"trusted": true}, "execution_count": 11, "outputs": []}, {"cell_type": "code", "source": "model_cfg = edict({\n    \"cnn_ckpt_19\":\"./data/vgg19_ascend_v111_imagenet2012_research_cv_bs64_acc74.ckpt\",\n    \"cnn_ckpt_16\":\"./data/vgg16_ascend_v120_imagenet2012_official_cv_bs32_acc73.ckpt\",\n    \"log_path\":\"./outputs\",\n\n    \"device_target\": 'Ascend',\n    \"per_batch_size\": 32,\n    \"graph_ckpt\":1,\n    \"rank\": 0,\n    \"group_size\":1\n})", "metadata": {"trusted": true}, "execution_count": 12, "outputs": []}, {"cell_type": "code", "source": "image_path = {\n    \"train\":\"./data/images/train\",\n    \"test\":\"./data/images/test\",\n    \"val\":\"./data/images/val\"\n}\n\nannotation_path = {\n    \"train\":\"./data/annotation/train.json\",\n    \"test\":\"./data/annotation/test.json\",\n    \"val\":\"./data/annotation/val.json\"\n}\n\nmodel_cfg= edict({\n    \"annotation\":annotation_path,\n    \"image\":image_path,\n    \"cnn_ckpt_19\":\"./data/vgg19_ascend_v111_imagenet2012_research_cv_bs64_acc74.ckpt\",\n    \"cnn_ckpt_16\":\"./data/vgg16_ascend_v120_imagenet2012_official_cv_bs32_acc73.ckpt\",\n    \"log_path\":\"./outputs\",\n\n    \"device_target\": 'Ascend',\n    \"per_batch_size\": 32,\n    \"graph_ckpt\":1,\n    \"rank\": 0,\n    \"group_size\":1\n})", "metadata": {"trusted": true}, "execution_count": 13, "outputs": []}, {"cell_type": "code", "source": "context.set_context(mode=context.GRAPH_MODE, device_target=model_cfg.device_target, device_id=0,enable_auto_mixed_precision=True,save_graphs=False)", "metadata": {"trusted": true}, "execution_count": 14, "outputs": []}, {"cell_type": "code", "source": "model_cfg.outputs_dir = os.path.join(model_cfg.log_path,\n                                    datetime.datetime.now().strftime('%Y-%m-%d_time_%H_%M_%S'))\n\nmodel_cfg.logger = get_logger(model_cfg.outputs_dir, model_cfg.rank)", "metadata": {"trusted": true}, "execution_count": 15, "outputs": []}, {"cell_type": "markdown", "source": "### 3.2\u6a21\u578b\u642d\u5efa", "metadata": {}}, {"cell_type": "code", "source": "# \u5bfc\u5165vgg\u6a21\u578b\nmodel_cfg.logger.important_info('start create vgg')\nvgg = vgg16(vgg_cfg.num_classes, vgg_cfg, phase=\"test\",include_top = False)\nvgg.add_flags_recursive(fp16=False)\nvgg.set_train(False)\nmodel_cfg.logger.important_info('start load checkpoint')\nparam_dict = load_checkpoint(model_cfg.cnn_ckpt_16)\nload_param_into_net(vgg, param_dict)", "metadata": {"trusted": true}, "execution_count": 16, "outputs": [{"name": "stdout", "text": "2021-07-14 15:39:26,381:INFO:\n**********************************************************************\n**********************************************************************\n**\n**\n**        start create vgg\n**\n**\n**********************************************************************\n**********************************************************************\n\n2021-07-14 15:39:26,916:INFO:\n**********************************************************************\n**********************************************************************\n**\n**\n**        start load checkpoint\n**\n**\n**********************************************************************\n**********************************************************************\n\n", "output_type": "stream"}, {"execution_count": 16, "output_type": "execute_result", "data": {"text/plain": "[]"}, "metadata": {}}]}, {"cell_type": "code", "source": "# def img2tensor(img_root,img_prefix,img_id):\n#         img_path = os.path.join(img_root,img_prefix+\"_\"+str(img_id).zfill(12)+\".jpg\")\n#         print(\"img_path:\",img_path)\n#         img = Image.open(img_path).convert('RGB')\n#         transform = edict({\n# #             \"Decode\": vision.Decode(),\n#             \"Resize\": vision.Resize((512, 512)),\n#             \"CenterCrop\": vision.CenterCrop(448),\n# #             \"Normalize\": vision.Normalize(mean=mean, std=std),\n# #             \"HWC2CHW\": vision.HWC2CHW(),\n#             \"ToTensor\":vision.ToTensor()\n#         })\n#         # img = transform.Decode(img)\n#         img = transform.Resize(img)\n#         img = transform.CenterCrop(img)\n#         img = transform.ToTensor(img)\n#         print(\"totensor:\",img)\n#     #     img = transform.Normalize(img) # CHW\n#     #     print(\"normalized:\",img)\n#     #     img = transform.HWC2CHW(img)\n#         img = [img]\n#         tensor = Tensor(img,mstype.float32)\n#         return tensor", "metadata": {"trusted": true}, "execution_count": 17, "outputs": []}, {"cell_type": "code", "source": "def get_feature_map(tensor):\n    model_cfg.logger.important_info('start get feature map')\n    output = vgg(tensor)  \n    return output", "metadata": {"trusted": true}, "execution_count": 18, "outputs": []}, {"cell_type": "code", "source": "# img = img2tensor(model_cfg.image.train,\"COCO_train2014\",9)\n# image_feat = get_feature_map(img)", "metadata": {"trusted": true}, "execution_count": 19, "outputs": []}, {"cell_type": "code", "source": "# image_feat = image_feat.transpose(0,2,3,1)\n# image_feat = image_feat.reshape(1, 196, 512)", "metadata": {"trusted": true}, "execution_count": 20, "outputs": []}, {"cell_type": "code", "source": "from collections import Counter\nimport numpy as np\nimport random\nfrom collections import OrderedDict\nimport math\n\nimport mindspore\nimport mindspore.nn as nn\nfrom mindspore import Tensor\n\n#from mindspore.ops import operations as ops\nfrom mindspore import ops\nfrom mindspore import dtype as mstype\n\nfloatX = np.float32\n\ndef init_weight(n, d, options):\n    ''' initialize weight matrix\n    options['init_type'] determines\n    gaussian or uniform initlizaiton\n    '''\n    if options['init_type'] == 'gaussian':\n        return Tensor((np.random.randn(n, d)).astype(floatX)) * options['std']\n    elif options['init_type'] == 'uniform':\n        # [-range, range]\n        return Tensor(((np.random.rand(n, d) * 2 - 1) * \\\n                options['range']).astype(floatX))\n    \ndef ortho_weight(ndim):\n    \"\"\"\n    Random orthogonal weights, we take\n    the right matrix in the SVD.\n\n    Remember in SVD, u has the same # rows as W\n    and v has the same # of cols as W. So we\n    are ensuring that the rows are\n    orthogonal.\n    \"\"\"\n    W = np.random.randn(ndim, ndim)\n    u, _, _ = np.linalg.svd(W)\n    return Tensor(u).astype('float32')\n\ndef init_fflayer(params, nin, nout, options, prefix='ff'):\n    ''' initialize ff layer\n    '''\n    params[prefix + '_w'] = init_weight(nin, nout, options)\n    params[prefix + '_b'] = Tensor(np.zeros(nout, dtype='float32'))\n    return params\n\n# def init_lstm_layer(params, nin, ndim, options, prefix='lstm'):\n#     ''' initializt lstm layer\n#     '''\n#     params[prefix + '_w_x'] = init_weight(nin, 4 * ndim, options)\n#     # use svd trick to initializ\n#     if options['init_lstm_svd']:\n#         params[prefix + '_w_h'] = Tensor(np.concatenate([ortho_weight(ndim),\n#                                                   ortho_weight(ndim),\n#                                                   ortho_weight(ndim),\n#                                                   ortho_weight(ndim)],\n#                                                  axis=1))\n#     else:\n#         params[prefix + '_w_h'] = init_weight(ndim, 4 * ndim, options)\n#     params[prefix + '_b_h'] = Tensor(np.zeros(4 * ndim, dtype='float32'))\n#     # set forget bias to be positive\n#     params[prefix + '_b_h'][ndim : 2*ndim] = Tensor(np.float32(options.get('forget_bias', 0)))\n#     return params\n\n# initialize the parmaters\ndef init_params(options):\n    ''' Initialize all the parameters\n    '''\n    params = OrderedDict()\n    n_words = options['n_words']\n    n_emb = options['n_emb']\n    n_dim = options['n_dim']\n    n_image_feat = options['n_image_feat']\n    n_common_feat = options['n_common_feat']\n    n_output = options['n_output']\n    n_attention = options['n_attention']\n\n    params['w_emb'] = Tensor((np.random.rand(n_words, n_emb) * 2 - 1) * 0.5).astype(floatX)\n\n    params = init_fflayer(params, n_image_feat, n_dim, options,\n                          prefix='image_mlp')\n\n    # attention model based parameters\n    params = init_fflayer(params, n_dim, n_attention, options,\n                          prefix='image_att_mlp_1')\n    params = init_fflayer(params, n_dim, n_attention, options,\n                          prefix='sent_att_mlp_1')\n    params = init_fflayer(params, n_attention, 1, options,\n                          prefix='combined_att_mlp_1')\n    params = init_fflayer(params, n_dim, n_attention, options,\n                          prefix='image_att_mlp_2')\n    params = init_fflayer(params, n_dim, n_attention, options,\n                          prefix='sent_att_mlp_2')\n    params = init_fflayer(params, n_attention, 1, options,\n                          prefix='combined_att_mlp_2')\n\n\n    # params for sentence image mlp\n    for i in range(options['combined_num_mlp']):\n        if i == 0 and options['combined_num_mlp'] == 1:\n            params = init_fflayer(params, n_dim, n_output,\n                                  options, prefix='combined_mlp_%d'%(i))\n        elif i == 0 and options['combined_num_mlp'] != 1:\n            params = init_fflayer(params, n_dim, n_common_feat,\n                                  options, prefix='combined_mlp_%d'%(i))\n        elif i == options['combined_num_mlp'] - 1 :\n            params = init_fflayer(params, n_common_feat, n_output,\n                                  options, prefix='combined_mlp_%d'%(i))\n        else:\n            params = init_fflayer(params, n_common_feat, n_common_feat,\n                                  options, prefix='combined_mlp_%d'%(i))\n\n    # lstm layer\n    #params = init_lstm_layer(params, n_emb, n_dim, options, prefix='sent_lstm')\n\n    return params\n\ndef init_shared_params(params):\n    ''' return a shared version of all parameters\n    '''\n    global shared_params\n    shared_params = OrderedDict()\n    for k, p in params.items():\n        shared_params[k] = params[k]\n\n    return shared_params\n\ndef fflayer(shared_params, x, options, prefix='ff', act_func='tanh'):\n    ''' fflayer: multiply weight then add bias\n    '''\n    tanh = nn.Tanh()\n    input = ops.dot(x, Tensor(shared_params[prefix + '_w'])) + \\\n                          Tensor(shared_params[prefix + '_b'])\n    return tanh(input)\n\ndef fflayer1(shared_params, x, options, prefix='ff'):\n    ''' fflayer: multiply weight then add bias\n    '''\n    input = ops.dot(x, Tensor(shared_params[prefix + '_w'])) + \\\n                          Tensor(shared_params[prefix + '_b'])\n    return input\n\ndef get_lr(options, curr_epoch):\n    if options['optimization'] == 'sgd':\n        power = max((curr_epoch - options['step_start']) / options['step'], 0)\n        power = math.ceil(power)\n        return options['lr'] * (options['gamma'] ** power)  #\n    else:\n        return options['lr']", "metadata": {"trusted": true}, "execution_count": 39, "outputs": []}, {"cell_type": "code", "source": "floatX = np.float32\nbatch_size = options['batch_size']\nmax_epochs = options['max_epochs']\n\n###############\n# build model #\n###############\nparams = init_params(options)\nshared_params = init_shared_params(params)", "metadata": {"trusted": true}, "execution_count": 40, "outputs": []}, {"cell_type": "code", "source": "# input_idx = np.ones((6618,100),dtype = 'int32')\n# shared_params['w_emb'] = ((np.random.rand(6620, 500) * 2 - 1) * 0.5).astype(floatX)\n# empty_word = np.zeros((1, 500), dtype='float32')\n# w_emb_extend = shared_params['w_emb']\n# input_emb = w_emb_extend[input_idx]", "metadata": {"trusted": true}, "execution_count": 41, "outputs": []}, {"cell_type": "code", "source": "class LSTM(nn.Cell):\n    def __init__(self, options, is_training=True):\n        super(LSTM, self).__init__()\n        if is_training:\n            self.batch_size = options['batch_size']\n        else:\n            self.batch_size = 1\n            \n        self.n_dim = options['n_dim']\n        self.n_emb = options['n_emb']\n        self.dropout = options['drop_ratio']\n        \n        # TODO\n        self.h = Tensor(np.zeros((1,self.batch_size, self.n_dim), dtype='float32'))\n        self.c = Tensor(np.zeros((1,self.batch_size, self.n_dim), dtype='float32'))\n        \n        self.rnn = nn.LSTM(self.n_emb,self.n_dim,1,True,True,self.dropout)\n        #self.cast = P.Cast()\n\n    def construct(self, x):\n        #x = self.cast(x, mstype.float16)\n        output,(h1,c1) = self.rnn(x, (self.h,self.c))\n        return output,(h1,c1)\n\nclass Question(nn.Cell):\n    def __init__(self, options, is_training=True):\n        super(Question, self).__init__()\n        #dict_size(vocab_size)\n        self.dict_size = options['dict_size']\n        #n_dim (hidden_size)\n        self.n_dim = options['n_dim']\n        self.n_emb = options['n_emb']\n        \n        if is_training:\n            self.batch_size = options['batch_size']\n        else:\n            self.batch_size = 1\n\n        #self.trans = P.Transpose()\n        #self.perm = (1, 0, 2)\n        \n        #HIGHLIGHT \u7b2c\u4e8c\u4e2a\u53c2\u6570n_dim -> n_emb\n        self.embedding = nn.Embedding(self.dict_size, self.n_emb)\n        #?\n        self.lstm = LSTM(options, is_training=is_training).to_float(mstype.float16)\n        #self.h = Tensor(np.zeros((self.batch_size, self.n_dim)).astype(np.float16))\n        #self.c = Tensor(np.zeros((self.batch_size, self.n_dim)).astype(np.float16))\n\n    def construct(self, question_input):\n        embeddings = self.embedding(question_input)\n        #embeddings = self.trans(embeddings, self.perm)\n        output, (hn,cn) = self.lstm(embeddings)\n        return output, hn, cn\n", "metadata": {"trusted": true}, "execution_count": 42, "outputs": []}, {"cell_type": "code", "source": "from mindspore.ops import operations as P", "metadata": {"trusted": true}, "execution_count": 43, "outputs": []}, {"cell_type": "code", "source": "class VQA(nn.Cell):\n    def __init__(self, options, is_train=True):\n        super(VQA, self).__init__()\n#         self.max_len = config.max_seq_length\n        self.is_train = is_train\n\n        #self.encoder = Encoder(config, is_train)\n        #self.decoder = Decoder(config, is_train)\n        self.expanddims = P.ExpandDims()\n        self.squeeze = P.Squeeze(axis=0)\n        self.argmax = P.ArgMaxWithValue(axis=int(2), keep_dims=True)\n        self.concat = P.Concat(axis=1)\n        self.concat2 = P.Concat(axis=0)\n        self.select = P.Select()\n        self.softmax = nn.Softmax()\n        self.print = P.Print()\n        \n        \n        ##### my #####\n        self.question = Question(options, is_train)\n        self.vgg = vgg\n    \n    def construct(self, x, src, dst):\n        model_cfg.logger.important_info('start construct')\n#         model_cfg.logger.important_info(x)\n#         model_cfg.logger.important_info(src)\n\n        self.print(\"src:\",src)\n        self.print(\"dst:\",dst)\n        self.print(\"x:\",x)\n        image_feat = self.vgg(x)\n        image_feat = image_feat.transpose(0,2,3,1)\n        image_feat = image_feat.reshape(1,196,512)\n        output,h_encode,c_encode = self.question(src)\n                \n        h_encode = h_encode[0][-1]\n        h_encode = h_encode[None,:]\n        # h_encode.shape 1,1024\n        \n        image_feat = fflayer(shared_params, image_feat, options,\n                             prefix='image_mlp',\n                              act_func='tanh')\n        image_feat = image_feat[0]\n        #image_feat.shape 196,1024\n        \n        image_feat_down = image_feat\n        #image_feat_down.shape 196,1024\n        \n        image_feat_attention_1 = fflayer(shared_params, image_feat_down, options,\n                                         prefix='image_att_mlp_1',\n                                         act_func='tanh')\n        #image_feat_attention_1.shape 196,512\n\n        \n        h_encode_attention_1 = fflayer(shared_params, h_encode, options,\n                                       prefix='sent_att_mlp_1',\n                                       act_func='tanh')\n        #h_encode_attentioshapehape 1,512\n        \n        combined_feat_attention_1 = image_feat_attention_1 + \\\n                            h_encode_attention_1[:, None, :]\n        #combined_feat_attention_1.shape 1,196,512\n\n        #if options['use_attention_drop']:\n        #combined_feat_attention_1 = dropout_layer(combined_feat_attention_1,\n                                                #dropout, trng, drop_ratio)\n        combined_feat_attention_1 = fflayer1(shared_params,\n                                    combined_feat_attention_1, options,\n                                    prefix='combined_att_mlp_1',)\n        #combined_feat_attention_1.shape 1,196,1\n        \n        prob_attention_1 = self.softmax(combined_feat_attention_1[:, :, 0])\n        #prob_attention_1.shape 1,196\n\n        image_feat_ave_1 = (prob_attention_1[:, :, None] * image_feat_down).asnumpy().sum(axis=1)\n        image_feat_ave_1 = Tensor(image_feat_ave_1)\n        \n        combined_hidden_1 = image_feat_ave_1 + h_encode\n        #combined_hidden_1 1,1024\n        \n        # second layer attention model\n        image_feat_attention_2 = fflayer(shared_params, image_feat_down, options,\n                                     prefix='image_att_mlp_2',\n                                     act_func=options.get('image_att_mlp_act',\n                                                          'tanh'))\n\n        h_encode_attention_2 = fflayer(shared_params, combined_hidden_1, options,\n                                   prefix='sent_att_mlp_2',\n                                   act_func=options.get('sent_att_mlp_act',\n                                                        'tanh'))\n        \n        combined_feat_attention_2 = image_feat_attention_2 + \\\n                                h_encode_attention_2[:, None, :]\n        \n        combined_feat_attention_2 = fflayer(shared_params,\n                                        combined_feat_attention_2, options,\n                                        prefix='combined_att_mlp_2',\n                                        act_func=options.get(\n                                            'combined_att_mlp_act', 'tanh'))\n        \n        prob_attention_2 = self.softmax(combined_feat_attention_2[:, :, 0])\n        \n        image_feat_ave_2 = (prob_attention_2[:, :, None] * image_feat_down).asnumpy().sum(axis=1)\n        image_feat_ave_2 = Tensor(image_feat_ave_2)\n        \n        combined_hidden = image_feat_ave_2 + combined_hidden_1\n        \n        prob = self.softmax(combined_hidden)\n        \n        \n        return prob", "metadata": {"trusted": true}, "execution_count": 50, "outputs": []}, {"cell_type": "code", "source": "vqa = VQA(options)\nds = create_dataset(2, mode='train',q_dict = question_key,a_dict = answer_top_k)\nopt = nn.Momentum(params=vqa.trainable_params(), learning_rate=0.1, momentum=0.9)\nloss = nn.SoftmaxCrossEntropyWithLogits(sparse=True, reduction='mean')\ntest_net = nn.TrainOneStepCell(vqa, optimizer=opt)\nmodel = Model(test_net,loss_fn = loss)", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "model.train(1,ds)", "metadata": {"trusted": true}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "from mindspore import dtype as mstype\ntest_batch = 8\nall_question_idx = Tensor(np.array(all_question_idx),mstype.int32)\nx = all_question_idx[0:8,]\n#modify\nembedding = nn.Embedding(options['dict_size'], options['n_emb'],True)\nembeddings = embedding(x)\n#\u8fd9\u91cc\u76848\u662fbatch_size\nh = Tensor(np.zeros((1,8, options['n_dim']), dtype='float32'))\nc = Tensor(np.zeros((1,8, options['n_dim']), dtype='float32'))\n        \nnet = nn.LSTM(options['n_emb'],options['n_dim'],1,True,True)\noutput,(h1,c1) = net(embeddings, (h,c))\nh_encode = h1[0][-1]\nh_encode = h_encode[None,:]\n# h_encode.shape 1,1024", "metadata": {}, "execution_count": 17, "outputs": []}, {"cell_type": "code", "source": "image_feat = fflayer(shared_params, image_feat, options,\n                        prefix='image_mlp',\n                        act_func='tanh')\nimage_feat = image_feat[0]\n#image_feat.shape 196,1024\n        \nimage_feat_down = image_feat\n#image_feat_down.shape 196,1024\n        \nimage_feat_attention_1 = fflayer(shared_params, image_feat_down, options,\n                                    prefix='image_att_mlp_1',\n                                    act_func='tanh')\n        #image_feat_attention_1.shape 196,512\n\n        \nh_encode_attention_1 = fflayer(shared_params, h_encode, options,\n                                prefix='sent_att_mlp_1',\n                                act_func='tanh')\n        #h_encode_attentioshapehape 1,512\n        \ncombined_feat_attention_1 = image_feat_attention_1 + \\\n                    h_encode_attention_1[:, None, :]\n        #combined_feat_attention_1.shape 1,196,512\n\n        #if options['use_attention_drop']:\n        #combined_feat_attention_1 = dropout_layer(combined_feat_attention_1,\n                                                #dropout, trng, drop_ratio)\ncombined_feat_attention_1 = fflayer1(shared_params,\n                            combined_feat_attention_1, options,\n                            prefix='combined_att_mlp_1',)\n        #combined_feat_attention_1.shape 1,196,1\n        \nsoftmax = nn.Softmax()\nprob_attention_1 = softmax(combined_feat_attention_1[:, :, 0])\n        #prob_attention_1.shape 1,196\n\nimage_feat_ave_1 = (prob_attention_1[:, :, None] * image_feat_down).asnumpy().sum(axis=1)\nimage_feat_ave_1 = Tensor(image_feat_ave_1)\n        \ncombined_hidden_1 = image_feat_ave_1 + h_encode\n        #combined_hidden_1 1,1024", "metadata": {}, "execution_count": 33, "outputs": []}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "def lstm_layer(shared_params, x, mask, h_0, c_0, options, prefix='lstm'):\n    ''' lstm layer:\n    :param shared_params: shared parameters\n    :param x: input, T x batch_size x n_emb\n    :param mask: mask for x, T x batch_size\n    '''\n    n_emb = options['n_emb']\n    n_dim = options['n_dim']\n    # weight matrix for x, n_emb x 4*n_dim (ifoc)\n    lstm_w_x = shared_params[prefix + '_w_x']\n    # weight matrix for h, n_dim x 4*n_dim\n    lstm_w_h = shared_params[prefix + '_w_h']\n    lstm_b_h = shared_params[prefix + '_b_h']\n    h_0 = h_0[:x.shape[1]]\n    c_0 = c_0[:x.shape[1]]\n    question_net = LSTM(n_emb, n_dim)\n    output, (h, c) = question_net(x, (h_0, c_0))\n    return h, c", "metadata": {}, "execution_count": 21, "outputs": []}, {"cell_type": "code", "source": "def build_model(shared_params, options):\n    #input_idx = Tensor.imatrix('input_idx')\n    input_idx = Tensor()\n    global empty_word\n    empty_word = np.zeros((1, options['n_emb']), dtype='float32')\n    w_emb_extend = Tensor.concatenate([empty_word, shared_params['w_emb']],\n                                 axis=0)\n    input_emb = w_emb_extend[input_idx]\n    \n    # get the transformed image feature\n    global h_0, c_0\n    h_0 = np.zeros((batch_size, n_dim), dtype='float32')\n    c_0 = np.zeros((batch_size, n_dim), dtype='float32')\n    h_encode, c_encode = lstm_layer(shared_params, input_emb, input_mask,\n                                    h_0, c_0, options, prefix='sent_lstm')\n    return h_encodem, c_encode", "metadata": {}, "execution_count": 22, "outputs": []}]}