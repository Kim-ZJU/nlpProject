{"metadata": {"language_info": {"name": "python", "version": "3.7.6", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "mindspore-python3.7-aarch64", "display_name": "MindSpore-python3.7-aarch64", "language": "python"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "code", "source": "import os\nimport time\nimport datetime\nimport moxing as mox\nimport argparse\nimport glob\nimport numpy as np\nimport mindspore.nn as nn\nfrom mindspore import Tensor, context\nfrom mindspore.nn.optim.momentum import Momentum\nfrom mindspore.train.model import Model\nfrom mindspore.train.serialization import load_checkpoint, load_param_into_net\nfrom mindspore.ops import operations as P\nfrom mindspore.ops import functional as F\nfrom mindspore.common import dtype as mstype\nimport mindspore.dataset.vision.py_transforms as vision", "metadata": {"trusted": true}, "execution_count": 31, "outputs": []}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=\"s3://nlp.final/san/data/\",dst_url=\"./data\")", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 32, "outputs": [{"name": "stderr", "text": "INFO:root:Listing OBS: 1000\nINFO:root:Listing OBS: 2000\nINFO:root:Listing OBS: 3000\nINFO:root:Listing OBS: 4000\nINFO:root:Listing OBS: 5000\nINFO:root:Listing OBS: 6000\nINFO:root:Listing OBS: 7000\nINFO:root:Listing OBS: 8000\nINFO:root:Listing OBS: 9000\nINFO:root:Listing OBS: 10000\nINFO:root:Listing OBS: 11000\nINFO:root:Listing OBS: 12000\nINFO:root:Listing OBS: 13000\nINFO:root:Listing OBS: 14000\nINFO:root:Listing OBS: 15000\nINFO:root:Listing OBS: 16000\nINFO:root:Listing OBS: 17000\nINFO:root:Listing OBS: 18000\nINFO:root:Listing OBS: 19000\nINFO:root:Listing OBS: 20000\nINFO:root:Listing OBS: 21000\nINFO:root:Listing OBS: 22000\nINFO:root:Listing OBS: 23000\nINFO:root:Listing OBS: 24000\nINFO:root:Listing OBS: 25000\nINFO:root:Listing OBS: 26000\nINFO:root:Listing OBS: 27000\nINFO:root:Listing OBS: 28000\nINFO:root:Listing OBS: 29000\nINFO:root:Listing OBS: 30000\nINFO:root:Listing OBS: 31000\nINFO:root:Listing OBS: 32000\nINFO:root:Listing OBS: 33000\nINFO:root:Listing OBS: 34000\nINFO:root:Listing OBS: 35000\nINFO:root:Listing OBS: 36000\nINFO:root:Listing OBS: 37000\nINFO:root:Listing OBS: 38000\nINFO:root:Listing OBS: 39000\nINFO:root:Listing OBS: 40000\nINFO:root:Listing OBS: 41000\nINFO:root:Listing OBS: 42000\nINFO:root:Listing OBS: 43000\nINFO:root:Listing OBS: 44000\nINFO:root:Listing OBS: 45000\nINFO:root:Listing OBS: 46000\nINFO:root:Listing OBS: 47000\nINFO:root:Listing OBS: 48000\nINFO:root:Listing OBS: 49000\nINFO:root:Listing OBS: 50000\nINFO:root:Listing OBS: 51000\nINFO:root:Listing OBS: 52000\nINFO:root:Listing OBS: 53000\nINFO:root:Listing OBS: 54000\nINFO:root:Listing OBS: 55000\nINFO:root:Listing OBS: 56000\nINFO:root:Listing OBS: 57000\nINFO:root:Listing OBS: 58000\nINFO:root:Listing OBS: 59000\nINFO:root:Listing OBS: 60000\nINFO:root:Listing OBS: 61000\nINFO:root:Listing OBS: 62000\nINFO:root:Listing OBS: 63000\nINFO:root:Listing OBS: 64000\nINFO:root:Listing OBS: 65000\nINFO:root:Listing OBS: 66000\nINFO:root:Listing OBS: 67000\nINFO:root:Listing OBS: 68000\nINFO:root:Listing OBS: 69000\nINFO:root:Listing OBS: 70000\nINFO:root:Listing OBS: 71000\nINFO:root:pid: None.\t1000/71899\nINFO:root:pid: None.\t2000/71899\nINFO:root:pid: None.\t3000/71899\nINFO:root:pid: None.\t4000/71899\nINFO:root:pid: None.\t5000/71899\nINFO:root:pid: None.\t6000/71899\nINFO:root:pid: None.\t7000/71899\nINFO:root:pid: None.\t8000/71899\nINFO:root:pid: None.\t9000/71899\nINFO:root:pid: None.\t10000/71899\nINFO:root:pid: None.\t11000/71899\nINFO:root:pid: None.\t12000/71899\nINFO:root:pid: None.\t13000/71899\nINFO:root:pid: None.\t14000/71899\nINFO:root:pid: None.\t15000/71899\nINFO:root:pid: None.\t16000/71899\nINFO:root:pid: None.\t17000/71899\nINFO:root:pid: None.\t18000/71899\nINFO:root:pid: None.\t19000/71899\nINFO:root:pid: None.\t20000/71899\nINFO:root:pid: None.\t21000/71899\nINFO:root:pid: None.\t22000/71899\nINFO:root:pid: None.\t23000/71899\nINFO:root:pid: None.\t24000/71899\nINFO:root:pid: None.\t25000/71899\nINFO:root:pid: None.\t26000/71899\nINFO:root:pid: None.\t27000/71899\nINFO:root:pid: None.\t28000/71899\nINFO:root:pid: None.\t29000/71899\nINFO:root:pid: None.\t30000/71899\nINFO:root:pid: None.\t31000/71899\nINFO:root:pid: None.\t32000/71899\nINFO:root:pid: None.\t33000/71899\nINFO:root:pid: None.\t34000/71899\nINFO:root:pid: None.\t35000/71899\nINFO:root:pid: None.\t36000/71899\nINFO:root:pid: None.\t37000/71899\nINFO:root:pid: None.\t38000/71899\nINFO:root:pid: None.\t39000/71899\nINFO:root:pid: None.\t40000/71899\nINFO:root:pid: None.\t41000/71899\nINFO:root:pid: None.\t42000/71899\nINFO:root:pid: None.\t43000/71899\nINFO:root:pid: None.\t44000/71899\nINFO:root:pid: None.\t45000/71899\nINFO:root:pid: None.\t46000/71899\nINFO:root:pid: None.\t47000/71899\nINFO:root:pid: None.\t48000/71899\nINFO:root:pid: None.\t49000/71899\nINFO:root:pid: None.\t50000/71899\nINFO:root:pid: None.\t51000/71899\nINFO:root:pid: None.\t52000/71899\nINFO:root:pid: None.\t53000/71899\nINFO:root:pid: None.\t54000/71899\nINFO:root:pid: None.\t55000/71899\nINFO:root:pid: None.\t56000/71899\nINFO:root:pid: None.\t57000/71899\nINFO:root:pid: None.\t58000/71899\nINFO:root:pid: None.\t59000/71899\nINFO:root:pid: None.\t60000/71899\nINFO:root:pid: None.\t61000/71899\nINFO:root:pid: None.\t62000/71899\nINFO:root:pid: None.\t63000/71899\nINFO:root:pid: None.\t64000/71899\nINFO:root:pid: None.\t65000/71899\nINFO:root:pid: None.\t66000/71899\nINFO:root:pid: None.\t67000/71899\nINFO:root:pid: None.\t68000/71899\nINFO:root:pid: None.\t69000/71899\nINFO:root:pid: None.\t70000/71899\nINFO:root:pid: None.\t71000/71899\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=\"s3://nlp.final/san/code/image_model/src\",dst_url=\"./src/\")", "metadata": {"trusted": true}, "execution_count": 3, "outputs": []}, {"cell_type": "code", "source": "from PIL import Image, ImageFile\n\nfrom src.utils.logging import get_logger\nfrom src.dataset import classification_dataset\nfrom easydict import EasyDict as edict\nfrom src.config import imagenet_cfg as vgg_cfg\n# from src.config import cifar_cfg as vgg_cfg", "metadata": {"trusted": true}, "execution_count": 4, "outputs": []}, {"cell_type": "code", "source": "from src.vgg import vgg19\nfrom src.vgg import vgg16", "metadata": {"trusted": true}, "execution_count": 5, "outputs": []}, {"cell_type": "code", "source": "image_path = {\n    \"train\":\"./data/images/train\",\n    \"test\":\"./data/images/test\",\n    \"val\":\"./data/images/val\"\n}\n\nannotation_path = {\n    \"train\":\"./data/annotation/train.json\",\n    \"test\":\"./data/annotation/test.json\",\n    \"val\":\"./data/annotation/val.json\"\n}", "metadata": {"trusted": true}, "execution_count": 6, "outputs": []}, {"cell_type": "code", "source": "model_cfg= edict({\n    \"annotation\":annotation_path,\n    \"image\":image_path,\n    \"cnn_ckpt_19\":\"./data/vgg19_ascend_v111_imagenet2012_research_cv_bs64_acc74.ckpt\",\n    \"cnn_ckpt_16\":\"./data/vgg16_ascend_v120_imagenet2012_official_cv_bs32_acc73.ckpt\",\n    \"log_path\":\"./outputs\",\n\n    \"device_target\": 'Ascend',\n    \"per_batch_size\": 32,\n    \"graph_ckpt\":1,\n    \"rank\": 0,\n    \"group_size\":1\n})", "metadata": {"trusted": true}, "execution_count": 7, "outputs": []}, {"cell_type": "code", "source": "context.set_context(mode=context.GRAPH_MODE, enable_auto_mixed_precision=True,\n                        device_target=model_cfg.device_target, save_graphs=False)\nif os.getenv('DEVICE_ID', \"not_set\").isdigit() and model_cfg.device_target == \"Ascend\":\n    context.set_context(device_id=int(os.getenv('DEVICE_ID')))\nmodel_cfg.outputs_dir = os.path.join(model_cfg.log_path,\n                                    datetime.datetime.now().strftime('%Y-%m-%d_time_%H_%M_%S'))\n\nmodel_cfg.logger = get_logger(model_cfg.outputs_dir, model_cfg.rank)", "metadata": {"trusted": true}, "execution_count": 8, "outputs": []}, {"cell_type": "code", "source": "model_cfg.logger.important_info('start create vgg')\nnetwork = vgg16(vgg_cfg.num_classes, vgg_cfg, phase=\"test\",include_top = False)\nnetwork.add_flags_recursive(fp16=False)\nnetwork.set_train(False)", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 9, "outputs": [{"name": "stdout", "text": "2021-07-13 03:15:06,155:INFO:\n**********************************************************************\n**********************************************************************\n**\n**\n**        start create vgg\n**\n**\n**********************************************************************\n**********************************************************************\n\ninit network\n", "output_type": "stream"}, {"execution_count": 9, "output_type": "execute_result", "data": {"text/plain": "Vgg<\n  (layers): SequentialCell<\n    (0): Conv2d<input_channels=3, output_channels=64, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (1): ReLU<>\n    (2): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (3): ReLU<>\n    (4): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n    (5): Conv2d<input_channels=64, output_channels=128, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (6): ReLU<>\n    (7): Conv2d<input_channels=128, output_channels=128, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (8): ReLU<>\n    (9): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n    (10): Conv2d<input_channels=128, output_channels=256, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (11): ReLU<>\n    (12): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (13): ReLU<>\n    (14): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (15): ReLU<>\n    (16): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n    (17): Conv2d<input_channels=256, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (18): ReLU<>\n    (19): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (20): ReLU<>\n    (21): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (22): ReLU<>\n    (23): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n    (24): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (25): ReLU<>\n    (26): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (27): ReLU<>\n    (28): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (29): ReLU<>\n    (30): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n    >\n  (flatten): Flatten<>\n  (classifier): SequentialCell<\n    (0): Dense<input_channels=25088, output_channels=4096, has_bias=True>\n    (1): ReLU<>\n    (2): Dropout<keep_prob=1.0>\n    (3): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n    (4): ReLU<>\n    (5): Dropout<keep_prob=1.0>\n    (6): Dense<input_channels=4096, output_channels=1000, has_bias=True>\n    >\n  >"}, "metadata": {}}]}, {"cell_type": "code", "source": "model_cfg.logger.important_info('start load checkpoint')\nparam_dict = load_checkpoint(model_cfg.cnn_ckpt_16)", "metadata": {"trusted": true}, "execution_count": 10, "outputs": [{"name": "stdout", "text": "2021-07-13 03:15:23,903:INFO:\n**********************************************************************\n**********************************************************************\n**\n**\n**        start load checkpoint\n**\n**\n**********************************************************************\n**********************************************************************\n\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "param_dict", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 11, "outputs": [{"execution_count": 11, "output_type": "execute_result", "data": {"text/plain": "{'classifier.0.bias': Parameter (name=classifier.0.bias, shape=(4096,), dtype=Float32, requires_grad=True),\n 'classifier.3.bias': Parameter (name=classifier.3.bias, shape=(4096,), dtype=Float32, requires_grad=True),\n 'classifier.6.bias': Parameter (name=classifier.6.bias, shape=(1000,), dtype=Float32, requires_grad=True),\n 'layers.0.weight': Parameter (name=layers.0.weight, shape=(64, 3, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.2.weight': Parameter (name=layers.2.weight, shape=(64, 64, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.5.weight': Parameter (name=layers.5.weight, shape=(128, 64, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.7.weight': Parameter (name=layers.7.weight, shape=(128, 128, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.10.weight': Parameter (name=layers.10.weight, shape=(256, 128, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.12.weight': Parameter (name=layers.12.weight, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.14.weight': Parameter (name=layers.14.weight, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.17.weight': Parameter (name=layers.17.weight, shape=(512, 256, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.19.weight': Parameter (name=layers.19.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.21.weight': Parameter (name=layers.21.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.24.weight': Parameter (name=layers.24.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.26.weight': Parameter (name=layers.26.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n 'layers.28.weight': Parameter (name=layers.28.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n 'classifier.0.weight': Parameter (name=classifier.0.weight, shape=(4096, 25088), dtype=Float32, requires_grad=True),\n 'classifier.3.weight': Parameter (name=classifier.3.weight, shape=(4096, 4096), dtype=Float32, requires_grad=True),\n 'classifier.6.weight': Parameter (name=classifier.6.weight, shape=(1000, 4096), dtype=Float32, requires_grad=True),\n 'global_step': Parameter (name=global_step, shape=(1,), dtype=Int32, requires_grad=True),\n 'momentum': Parameter (name=momentum, shape=(), dtype=Float32, requires_grad=True),\n 'moments.classifier.0.bias': Parameter (name=moments.classifier.0.bias, shape=(4096,), dtype=Float32, requires_grad=True),\n 'moments.classifier.3.bias': Parameter (name=moments.classifier.3.bias, shape=(4096,), dtype=Float32, requires_grad=True),\n 'moments.classifier.6.bias': Parameter (name=moments.classifier.6.bias, shape=(1000,), dtype=Float32, requires_grad=True),\n 'moments.layers.0.weight': Parameter (name=moments.layers.0.weight, shape=(64, 3, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.2.weight': Parameter (name=moments.layers.2.weight, shape=(64, 64, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.5.weight': Parameter (name=moments.layers.5.weight, shape=(128, 64, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.7.weight': Parameter (name=moments.layers.7.weight, shape=(128, 128, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.10.weight': Parameter (name=moments.layers.10.weight, shape=(256, 128, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.12.weight': Parameter (name=moments.layers.12.weight, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.14.weight': Parameter (name=moments.layers.14.weight, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.17.weight': Parameter (name=moments.layers.17.weight, shape=(512, 256, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.19.weight': Parameter (name=moments.layers.19.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.21.weight': Parameter (name=moments.layers.21.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.24.weight': Parameter (name=moments.layers.24.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.26.weight': Parameter (name=moments.layers.26.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.layers.28.weight': Parameter (name=moments.layers.28.weight, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=True),\n 'moments.classifier.0.weight': Parameter (name=moments.classifier.0.weight, shape=(4096, 25088), dtype=Float32, requires_grad=True),\n 'moments.classifier.3.weight': Parameter (name=moments.classifier.3.weight, shape=(4096, 4096), dtype=Float32, requires_grad=True),\n 'moments.classifier.6.weight': Parameter (name=moments.classifier.6.weight, shape=(1000, 4096), dtype=Float32, requires_grad=True),\n 'learning_rate': Parameter (name=learning_rate, shape=(225180,), dtype=Float32, requires_grad=True)}"}, "metadata": {}}]}, {"cell_type": "code", "source": "param_dict['layers.0.weight'].data", "metadata": {"trusted": true}, "execution_count": 12, "outputs": [{"execution_count": 12, "output_type": "execute_result", "data": {"text/plain": "Parameter (name=layers.0.weight, shape=(64, 3, 3, 3), dtype=Float32, requires_grad=True)"}, "metadata": {}}]}, {"cell_type": "code", "source": "param_dict['classifier.0.bias'].data", "metadata": {"trusted": true}, "execution_count": 13, "outputs": [{"execution_count": 13, "output_type": "execute_result", "data": {"text/plain": "Parameter (name=classifier.0.bias, shape=(4096,), dtype=Float32, requires_grad=True)"}, "metadata": {}}]}, {"cell_type": "code", "source": "load_param_into_net(network, param_dict)", "metadata": {"trusted": true}, "execution_count": 14, "outputs": [{"execution_count": 14, "output_type": "execute_result", "data": {"text/plain": "[]"}, "metadata": {}}]}, {"cell_type": "code", "source": "network.get_parameters", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 15, "outputs": [{"execution_count": 15, "output_type": "execute_result", "data": {"text/plain": "<bound method Cell.get_parameters of Vgg<\n  (layers): SequentialCell<\n    (0): Conv2d<input_channels=3, output_channels=64, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (1): ReLU<>\n    (2): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (3): ReLU<>\n    (4): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n    (5): Conv2d<input_channels=64, output_channels=128, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (6): ReLU<>\n    (7): Conv2d<input_channels=128, output_channels=128, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (8): ReLU<>\n    (9): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n    (10): Conv2d<input_channels=128, output_channels=256, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (11): ReLU<>\n    (12): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (13): ReLU<>\n    (14): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (15): ReLU<>\n    (16): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n    (17): Conv2d<input_channels=256, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (18): ReLU<>\n    (19): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (20): ReLU<>\n    (21): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (22): ReLU<>\n    (23): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n    (24): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (25): ReLU<>\n    (26): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (27): ReLU<>\n    (28): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3),stride=(1, 1),  pad_mode=pad, padding=1, dilation=(1, 1), group=1, has_bias=Falseweight_init=ones, bias_init=zeros, format=NCHW>\n    (29): ReLU<>\n    (30): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n    >\n  (flatten): Flatten<>\n  (classifier): SequentialCell<\n    (0): Dense<input_channels=25088, output_channels=4096, has_bias=True>\n    (1): ReLU<>\n    (2): Dropout<keep_prob=1.0>\n    (3): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n    (4): ReLU<>\n    (5): Dropout<keep_prob=1.0>\n    (6): Dense<input_channels=4096, output_channels=1000, has_bias=True>\n    >\n  >>"}, "metadata": {}}]}, {"cell_type": "code", "source": "# wzl\nmean = [0.485 , 0.456, 0.406]\nstd = [0.229 , 0.224, 0.225]\n\ndef get_feature_map(tensor):\n    model_cfg.logger.important_info('start get feature map')\n    output = network(tensor)  \n    return output\n\n# # ccy\n# def get_feature_map(img_root,img_prefix,img_id):\n#     model_cfg.logger.important_info('start get feature map')\n#     img_path = os.path.join(img_root,img_prefix+\"_\"+str(img_id).zfill(12)+\".jpg\")\n#     print(\"img_path:\",img_path)\n    \n#     dataset = ds.CocoDataset(dataset_dir=img_path,annotation_file=,task='Detection')\n#     output = network(Tensor(dataset,mstype.float32))\n# #     print(output)\n\n# import mindspore.dataset as ds\n# # ccy\n# def get_feature_map(img_root,img_prefix,img_id):\n#     model_cfg.logger.important_info('start get feature map')\n#     img_path = os.path.join(img_root,img_prefix+\"_\"+str(img_id).zfill(12)+\".jpg\")\n#     graph_dataset = ds.GraphData(dataset_file=img_path, num_parallel_workers=2)\n#     nodes = graph_dataset.get_all_nodes(node_type=1)\n#     features = graph_dataset.get_node_feature(node_list=nodes, feature_types=[1])\n#     print(features)\n#     output = network(Tensor(graph_dataset,mstype.float32))", "metadata": {"trusted": true}, "execution_count": 16, "outputs": []}, {"cell_type": "code", "source": "def img2tensor(img_root,img_prefix,img_id):\n        img_path = os.path.join(img_root,img_prefix+\"_\"+str(img_id).zfill(12)+\".jpg\")\n        print(\"img_path:\",img_path)\n        img = Image.open(img_path).convert('RGB')\n        transform = edict({\n            \"Decode\": vision.Decode(),\n            \"Resize\": vision.Resize((512, 512)),\n            \"CenterCrop\": vision.CenterCrop(448),\n            \"Normalize\": vision.Normalize(mean=mean, std=std),\n            \"HWC2CHW\": vision.HWC2CHW(),\n            \"ToTensor\":vision.ToTensor()\n        })\n        # img = transform.Decode(img)\n        img = transform.Resize(img)\n        img = transform.CenterCrop(img)\n        img = transform.ToTensor(img)\n        print(\"totensor:\",img)\n    #     img = transform.Normalize(img) # CHW\n    #     print(\"normalized:\",img)\n    #     img = transform.HWC2CHW(img)\n        img = [img]\n        tensor = Tensor(img,mstype.float32)\n        return tensor", "metadata": {"trusted": true}, "execution_count": 25, "outputs": []}, {"cell_type": "code", "source": "img = img2tensor(model_cfg.image.train,\"COCO_train2014\",9)", "metadata": {"trusted": true}, "execution_count": 26, "outputs": [{"name": "stdout", "text": "img_path: ./data/images/train/COCO_train2014_000000000009.jpg\ntotensor: [[[0.         0.00392157 0.         ... 0.05098039 0.04705882 0.04705882]\n  [0.         0.00784314 0.00392157 ... 0.04313726 0.04705882 0.05490196]\n  [0.         0.         0.         ... 0.04313726 0.05490196 0.05490196]\n  ...\n  [0.827451   0.81960785 0.80784315 ... 0.03137255 0.01176471 0.04705882]\n  [0.81960785 0.8156863  0.8        ... 0.01568628 0.05098039 0.14901961]\n  [0.827451   0.80784315 0.79607844 ... 0.09411765 0.1764706  0.20392157]]\n\n [[0.13333334 0.13725491 0.13725491 ... 0.         0.         0.        ]\n  [0.12941177 0.13725491 0.13333334 ... 0.         0.         0.        ]\n  [0.12941177 0.14117648 0.14117648 ... 0.00392157 0.00392157 0.        ]\n  ...\n  [0.7058824  0.69411767 0.68235296 ... 0.20392157 0.19215687 0.20392157]\n  [0.69803923 0.6901961  0.6745098  ... 0.1764706  0.19215687 0.27058825]\n  [0.7058824  0.6862745  0.67058825 ... 0.22745098 0.29411766 0.30588236]]\n\n [[0.5176471  0.5137255  0.5058824  ... 0.17254902 0.16470589 0.16470589]\n  [0.5137255  0.5137255  0.5058824  ... 0.16862746 0.16470589 0.16862746]\n  [0.5176471  0.5176471  0.50980395 ... 0.16470589 0.1764706  0.18431373]\n  ...\n  [0.         0.00392157 0.00784314 ... 0.5019608  0.4627451  0.45490196]\n  [0.         0.00784314 0.         ... 0.43137255 0.44313726 0.50980395]\n  [0.00784314 0.00392157 0.00392157 ... 0.46666667 0.5372549  0.56078434]]]\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "img.shape", "metadata": {"trusted": true}, "execution_count": 27, "outputs": [{"execution_count": 27, "output_type": "execute_result", "data": {"text/plain": "(1, 3, 448, 448)"}, "metadata": {}}]}, {"cell_type": "code", "source": "out = get_feature_map(img)", "metadata": {"trusted": true}, "execution_count": 28, "outputs": [{"name": "stdout", "text": "2021-07-13 03:18:38,221:INFO:\n**********************************************************************\n**********************************************************************\n**\n**\n**        start get feature map\n**\n**\n**********************************************************************\n**********************************************************************\n\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "out[0][0]", "metadata": {"scrolled": true, "trusted": true}, "execution_count": 29, "outputs": [{"execution_count": 29, "output_type": "execute_result", "data": {"text/plain": "Tensor(shape=[14, 14], dtype=Float32, value=\n[[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  1.70898438e+00,  9.82910156e-01,  0.00000000e+00],\n [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  1.89160156e+00,  1.40136719e+00,  2.18505859e-01],\n [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  1.78710938e+00,  2.03906250e+00,  1.13281250e+00],\n ...\n [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  1.93554688e+00,  1.36132812e+00,  0.00000000e+00],\n [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  1.32617188e+00,  1.20214844e+00,  0.00000000e+00],\n [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00 ...  0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"}, "metadata": {}}]}, {"cell_type": "code", "source": "out.shape", "metadata": {"trusted": true}, "execution_count": 30, "outputs": [{"execution_count": 30, "output_type": "execute_result", "data": {"text/plain": "(1, 512, 14, 14)"}, "metadata": {}}]}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}